{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyN9gzlcPK+D1qWF2ZM436Rn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Pre-processing"],"metadata":{"id":"--hcboxZ_mrs"}},{"cell_type":"markdown","source":["Since the image-text data extracted by the CLIP model has a large amount of feature data, it is stored as HDF5 files, which is convenient for subsequent data loading. The stored feature file contains the result of fusion of image features and text features."],"metadata":{"id":"4ObHiz8X_qi8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"908de7a0-479a-4a7e-9ef3-6fa7611a01c8"},"outputs":[],"source":["import numpy as np\n","import librosa\n","from note_seq.protobuf import music_pb2\n","from note_seq import sequences_lib\n","from note_seq import audio_io\n","from note_seq import midi_io\n","from pydub import AudioSegment\n","import tensorflow as tf\n","from note_seq import note_sequence_to_midi_file, NoteSequence, midi_to_note_sequence\n","from magenta.models.music_vae import TrainedModel, configs\n","\n","import pandas as pd\n","import torch\n","import clip\n","from PIL import Image\n","import os\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","import torch\n","import torch.nn as nn\n","import note_seq\n","\n","from tensorflow.keras.layers import Concatenate, Dense, LSTMCell, RNN, StackedRNNCells, Layer\n","from tensorflow.keras import Model\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.optimizers import Adam\n","from tqdm import tqdm\n","\n","import h5py\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7f6ccc84-01ca-4f34-961d-f6b85090d4a5","outputId":"d969eaf1-e4d4-425e-e709-e3c53caf8612"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>443657</th>\n","      <td>willi-baumeister_machine-man-with-spiral-turn-...</td>\n","      <td>The interlocking mechanical shapes fitting tog...</td>\n","      <td>R_HAtyDbw1M_30-40</td>\n","      <td>Someone is skillfully playing maracas playing ...</td>\n","      <td>0.806879</td>\n","    </tr>\n","    <tr>\n","      <th>443658</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","    </tr>\n","    <tr>\n","      <th>443659</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","    </tr>\n","    <tr>\n","      <th>443660</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","    </tr>\n","    <tr>\n","      <th>443661</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>443662 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","443657  willi-baumeister_machine-man-with-spiral-turn-...   \n","443658                           gino-severini_a-dancer-1   \n","443659                  ivan-aivazovsky_sea-at-night-1861   \n","443660                  ivan-aivazovsky_sea-at-night-1861   \n","443661                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","443657  The interlocking mechanical shapes fitting tog...   \n","443658  the collection and collage of different colors...   \n","443659  The peaceful reflections of the moonlight on t...   \n","443660  I can imagine the sailors resting this peacefu...   \n","443661  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","443657    R_HAtyDbw1M_30-40   \n","443658     oMZcsGUi8ZE_0-10   \n","443659    s1QeDT7jqHQ_30-40   \n","443660    ABVYSaLu_VM_10-20   \n","443661    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \n","0       Here we have a slow piano piece played in a ma...          0.791458  \n","1       This is a recording of two didgeridoos. They a...          0.772168  \n","2       This audio contains a female voice speaking in...          0.798202  \n","3       The low quality recording features a resonatin...          0.792188  \n","4       In this clip, a large bell is rung and left to...          0.740201  \n","...                                                   ...               ...  \n","443657  Someone is skillfully playing maracas playing ...          0.806879  \n","443658  This clip features a synchronised playing of s...          0.799300  \n","443659  The low quality recording features multiple la...          0.781008  \n","443660  Here we have a slow piano piece played in a ma...          0.733153  \n","443661  The low quality recording features a theremin ...          0.761976  \n","\n","[443662 rows x 5 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["base_data = pd.read_csv(\"E:\\\\Project and Dissertation in Data Science\\\\dataset\\\\matched_data_TINYBERT.csv\")\n","base_data"]},{"cell_type":"markdown","metadata":{"id":"BwTZbG-0Fsr1"},"source":["## CLIP Model"]},{"cell_type":"markdown","metadata":{"id":"_K8Z3ch2Fsr1"},"source":["### Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESZmlg_uFsr1"},"outputs":[],"source":["# load pre-trained CLIP model\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)"]},{"cell_type":"markdown","metadata":{"id":"6FgbuihTFsr1"},"source":["### Extract Image and Text Features"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"ce39ff5a-c62f-4698-ea69-03daee9a9f53","id":"GImOgSy2Fsr1"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing batches: 100%|██████████| 88733/88733 [2:56:44<00:00,  8.37it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["                                             Artwork  \\\n","0  vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1  vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2  vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3  vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4  vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","\n","                                       Art_Utterance           Music_Name  \\\n","0  She seems very happy in the picture, and you w...    ABVYSaLu_VM_10-20   \n","1  This woman has really knotty hands which makes...  vnwKpQeza3A_320-330   \n","2  When looking at this woman, I am filled with c...    0VwX92X3iPc_30-40   \n","3  A woman looking at ease, peaceful, and satisfi...  kh6rmFg3U4k_480-490   \n","4  She looks like a lady from that past that migh...  -VI2IRq17rs_360-370   \n","\n","                                       Music_Comment  Similarity_Score  \\\n","0  Here we have a slow piano piece played in a ma...          0.791458   \n","1  This is a recording of two didgeridoos. They a...          0.772168   \n","2  This audio contains a female voice speaking in...          0.798202   \n","3  The low quality recording features a resonatin...          0.792188   \n","4  In this clip, a large bell is rung and left to...          0.740201   \n","\n","                                      image_features  \\\n","0  [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","1  [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","2  [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","3  [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","4  [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","\n","                                       text_features  similarities  \n","0  [[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...      0.211750  \n","1  [[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...      0.214637  \n","2  [[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...      0.241790  \n","3  [[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....      0.231524  \n","4  [[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...      0.253234  \n"]}],"source":["image_base_path = \"E:\\\\Project and Dissertation in Data Science\\\\dataset\\\\artemis_official_data\\\\art_images\"\n","\n","# 拼接图像文件名后缀\n","data['Artwork'] = data['Artwork'].apply(lambda x: x + '.jpg')\n","\n","def preprocess_image(image_filename):\n","    image_path = os.path.join(image_base_path, image_filename)\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image = preprocess(image).unsqueeze(0)\n","    return image\n","\n","batch_size = 5  # 定义每次处理的批次大小\n","num_batches = len(data) // batch_size + (len(data) % batch_size != 0)\n","\n","# 初始化存储特征和相似度的列表\n","all_image_features = []\n","all_text_features = []\n","all_similarities = []\n","\n","for i in tqdm(range(num_batches), desc=\"Processing batches\", total=num_batches):\n","    start_idx = i * batch_size\n","    end_idx = min((i + 1) * batch_size, len(data))\n","\n","    # 逐个处理批次中的图像和文本\n","    for idx in range(start_idx, end_idx):\n","        # 预处理图像\n","        image = preprocess_image(data['Artwork'].iloc[idx])\n","\n","        # 处理对应的文本\n","        text = data['Art_Utterance'].iloc[idx]\n","\n","        # 提取图像和文本特征\n","        with torch.no_grad():\n","            image_feature = torch.cat([model.encode_image(image.to(device))]).cpu().numpy()\n","            text_token = clip.tokenize([text], truncate=True).to(device)\n","            text_feature = model.encode_text(text_token).cpu().numpy()\n","\n","        # 存储特征\n","        all_image_features.append(image_feature)\n","        all_text_features.append(text_feature)\n","\n","        # 计算相似度\n","        similarity = cosine_similarity(image_feature, text_feature)[0][0]\n","        all_similarities.append(similarity)\n","\n","# 合并所有批次的特征并存储到数据框中\n","data['image_features'] = all_image_features\n","data['text_features'] = all_text_features\n","data['similarities'] = all_similarities\n","\n","# 打印结果和相似度\n","print(data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQDdy261Fsr1"},"outputs":[],"source":["# 创建 HDF5 文件（'w' 代表写模式）\n","with h5py.File('data.h5', 'w') as hf:\n","    hf.create_dataset('image_features', data=np.array(data['image_features'].tolist()))\n","    hf.create_dataset('text_features', data=np.array(data['text_features'].tolist()))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O69AbfjzFsr1"},"outputs":[],"source":["# 打开 HDF5 文件并读取数据\n","with h5py.File('data.h5', 'r') as hf:\n","    image_features = hf['image_features'][:]\n","    text_features = hf['text_features'][:]\n","\n","# 将数组转换为列表（如果需要）并添加到 other_data DataFrame\n","base_data['image_features'] = list(image_features)\n","base_data['text_features'] = list(text_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"dececac3-55e6-4d45-eb2f-d93cc75a3e1e","id":"SUDUK2UmFsr1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","      <th>image_features</th>\n","      <th>text_features</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>443657</th>\n","      <td>willi-baumeister_machine-man-with-spiral-turn-...</td>\n","      <td>The interlocking mechanical shapes fitting tog...</td>\n","      <td>R_HAtyDbw1M_30-40</td>\n","      <td>Someone is skillfully playing maracas playing ...</td>\n","      <td>0.806879</td>\n","      <td>[[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...</td>\n","      <td>[[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...</td>\n","    </tr>\n","    <tr>\n","      <th>443658</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","      <td>[[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...</td>\n","      <td>[[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...</td>\n","    </tr>\n","    <tr>\n","      <th>443659</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>443660</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...</td>\n","    </tr>\n","    <tr>\n","      <th>443661</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","443657  willi-baumeister_machine-man-with-spiral-turn-...   \n","443658                           gino-severini_a-dancer-1   \n","443659                  ivan-aivazovsky_sea-at-night-1861   \n","443660                  ivan-aivazovsky_sea-at-night-1861   \n","443661                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance         Music_Name  \\\n","443657  The interlocking mechanical shapes fitting tog...  R_HAtyDbw1M_30-40   \n","443658  the collection and collage of different colors...   oMZcsGUi8ZE_0-10   \n","443659  The peaceful reflections of the moonlight on t...  s1QeDT7jqHQ_30-40   \n","443660  I can imagine the sailors resting this peacefu...  ABVYSaLu_VM_10-20   \n","443661  The steep mountains and the moonlight provide ...  8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \\\n","443657  Someone is skillfully playing maracas playing ...          0.806879   \n","443658  This clip features a synchronised playing of s...          0.799300   \n","443659  The low quality recording features multiple la...          0.781008   \n","443660  Here we have a slow piano piece played in a ma...          0.733153   \n","443661  The low quality recording features a theremin ...          0.761976   \n","\n","                                           image_features  \\\n","443657  [[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...   \n","443658  [[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...   \n","443659  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443660  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443661  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","\n","                                            text_features  \n","443657  [[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...  \n","443658  [[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...  \n","443659  [[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....  \n","443660  [[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...  \n","443661  [[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data2 = base_data\n","data2.tail()"]},{"cell_type":"markdown","metadata":{"id":"-ih1MDtoFsr2"},"source":["## Feature Fusion Method"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"7b6a26d2-caf7-41f3-eb01-20907d1d00f1","id":"o2UpVF8CFsr2"},"outputs":[{"name":"stdout","output_type":"stream","text":["所有图像特征的长度相同: True\n","所有文本特征的长度相同: True\n","两列特征的长度完全匹配: True\n"]}],"source":["# 检查每列的长度\n","image_feature_length = data2['image_features'].apply(len)\n","text_feature_length = data2['text_features'].apply(len)\n","\n","# 检查是否每个样本的特征长度都相同\n","all_image_sizes_same = image_feature_length.nunique() == 1\n","all_text_sizes_same = text_feature_length.nunique() == 1\n","\n","# 检查两列之间的长度是否相同\n","all_sizes_match = all(image_feature_length == text_feature_length)\n","\n","print(\"所有图像特征的长度相同:\", all_image_sizes_same)\n","print(\"所有文本特征的长度相同:\", all_text_sizes_same)\n","print(\"两列特征的长度完全匹配:\", all_sizes_match)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"53f9e4ac-5377-4f3c-e3ca-d3b94ef5d517","id":"_RSnfAsvFsr2"},"outputs":[{"name":"stdout","output_type":"stream","text":["图像特征长度分布:\n"," 1    443662\n","Name: image_features, dtype: int64\n","文本特征长度分布:\n"," 1    443662\n","Name: text_features, dtype: int64\n"]}],"source":["# 查看图像特征长度的分布\n","image_feature_length_distribution = data2['image_features'].apply(len).value_counts()\n","print(\"图像特征长度分布:\\n\", image_feature_length_distribution)\n","\n","# 查看文本特征长度的分布\n","text_feature_length_distribution = data2['text_features'].apply(len).value_counts()\n","print(\"文本特征长度分布:\\n\", text_feature_length_distribution)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"561e0db4-5c8f-4d61-d150-b46d515e84e4","id":"7jv16wmqFsr2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Text features dimension: 512\n","Image features dimension: 512\n"]}],"source":["print(\"Text features dimension:\", text_features[0].shape[1])\n","print(\"Image features dimension:\", image_features[0].shape[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gb3gqkc1Fsr2"},"outputs":[],"source":["batch_size = 10  # 根据你的内存大小调整这个批大小\n","num_batches = (len(data2) + batch_size - 1) // batch_size\n","\n","features_mean = []\n","features_weighted = []\n","\n","for i in range(num_batches):\n","    start_idx = i * batch_size\n","    end_idx = min((i + 1) * batch_size, len(data2))\n","\n","    # 计算批次内的向量平均\n","    batch_mean = (data2['image_features'][start_idx:end_idx] + data2['text_features'][start_idx:end_idx]) / 2\n","    features_mean.append(batch_mean)\n","\n","    # 计算批次内的向量加权平均\n","    alpha = 0.6\n","    batch_weighted = alpha * data2['image_features'][start_idx:end_idx] + (1 - alpha) * data2['text_features'][start_idx:end_idx]\n","    features_weighted.append(batch_weighted)\n","\n","# 将所有批次的结果合并回 DataFrame\n","data2['features_mean'] = np.concatenate(features_mean, axis=0)\n","data2['features_weighted'] = np.concatenate(features_weighted, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"ebd09900-f2ac-4237-f424-4e84ea0638b0","id":"EkDwoHtOFsr2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","      <th>image_features</th>\n","      <th>text_features</th>\n","      <th>features_mean</th>\n","      <th>features_weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...</td>\n","      <td>[[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...</td>\n","      <td>[[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...</td>\n","      <td>[[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...</td>\n","      <td>[[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...</td>\n","      <td>[[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...</td>\n","      <td>[[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....</td>\n","      <td>[[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...</td>\n","      <td>[[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...</td>\n","      <td>[[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....</td>\n","      <td>[[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>443657</th>\n","      <td>willi-baumeister_machine-man-with-spiral-turn-...</td>\n","      <td>The interlocking mechanical shapes fitting tog...</td>\n","      <td>R_HAtyDbw1M_30-40</td>\n","      <td>Someone is skillfully playing maracas playing ...</td>\n","      <td>0.806879</td>\n","      <td>[[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...</td>\n","      <td>[[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...</td>\n","      <td>[[0.2112, 0.1582, 0.1954, -0.1548, 0.02435, 0....</td>\n","      <td>[[0.2625, 0.1536, 0.1647, -0.1792, 0.04053, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>443658</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","      <td>[[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...</td>\n","      <td>[[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...</td>\n","      <td>[[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....</td>\n","      <td>[[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>443659</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....</td>\n","      <td>[[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...</td>\n","      <td>[[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...</td>\n","    </tr>\n","    <tr>\n","      <th>443660</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...</td>\n","      <td>[[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...</td>\n","      <td>[[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...</td>\n","    </tr>\n","    <tr>\n","      <th>443661</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...</td>\n","      <td>[[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...</td>\n","      <td>[[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>443662 rows × 9 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","443657  willi-baumeister_machine-man-with-spiral-turn-...   \n","443658                           gino-severini_a-dancer-1   \n","443659                  ivan-aivazovsky_sea-at-night-1861   \n","443660                  ivan-aivazovsky_sea-at-night-1861   \n","443661                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","443657  The interlocking mechanical shapes fitting tog...   \n","443658  the collection and collage of different colors...   \n","443659  The peaceful reflections of the moonlight on t...   \n","443660  I can imagine the sailors resting this peacefu...   \n","443661  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","443657    R_HAtyDbw1M_30-40   \n","443658     oMZcsGUi8ZE_0-10   \n","443659    s1QeDT7jqHQ_30-40   \n","443660    ABVYSaLu_VM_10-20   \n","443661    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \\\n","0       Here we have a slow piano piece played in a ma...          0.791458   \n","1       This is a recording of two didgeridoos. They a...          0.772168   \n","2       This audio contains a female voice speaking in...          0.798202   \n","3       The low quality recording features a resonatin...          0.792188   \n","4       In this clip, a large bell is rung and left to...          0.740201   \n","...                                                   ...               ...   \n","443657  Someone is skillfully playing maracas playing ...          0.806879   \n","443658  This clip features a synchronised playing of s...          0.799300   \n","443659  The low quality recording features multiple la...          0.781008   \n","443660  Here we have a slow piano piece played in a ma...          0.733153   \n","443661  The low quality recording features a theremin ...          0.761976   \n","\n","                                           image_features  \\\n","0       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","1       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","2       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","3       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","4       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","...                                                   ...   \n","443657  [[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...   \n","443658  [[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...   \n","443659  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443660  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443661  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","\n","                                            text_features  \\\n","0       [[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...   \n","1       [[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...   \n","2       [[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...   \n","3       [[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....   \n","4       [[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...   \n","...                                                   ...   \n","443657  [[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...   \n","443658  [[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...   \n","443659  [[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....   \n","443660  [[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...   \n","443661  [[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...   \n","\n","                                            features_mean  \\\n","0       [[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...   \n","1       [[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...   \n","2       [[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...   \n","3       [[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...   \n","4       [[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....   \n","...                                                   ...   \n","443657  [[0.2112, 0.1582, 0.1954, -0.1548, 0.02435, 0....   \n","443658  [[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....   \n","443659  [[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...   \n","443660  [[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...   \n","443661  [[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...   \n","\n","                                        features_weighted  \n","0       [[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...  \n","1       [[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...  \n","2       [[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...  \n","3       [[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....  \n","4       [[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...  \n","...                                                   ...  \n","443657  [[0.2625, 0.1536, 0.1647, -0.1792, 0.04053, 0....  \n","443658  [[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....  \n","443659  [[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...  \n","443660  [[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...  \n","443661  [[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....  \n","\n","[443662 rows x 9 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["data2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fm9ae9pCFsr2"},"outputs":[],"source":["# 创建 HDF5 文件（'w' 代表写模式）\n","with h5py.File('data_mean_and_weighted.h5', 'w') as hf:\n","    hf.create_dataset('image_features', data=np.array(data2['image_features'].tolist()))\n","    hf.create_dataset('text_features', data=np.array(data2['text_features'].tolist()))\n","    hf.create_dataset('features_mean', data=np.array(data2['features_mean'].tolist()))\n","    hf.create_dataset('features_weighted', data=np.array(data2['features_weighted'].tolist()))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yhSjk_GFsr3"},"outputs":[],"source":["# 打开 HDF5 文件并读取数据\n","with h5py.File('data_mean_and_weighted.h5', 'r') as hf:\n","    image_features = hf['image_features'][:]\n","    text_features = hf['text_features'][:]\n","    features_mean = hf['features_mean'][:]\n","    features_weighted = hf['features_weighted'][:]\n","\n","# 将数组转换为列表（如果需要）并添加到 other_data DataFrame\n","base_data['image_features'] = list(image_features)\n","base_data['text_features'] = list(text_features)\n","base_data['features_mean'] = list(features_mean)\n","base_data['features_weighted'] = list(features_weighted)"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"63bf5c5a-93aa-4854-a8e6-748e2f355a3c","id":"q2iHwPH_Fsr3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","      <th>image_features</th>\n","      <th>text_features</th>\n","      <th>features_mean</th>\n","      <th>features_weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...</td>\n","      <td>[[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...</td>\n","      <td>[[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...</td>\n","      <td>[[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...</td>\n","      <td>[[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...</td>\n","      <td>[[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...</td>\n","      <td>[[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....</td>\n","      <td>[[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...</td>\n","      <td>[[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...</td>\n","      <td>[[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....</td>\n","      <td>[[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>443657</th>\n","      <td>willi-baumeister_machine-man-with-spiral-turn-...</td>\n","      <td>The interlocking mechanical shapes fitting tog...</td>\n","      <td>R_HAtyDbw1M_30-40</td>\n","      <td>Someone is skillfully playing maracas playing ...</td>\n","      <td>0.806879</td>\n","      <td>[[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...</td>\n","      <td>[[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...</td>\n","      <td>[[0.2112, 0.1582, 0.1954, -0.1548, 0.02435, 0....</td>\n","      <td>[[0.2625, 0.1536, 0.1647, -0.1792, 0.04053, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>443658</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","      <td>[[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...</td>\n","      <td>[[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...</td>\n","      <td>[[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....</td>\n","      <td>[[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>443659</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....</td>\n","      <td>[[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...</td>\n","      <td>[[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...</td>\n","    </tr>\n","    <tr>\n","      <th>443660</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...</td>\n","      <td>[[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...</td>\n","      <td>[[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...</td>\n","    </tr>\n","    <tr>\n","      <th>443661</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...</td>\n","      <td>[[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...</td>\n","      <td>[[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>443662 rows × 9 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","443657  willi-baumeister_machine-man-with-spiral-turn-...   \n","443658                           gino-severini_a-dancer-1   \n","443659                  ivan-aivazovsky_sea-at-night-1861   \n","443660                  ivan-aivazovsky_sea-at-night-1861   \n","443661                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","443657  The interlocking mechanical shapes fitting tog...   \n","443658  the collection and collage of different colors...   \n","443659  The peaceful reflections of the moonlight on t...   \n","443660  I can imagine the sailors resting this peacefu...   \n","443661  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","443657    R_HAtyDbw1M_30-40   \n","443658     oMZcsGUi8ZE_0-10   \n","443659    s1QeDT7jqHQ_30-40   \n","443660    ABVYSaLu_VM_10-20   \n","443661    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \\\n","0       Here we have a slow piano piece played in a ma...          0.791458   \n","1       This is a recording of two didgeridoos. They a...          0.772168   \n","2       This audio contains a female voice speaking in...          0.798202   \n","3       The low quality recording features a resonatin...          0.792188   \n","4       In this clip, a large bell is rung and left to...          0.740201   \n","...                                                   ...               ...   \n","443657  Someone is skillfully playing maracas playing ...          0.806879   \n","443658  This clip features a synchronised playing of s...          0.799300   \n","443659  The low quality recording features multiple la...          0.781008   \n","443660  Here we have a slow piano piece played in a ma...          0.733153   \n","443661  The low quality recording features a theremin ...          0.761976   \n","\n","                                           image_features  \\\n","0       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","1       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","2       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","3       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","4       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","...                                                   ...   \n","443657  [[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...   \n","443658  [[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...   \n","443659  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443660  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443661  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","\n","                                            text_features  \\\n","0       [[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...   \n","1       [[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...   \n","2       [[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...   \n","3       [[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....   \n","4       [[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...   \n","...                                                   ...   \n","443657  [[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...   \n","443658  [[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...   \n","443659  [[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....   \n","443660  [[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...   \n","443661  [[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...   \n","\n","                                            features_mean  \\\n","0       [[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...   \n","1       [[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...   \n","2       [[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...   \n","3       [[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...   \n","4       [[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....   \n","...                                                   ...   \n","443657  [[0.2112, 0.1582, 0.1954, -0.1548, 0.02435, 0....   \n","443658  [[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....   \n","443659  [[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...   \n","443660  [[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...   \n","443661  [[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...   \n","\n","                                        features_weighted  \n","0       [[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...  \n","1       [[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...  \n","2       [[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...  \n","3       [[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....  \n","4       [[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...  \n","...                                                   ...  \n","443657  [[0.2625, 0.1536, 0.1647, -0.1792, 0.04053, 0....  \n","443658  [[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....  \n","443659  [[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...  \n","443660  [[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...  \n","443661  [[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....  \n","\n","[443662 rows x 9 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["base_data"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"bc306695-ed68-4a07-f030-34a992d92c24","id":"3tPRfi9YFsr3"},"outputs":[{"name":"stdout","output_type":"stream","text":["图像特征长度分布:\n"," 1    443662\n","Name: image_features, dtype: int64\n","文本特征长度分布:\n"," 1    443662\n","Name: text_features, dtype: int64\n","图文均值特征长度分布:\n"," 1    443662\n","Name: features_mean, dtype: int64\n","图文加权平均特征长度分布:\n"," 1    443662\n","Name: features_weighted, dtype: int64\n"]}],"source":["# 查看图像特征长度的分布\n","image_feature_length_distribution = data2['image_features'].apply(len).value_counts()\n","print(\"图像特征长度分布:\\n\", image_feature_length_distribution)\n","\n","# 查看文本特征长度的分布\n","text_feature_length_distribution = data2['text_features'].apply(len).value_counts()\n","print(\"文本特征长度分布:\\n\", text_feature_length_distribution)\n","\n","# 查看图像特征长度的分布\n","image_text_feature_mean_length_distribution = data2['features_mean'].apply(len).value_counts()\n","print(\"图文均值特征长度分布:\\n\", image_text_feature_mean_length_distribution)\n","\n","# 查看文本特征长度的分布\n","image_text_feature_weighted_length_distribution = data2['features_weighted'].apply(len).value_counts()\n","print(\"图文加权平均特征长度分布:\\n\", image_text_feature_weighted_length_distribution)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"6768fd41-ab46-403a-f23b-d37dc31af52c","id":"IysrsLEsFsr3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Text features dimension: 512\n","Image features dimension: 512\n","Image-Text features mean dimension: 512\n","Image-Text features weighted dimension: 512\n"]}],"source":["print(\"Text features dimension:\", text_features[0].shape[1])\n","print(\"Image features dimension:\", image_features[0].shape[1])\n","print(\"Image-Text features mean dimension:\", features_mean[0].shape[1])\n","print(\"Image-Text features weighted dimension:\", features_weighted[0].shape[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"outputId":"2bd38282-c537-4e19-eed3-0fd0203fea3b","id":"rpA7v2zfFsr3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","      <th>image_features</th>\n","      <th>text_features</th>\n","      <th>features_mean</th>\n","      <th>features_weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...</td>\n","      <td>[[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...</td>\n","      <td>[[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...</td>\n","      <td>[[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...</td>\n","      <td>[[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...</td>\n","      <td>[[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...</td>\n","      <td>[[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....</td>\n","      <td>[[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...</td>\n","      <td>[[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...</td>\n","      <td>[[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....</td>\n","      <td>[[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>443657</th>\n","      <td>willi-baumeister_machine-man-with-spiral-turn-...</td>\n","      <td>The interlocking mechanical shapes fitting tog...</td>\n","      <td>R_HAtyDbw1M_30-40</td>\n","      <td>Someone is skillfully playing maracas playing ...</td>\n","      <td>0.806879</td>\n","      <td>[[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...</td>\n","      <td>[[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...</td>\n","      <td>[[0.2112, 0.1582, 0.1954, -0.1548, 0.02435, 0....</td>\n","      <td>[[0.2625, 0.1536, 0.1647, -0.1792, 0.04053, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>443658</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","      <td>[[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...</td>\n","      <td>[[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...</td>\n","      <td>[[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....</td>\n","      <td>[[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>443659</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....</td>\n","      <td>[[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...</td>\n","      <td>[[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...</td>\n","    </tr>\n","    <tr>\n","      <th>443660</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...</td>\n","      <td>[[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...</td>\n","      <td>[[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...</td>\n","    </tr>\n","    <tr>\n","      <th>443661</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...</td>\n","      <td>[[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...</td>\n","      <td>[[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>443662 rows × 9 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","443657  willi-baumeister_machine-man-with-spiral-turn-...   \n","443658                           gino-severini_a-dancer-1   \n","443659                  ivan-aivazovsky_sea-at-night-1861   \n","443660                  ivan-aivazovsky_sea-at-night-1861   \n","443661                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","443657  The interlocking mechanical shapes fitting tog...   \n","443658  the collection and collage of different colors...   \n","443659  The peaceful reflections of the moonlight on t...   \n","443660  I can imagine the sailors resting this peacefu...   \n","443661  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","443657    R_HAtyDbw1M_30-40   \n","443658     oMZcsGUi8ZE_0-10   \n","443659    s1QeDT7jqHQ_30-40   \n","443660    ABVYSaLu_VM_10-20   \n","443661    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \\\n","0       Here we have a slow piano piece played in a ma...          0.791458   \n","1       This is a recording of two didgeridoos. They a...          0.772168   \n","2       This audio contains a female voice speaking in...          0.798202   \n","3       The low quality recording features a resonatin...          0.792188   \n","4       In this clip, a large bell is rung and left to...          0.740201   \n","...                                                   ...               ...   \n","443657  Someone is skillfully playing maracas playing ...          0.806879   \n","443658  This clip features a synchronised playing of s...          0.799300   \n","443659  The low quality recording features multiple la...          0.781008   \n","443660  Here we have a slow piano piece played in a ma...          0.733153   \n","443661  The low quality recording features a theremin ...          0.761976   \n","\n","                                           image_features  \\\n","0       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","1       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","2       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","3       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","4       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","...                                                   ...   \n","443657  [[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...   \n","443658  [[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...   \n","443659  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443660  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443661  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","\n","                                            text_features  \\\n","0       [[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...   \n","1       [[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...   \n","2       [[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...   \n","3       [[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....   \n","4       [[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...   \n","...                                                   ...   \n","443657  [[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...   \n","443658  [[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...   \n","443659  [[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....   \n","443660  [[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...   \n","443661  [[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...   \n","\n","                                            features_mean  \\\n","0       [[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...   \n","1       [[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...   \n","2       [[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...   \n","3       [[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...   \n","4       [[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....   \n","...                                                   ...   \n","443657  [[0.2112, 0.1582, 0.1954, -0.1548, 0.02435, 0....   \n","443658  [[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....   \n","443659  [[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...   \n","443660  [[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...   \n","443661  [[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...   \n","\n","                                        features_weighted  \n","0       [[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...  \n","1       [[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...  \n","2       [[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...  \n","3       [[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....  \n","4       [[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...  \n","...                                                   ...  \n","443657  [[0.2625, 0.1536, 0.1647, -0.1792, 0.04053, 0....  \n","443658  [[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....  \n","443659  [[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...  \n","443660  [[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...  \n","443661  [[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....  \n","\n","[443662 rows x 9 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["base_data"]},{"cell_type":"markdown","metadata":{"id":"6392a4a6-3061-4045-b325-9653201f5629"},"source":["## Transform the Music Format"]},{"cell_type":"markdown","metadata":{"id":"19731444-f8c0-4c79-94a9-d66ffbad811d"},"source":["#### .WAV File -> .MID File"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"91b93200-93b1-48f4-a719-5db5bd8e2a19","outputId":"2eb598f5-e44a-4d1e-c900-80781715294d"},"outputs":[{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 1s 16ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-0SdAVK79lg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-0SdAVK79lg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-0vPFx-wRRI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-0vPFx-wRRI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-0xzrMun0Rs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-0xzrMun0Rs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-3Kv4fdm7Uk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-3Kv4fdm7Uk_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-4NLarMj4xU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-4NLarMj4xU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-5f6hjZf9Yw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-5f6hjZf9Yw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-5FoeegAgvU_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-5FoeegAgvU_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-5xOcMJpTUk_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-5xOcMJpTUk_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-6HBGg1cAI0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-6HBGg1cAI0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-6pcgdLfb_A_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-6pcgdLfb_A_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-6QGvxvaTkI_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-6QGvxvaTkI_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-7B9tPuIP-w_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-7B9tPuIP-w_450-460.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-7wUQP6G5EQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-7wUQP6G5EQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-8C-gydUbR8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-8C-gydUbR8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-8cgbhIR_pw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-8cgbhIR_pw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-bgHkxwoliw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-bgHkxwoliw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-BHPu-dPmWQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-BHPu-dPmWQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-BIMKnb3tlo_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-BIMKnb3tlo_410-420.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-ByoSbgzr4M_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-ByoSbgzr4M_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-cLzki-B06o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-cLzki-B06o_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-Dtir74TiUM_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-Dtir74TiUM_40-50.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 15ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-e4wXAy1iVo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-e4wXAy1iVo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-eDAoheZrY8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-eDAoheZrY8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-EVRXQpt1-8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-EVRXQpt1-8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-f1DNyngKVY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-f1DNyngKVY_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-f6s6kQEHFY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-f6s6kQEHFY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-FEPOSP7ay0_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-FEPOSP7ay0_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-FFx68qSAuY_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-FFx68qSAuY_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-fxh7jAJR8U_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-fxh7jAJR8U_70-80.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-Gf4Ihv1zwc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-Gf4Ihv1zwc_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-hSMzrWZCAE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-hSMzrWZCAE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-i9gpG3vPwA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-i9gpG3vPwA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-i9uQMysy_A_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-i9uQMysy_A_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-IZbvEO9wzU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-IZbvEO9wzU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-jpbCWcz2pk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-jpbCWcz2pk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-JvB5AL59fM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-JvB5AL59fM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-kpR93atgd8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-kpR93atgd8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-lPXTBXa0tE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-lPXTBXa0tE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-M-6VinyMiY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-M-6VinyMiY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-M6K3QoHh40_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-M6K3QoHh40_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-m9pH0WXQto_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-m9pH0WXQto_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-mA_bqD1tgU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-mA_bqD1tgU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-nlkWWphiaM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-nlkWWphiaM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-o0ZtQIkM60_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-o0ZtQIkM60_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-O9mnfC61Ac_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-O9mnfC61Ac_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-oP-XX28B0s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-oP-XX28B0s_30-40.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-pUfYFcsgG4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-pUfYFcsgG4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-Q9MTRXS4bE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-Q9MTRXS4bE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-qcTD2o6I9s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-qcTD2o6I9s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-QuWdnmn-kM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-QuWdnmn-kM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-R0267o4lLk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-R0267o4lLk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-r2-9oyIzkQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-r2-9oyIzkQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-rAhS48FkYw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-rAhS48FkYw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-SD43H5B5hE_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-SD43H5B5hE_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-taO6N-rxv4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-taO6N-rxv4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-tmY1GEH3_Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-tmY1GEH3_Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-tpq_bzSKes_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-tpq_bzSKes_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-U16iKiXGuY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-U16iKiXGuY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-uaTK8sa5Ms_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-uaTK8sa5Ms_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-Umconw-CRE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-Umconw-CRE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-UuEBhule84_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-UuEBhule84_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-v5hgCh3M2w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-v5hgCh3M2w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-VI2IRq17rs_360-370.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-VI2IRq17rs_360-370.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-w12aSkQ9No_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-w12aSkQ9No_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-w4HLksto_k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-w4HLksto_k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-w8maIWtnUk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-w8maIWtnUk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-wVWjl9Kq6U_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-wVWjl9Kq6U_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-wymN80CiYU_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-wymN80CiYU_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-XkbErI_7EU_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-XkbErI_7EU_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-XN0NtrnfMY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-XN0NtrnfMY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-YATTKBtmRA_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-YATTKBtmRA_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-YIT4HBM__g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-YIT4HBM__g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-zA6LL78KYU_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-zA6LL78KYU_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-ZHpNr_KRXU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-ZHpNr_KRXU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-zOybsEdM5E_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-zOybsEdM5E_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\-_OzT7Xyvok_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\-_OzT7Xyvok_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\00M9FhCet6s_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\00M9FhCet6s_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\01hjVJN9xCg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\01hjVJN9xCg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\01PzcPKT3_E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\01PzcPKT3_E_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\03z0rpIkm5g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\03z0rpIkm5g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\04NjXsLyCl4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\04NjXsLyCl4_30-40.mid\n","31/31 [==============================] - 1s 18ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\05JAmKFVy44_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\05JAmKFVy44_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\05OJDYeHLMc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\05OJDYeHLMc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\06Brdf83RZE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\06Brdf83RZE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\06IU9WsEp3s_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\06IU9WsEp3s_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\07FxCXxknY4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\07FxCXxknY4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\08u-jdwjM74_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\08u-jdwjM74_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\09lQmg2wvsY_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\09lQmg2wvsY_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0a6uLBmqZgA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0a6uLBmqZgA_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0a91szM1Ivw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0a91szM1Ivw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0abzD7hBTRk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0abzD7hBTRk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0ADP-O_V3vA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0ADP-O_V3vA_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0BFauf6TGGU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0BFauf6TGGU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0bP2MH3LqvI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0bP2MH3LqvI_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0bRUkLsttto_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0bRUkLsttto_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0bvPjMQ_WbE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0bvPjMQ_WbE_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0c1YU_VtFRE_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0c1YU_VtFRE_180-190.mid\n","32/32 [==============================] - 0s 11ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0cNYPgD6cEA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0cNYPgD6cEA_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0DizopdPMBw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0DizopdPMBw_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0dPx94RPy2M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0dPx94RPy2M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0EvpBtracsk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0EvpBtracsk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0ewQiU3q5jM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0ewQiU3q5jM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0ewWspUqB6Y_430-440.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0ewWspUqB6Y_430-440.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0EzWmAPwoTs_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0EzWmAPwoTs_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0fCpAuxrQ_I_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0fCpAuxrQ_I_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0fiOM---7QI_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0fiOM---7QI_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0Gxn9FtaJFc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0Gxn9FtaJFc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0H3FAoDgzhI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0H3FAoDgzhI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0HXYdGGKV2k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0HXYdGGKV2k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0i8VM_EooCs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0i8VM_EooCs_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0ISHZQJdeSw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0ISHZQJdeSw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0JbGxIR8JTk_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0JbGxIR8JTk_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0jFQ21A6GRA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0jFQ21A6GRA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0KCVgexi4yU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0KCVgexi4yU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0LE6Ll1rVlg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0LE6Ll1rVlg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0lIETNZ_7sg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0lIETNZ_7sg_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0LLlcPiatiU_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0LLlcPiatiU_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0M7nETLOsKQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0M7nETLOsKQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0m9-5BkL4Mc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0m9-5BkL4Mc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0MzrXd8CUCg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0MzrXd8CUCg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0nk7utNkHOY_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0nk7utNkHOY_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0NZY0GHQBP0_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0NZY0GHQBP0_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0OhtODbKajw_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0OhtODbKajw_350-360.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0oIFGARD9xE_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0oIFGARD9xE_410-420.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0Olm321vgk8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0Olm321vgk8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0ONdm4sW47c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0ONdm4sW47c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0OY8XXZ98rw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0OY8XXZ98rw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0OYlHvyfNk4_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0OYlHvyfNk4_130-140.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0PMFAO4TIU4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0PMFAO4TIU4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0q-80dzp6PU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0q-80dzp6PU_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0Q1JLNfm8oU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0Q1JLNfm8oU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0QAaln-hjPw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0QAaln-hjPw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0qtbbK5HVMw_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0qtbbK5HVMw_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0QYNC7J05XI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0QYNC7J05XI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0RcMzUdXDRQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0RcMzUdXDRQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0RDz0rLakwc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0RDz0rLakwc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0rNr_qnoPQ4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0rNr_qnoPQ4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0RpkkfkUBRU_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0RpkkfkUBRU_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0s0Uy0-zBa0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0s0Uy0-zBa0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0SNhAKyXtC8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0SNhAKyXtC8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0SnjS2w_c80_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0SnjS2w_c80_520-530.mid\n","14/31 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 1s 18ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0soVCtJgDTk_5-15.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0soVCtJgDTk_5-15.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0sPVAP17w2U_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0sPVAP17w2U_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0TiEO149Ydc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0TiEO149Ydc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0trWdhSvab4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0trWdhSvab4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0u1sk49gAU0_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0u1sk49gAU0_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0u4gY1bBUwQ_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0u4gY1bBUwQ_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0u5-WiBKam8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0u5-WiBKam8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0Ubu4BqSWmU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0Ubu4BqSWmU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0vFPs6XsU_Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0vFPs6XsU_Q_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0VjPCd62oKg_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0VjPCd62oKg_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0VsjSa1X7iA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0VsjSa1X7iA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0VwX92X3iPc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0VwX92X3iPc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0Wdh45yt7tY_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0Wdh45yt7tY_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0wzsE67O5tE_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0wzsE67O5tE_230-240.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0x6chChxzV0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0x6chChxzV0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0XxinBtKouQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0XxinBtKouQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0ZNFJz-eZTU_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0ZNFJz-eZTU_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0ZXWSO_Y2C0_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0ZXWSO_Y2C0_160-170.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0_hH79HnEdo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0_hH79HnEdo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0_QcatLmg7c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0_QcatLmg7c_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\0_XItMAYkwc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\0_XItMAYkwc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1-Y9kafYuqQ_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1-Y9kafYuqQ_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\10dur7jhFQM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\10dur7jhFQM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\11D0JdB7_4k_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\11D0JdB7_4k_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\11fNNN95_og_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\11fNNN95_og_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\13n6n6nKMhI_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\13n6n6nKMhI_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\14hTDUjCr_g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\14hTDUjCr_g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\15CZ2h5VL-A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\15CZ2h5VL-A_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\16F5fdORzSo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\16F5fdORzSo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\16TsDMjHzYU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\16TsDMjHzYU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\17AtKbQ7glU_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\17AtKbQ7glU_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\19-GI2LzOtc_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\19-GI2LzOtc_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\19Pp9QEw17U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\19Pp9QEw17U_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1ACn3u5UnBw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1ACn3u5UnBw_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1ArUx6UCxe4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1ArUx6UCxe4_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1bSP4wLfMpA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1bSP4wLfMpA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1BVSYfNCcv0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1BVSYfNCcv0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1Ccis4FDGwY_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1Ccis4FDGwY_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1cqcTbDxsHM_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1cqcTbDxsHM_130-140.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1dt9eL2rmSY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1dt9eL2rmSY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1FnA3w94zXI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1FnA3w94zXI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1FnT0RrfMEA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1FnT0RrfMEA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1FU5odlgLmo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1FU5odlgLmo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1GCOnj53QYM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1GCOnj53QYM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1gDNqOQFopY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1gDNqOQFopY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1h2sb2xeCt8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1h2sb2xeCt8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1hABzqBHh7w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1hABzqBHh7w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1hWAOReJehw_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1hWAOReJehw_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1i1sbQOILb0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1i1sbQOILb0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1IK4OeOqAEo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1IK4OeOqAEo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1IMi7yfZVVM_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1IMi7yfZVVM_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1Is1xfDjZrw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1Is1xfDjZrw_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1j13NdQiw8c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1j13NdQiw8c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1jATjKL2vAE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1jATjKL2vAE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1JpeDWbgUO8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1JpeDWbgUO8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1jptuEjuTig_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1jptuEjuTig_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1JqNiV03kog_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1JqNiV03kog_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1JwoLPCIGhs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1JwoLPCIGhs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1KmsVHx7E2c_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1KmsVHx7E2c_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1KN3GrwhY8c_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1KN3GrwhY8c_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1LA64TXatWk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1LA64TXatWk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1ls3ectO1F4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1ls3ectO1F4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1mB_cboJR8s_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1mB_cboJR8s_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1MwaXCfUvX8_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1MwaXCfUvX8_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1nUqhH8bAPk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1nUqhH8bAPk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1O4LpU7HggY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1O4LpU7HggY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1o7iTDLNTFk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1o7iTDLNTFk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1OIfQHKnAcw_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1OIfQHKnAcw_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1PKxdTlquCA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1PKxdTlquCA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1pR0SgbqP3M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1pR0SgbqP3M_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1PSzSTilu_s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1PSzSTilu_s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1Q9DXhXMSFI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1Q9DXhXMSFI_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1QFli7KSXAQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1QFli7KSXAQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1QSD-dzEv7Y_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1QSD-dzEv7Y_40-50.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1Rd1w7Ty1ak_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1Rd1w7Ty1ak_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1rhsnmWLeGw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1rhsnmWLeGw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1RhYdQnZ_hw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1RhYdQnZ_hw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1RRGInmOhTQ_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1RRGInmOhTQ_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1RwhRTe-OKk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1RwhRTe-OKk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1tNkAc29aPE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1tNkAc29aPE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1ToIyrmWFjw_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1ToIyrmWFjw_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1tz4xNRRR4M_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1tz4xNRRR4M_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1uHF1-8TcEk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1uHF1-8TcEk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1V7ReAk9k-4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1V7ReAk9k-4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1W2Cz2Jj76Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1W2Cz2Jj76Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1W2FOzSXsxs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1W2FOzSXsxs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1WlvXneu6oY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1WlvXneu6oY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1xhwyUVSRQk_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1xhwyUVSRQk_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1y1lEOGBcWM_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1y1lEOGBcWM_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1ypKEH2kd7g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1ypKEH2kd7g_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1YPYQP6yupA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1YPYQP6yupA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1yWGmdevTuM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1yWGmdevTuM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1ZaxqZMs21M_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1ZaxqZMs21M_220-230.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1Ziku4FLka4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1Ziku4FLka4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\1_YHHL_t2GI_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\1_YHHL_t2GI_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2-K-7T8ZIWA_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2-K-7T8ZIWA_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\20Vh6z6Ie0E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\20Vh6z6Ie0E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\21MgIcLN8Ow_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\21MgIcLN8Ow_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\23xC7lTBikU_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\23xC7lTBikU_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\244y56-vLWE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\244y56-vLWE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\24cmo2fEQo8_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\24cmo2fEQo8_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\25RWrqQol7Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\25RWrqQol7Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\26HLgXWF-Co_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\26HLgXWF-Co_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\26IOFykrJrc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\26IOFykrJrc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\26jTWRMRoxY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\26jTWRMRoxY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\28pkN4m1x6I_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\28pkN4m1x6I_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\28wBrNjHXOM_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\28wBrNjHXOM_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2aPVOidHLXI_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2aPVOidHLXI_190-200.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2ATMQxWVpXk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2ATMQxWVpXk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2BBAUwC1BI4_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2BBAUwC1BI4_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2bcnAoZbptI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2bcnAoZbptI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2bCuw7U_Rac_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2bCuw7U_Rac_390-400.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2BGzxAuetOA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2BGzxAuetOA_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2ctgUIqyaBk_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2ctgUIqyaBk_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2cxs73i3l1M_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2cxs73i3l1M_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2CzfBZ1mYBs_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2CzfBZ1mYBs_170-180.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2f1UXGix_Cw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2f1UXGix_Cw_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2FQKfGCwjSE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2FQKfGCwjSE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2G5bSYHcJSM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2G5bSYHcJSM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2gc1L3g1itU_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2gc1L3g1itU_20-30.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2GepmcbNlJY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2GepmcbNlJY_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2Gja9wBkz6U_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2Gja9wBkz6U_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2gvyOxKuQPY_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2gvyOxKuQPY_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2GWkKVHxGRM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2GWkKVHxGRM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2i4UNf8tjvU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2i4UNf8tjvU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2I6pPRWKsCQ_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2I6pPRWKsCQ_380-390.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2Ic1zm9mBjk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2Ic1zm9mBjk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2IpapScfsT4_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2IpapScfsT4_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2JnlmS1zzls_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2JnlmS1zzls_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2JNY2SaMk7s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2JNY2SaMk7s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2JuMYUPMGGM_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2JuMYUPMGGM_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2juYRZnhF3g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2juYRZnhF3g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2kcSUBkFbaQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2kcSUBkFbaQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2KkNk9Ao7G4_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2KkNk9Ao7G4_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2kORDnISun4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2kORDnISun4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2KwSyaLT_mw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2KwSyaLT_mw_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2kY_ZG78V-g_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2kY_ZG78V-g_270-280.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2lBZ6yPW9WU_360-370.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2lBZ6yPW9WU_360-370.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2M-CFCo-rkY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2M-CFCo-rkY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2MpzHv5KNZU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2MpzHv5KNZU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2MZUbxulAI4_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2MZUbxulAI4_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2nsZhXxes68_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2nsZhXxes68_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2o1p83UjJFA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2o1p83UjJFA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2pTnwe3DzCs_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2pTnwe3DzCs_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2qO-OQtOBK0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2qO-OQtOBK0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2RMOegT2Jn8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2RMOegT2Jn8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2SenLjPbGzU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2SenLjPbGzU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2ShO1jZYZeA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2ShO1jZYZeA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2sIfE3KOi5s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2sIfE3KOi5s_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2SI_uNBcSyw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2SI_uNBcSyw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2SQxfaWAJJg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2SQxfaWAJJg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2T1P9ovsl4A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2T1P9ovsl4A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2U8Dvh7nwFI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2U8Dvh7nwFI_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2uagA3ujRtM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2uagA3ujRtM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2Ui85-AOLyo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2Ui85-AOLyo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2umjh27MkjU_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2umjh27MkjU_320-330.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2unse6chkMU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2unse6chkMU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2VFVe0RCn7g_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2VFVe0RCn7g_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2vQTq4QLP8U_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2vQTq4QLP8U_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2wGkbHl3IUE_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2wGkbHl3IUE_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2WxUIkF2zEw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2WxUIkF2zEw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2wZCoeq9Ppc_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2wZCoeq9Ppc_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2x4694ExyCU_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2x4694ExyCU_310-320.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2x9735gU01s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2x9735gU01s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2xATintzaj4_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2xATintzaj4_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2xGRCsW6-Bk_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2xGRCsW6-Bk_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2xQuWif8axE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2xQuWif8axE_30-40.mid\n","16/31 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 1s 16ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2xtOqrNKH5s_23-33.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2xtOqrNKH5s_23-33.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2y1QnNBaxAU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2y1QnNBaxAU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2YAyM0aHFRU_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2YAyM0aHFRU_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2YQPwRLB1s0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2YQPwRLB1s0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2z1elo4ucis_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2z1elo4ucis_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2ZB7DUGOdZw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2ZB7DUGOdZw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2zjtZYqg3Ow_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2zjtZYqg3Ow_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2zo5z1I0CeM_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2zo5z1I0CeM_150-160.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2ZogsGp-T4o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2ZogsGp-T4o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2zpITTJiw7Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2zpITTJiw7Q_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2zrPFxxT1VM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2zrPFxxT1VM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2ZrqWkdwVzo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2ZrqWkdwVzo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2ZYzviKuq9w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2ZYzviKuq9w_30-40.mid\n","1/1 [==============================] - 0s 221ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2_kLD3IbF2c_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2_kLD3IbF2c_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2_mFg42LlUI_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2_mFg42LlUI_70-80.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\2_Vk3tmqz-0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\2_Vk3tmqz-0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3-_QS346VWo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3-_QS346VWo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\30tNWUyJCog_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\30tNWUyJCog_140-150.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\31DNFoW3NAw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\31DNFoW3NAw_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\31iD2VPLMxQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\31iD2VPLMxQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\31O2j4aAgYU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\31O2j4aAgYU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\32C6w8V7TX8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\32C6w8V7TX8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\32iayLTRmxg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\32iayLTRmxg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\338iZ76huSQ_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\338iZ76huSQ_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\33dCbb1MyYU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\33dCbb1MyYU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\35b9UHjagaI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\35b9UHjagaI_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\36ToDxW_hns_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\36ToDxW_hns_90-100.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\38R9Vnwt890_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\38R9Vnwt890_30-40.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\390At7lW4iw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\390At7lW4iw_0-10.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3b3s0TvjGwA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3b3s0TvjGwA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3bg0iy-ypcw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3bg0iy-ypcw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3C-5_z01Olc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3C-5_z01Olc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3cEQfNZ_F1w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3cEQfNZ_F1w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3ClbaJYWVO4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3ClbaJYWVO4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3dUo62RsD00_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3dUo62RsD00_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3e6GleQ9sl0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3e6GleQ9sl0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3EtbIWF_ynU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3EtbIWF_ynU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3EXXs3x4Ius_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3EXXs3x4Ius_30-40.mid\n","1/1 [==============================] - 0s 7ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3FJFcgaa0oE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3FJFcgaa0oE_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3fqWosszpnE_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3fqWosszpnE_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3gh1oldZ7Zc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3gh1oldZ7Zc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3HtfWSbmuAc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3HtfWSbmuAc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3IYd8cCmUkQ_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3IYd8cCmUkQ_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3jLef5eHgzU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3jLef5eHgzU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3JYQgXudiH8_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3JYQgXudiH8_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3KdyWJ6wTOw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3KdyWJ6wTOw_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3KQy3Cajo4E_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3KQy3Cajo4E_150-160.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3kSQNjfJnN8_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3kSQNjfJnN8_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3kXukXBvDQQ_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3kXukXBvDQQ_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3m4QSVVBMss_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3m4QSVVBMss_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3mNOJpN_qOQ_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3mNOJpN_qOQ_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3NAqH9LYDyU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3NAqH9LYDyU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3nbB3F-OdSM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3nbB3F-OdSM_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3nfiGGQykxk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3nfiGGQykxk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3noh9LiQNrs_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3noh9LiQNrs_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3Nwsd439zmU_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3Nwsd439zmU_260-270.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3obJKn19jTE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3obJKn19jTE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3otUlQ4wvLY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3otUlQ4wvLY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3OWArQGgmm0_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3OWArQGgmm0_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3PoC1-xd4Yw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3PoC1-xd4Yw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3pU34vUoO9g_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3pU34vUoO9g_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3PwR0D7CuwM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3PwR0D7CuwM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3QNFY4MKTy4_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3QNFY4MKTy4_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3QqVP0odOw4_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3QqVP0odOw4_260-270.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3R8xDvhJk54_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3R8xDvhJk54_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3rbWoeUg9yo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3rbWoeUg9yo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3rvqiSZB4pA_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3rvqiSZB4pA_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3sIlpn9nvKU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3sIlpn9nvKU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3tbFP_JKzXw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3tbFP_JKzXw_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3tK7PpCo0PQ_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3tK7PpCo0PQ_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3tlaELkmRqs_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3tlaELkmRqs_180-190.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3TQmts_MxyQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3TQmts_MxyQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3tSPMzvuQpk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3tSPMzvuQpk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3tyb0cXoX2g_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3tyb0cXoX2g_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3u9OO9Og0Gc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3u9OO9Og0Gc_50-60.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3UHHjbO0ThM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3UHHjbO0ThM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3uz_ZrGsIaA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3uz_ZrGsIaA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3VEMHWnewuc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3VEMHWnewuc_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3vEsFxolnFs_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3vEsFxolnFs_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3VTinB14Pmw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3VTinB14Pmw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3w3fD54bNvU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3w3fD54bNvU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3w4nFQrUQ8k_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3w4nFQrUQ8k_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3w_LsKl-3Pk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3w_LsKl-3Pk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3XeMR8lX0dg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3XeMR8lX0dg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3Xoz87_SUdw_430-440.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3Xoz87_SUdw_430-440.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3Yc7_n6mDsI_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3Yc7_n6mDsI_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3YuO2UOYKRk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3YuO2UOYKRk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3zIQTDfS4Hk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3zIQTDfS4Hk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3zPvfVmL0nE_550-560.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3zPvfVmL0nE_550-560.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3zT0aiN2E70_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3zT0aiN2E70_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3ZyuBJEbmJM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3ZyuBJEbmJM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\3_M9ZMo5TiU_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\3_M9ZMo5TiU_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4--05CAaDsg_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4--05CAaDsg_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\40D4L5Ndi6k_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\40D4L5Ndi6k_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\40i3_JH6FYw_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\40i3_JH6FYw_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\40kbMyL2Wgo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\40kbMyL2Wgo_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\40vmsGsFBsw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\40vmsGsFBsw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\42QgE4mM55I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\42QgE4mM55I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\44sbWBFswUY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\44sbWBFswUY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\45iNSkfzOwM_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\45iNSkfzOwM_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\46WpyRUqwXU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\46WpyRUqwXU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\476vNb6thyM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\476vNb6thyM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\49nqh7uI9fw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\49nqh7uI9fw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4a1a-lmDVaY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4a1a-lmDVaY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4AejyFDHP_k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4AejyFDHP_k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4AfykLGm0j8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4AfykLGm0j8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4b8gTARnmVE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4b8gTARnmVE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Bc9OoagYmo_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Bc9OoagYmo_80-90.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4BIIFU_b6BY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4BIIFU_b6BY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4bXb6GLm6zg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4bXb6GLm6zg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4cg3MsrvJqw_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4cg3MsrvJqw_210-220.mid\n","1/1 [==============================] - 0s 18ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4CkJjhuYRmY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4CkJjhuYRmY_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4CkZqT26Vb0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4CkZqT26Vb0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4CrPPlHN9_s_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4CrPPlHN9_s_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4dilYyxYLmM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4dilYyxYLmM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4ezo771lGts_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4ezo771lGts_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4gEmWJCPZGo_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4gEmWJCPZGo_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4GlH0-KhInI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4GlH0-KhInI_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4H1nc2Xv2Hg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4H1nc2Xv2Hg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4HfU5OQUqq0_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4HfU5OQUqq0_220-230.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4HhJneiP-hY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4HhJneiP-hY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4hulNRgH6cI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4hulNRgH6cI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4i11P4OCRfk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4i11P4OCRfk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4i9DgH80kDg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4i9DgH80kDg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4JYJRqwqWGM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4JYJRqwqWGM_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4jzr88nEdCM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4jzr88nEdCM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4KqSdK5KM-I_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4KqSdK5KM-I_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4kyWH8eWP8M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4kyWH8eWP8M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4kZ0EZg5JRU_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4kZ0EZg5JRU_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4l441DdEJfU_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4l441DdEJfU_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4L9KyVVsQOc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4L9KyVVsQOc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4lcZkOMhKv8_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4lcZkOMhKv8_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Lk8pUeLCwQ_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Lk8pUeLCwQ_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4ls_8xIjBzM_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4ls_8xIjBzM_150-160.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4LZSSya3ZZQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4LZSSya3ZZQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4M0njWKFsME_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4M0njWKFsME_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4mC6K77Y_Ho_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4mC6K77Y_Ho_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Mm5mBgktG0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Mm5mBgktG0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Mo7tdV2LZk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Mo7tdV2LZk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4mtfOkzOvBI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4mtfOkzOvBI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4M_k01zIbVM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4M_k01zIbVM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4o0bARRMYQ8_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4o0bARRMYQ8_160-170.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4PGzlwvXMnE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4PGzlwvXMnE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4PNPgaLKFlc_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4PNPgaLKFlc_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4q-eGdrqiIw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4q-eGdrqiIw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4q6e_ZDFOZI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4q6e_ZDFOZI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4QES-SJ7mP0_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4QES-SJ7mP0_210-220.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4refolVb_uQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4refolVb_uQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4S4NDnNTptY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4S4NDnNTptY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4sD0Bvt3FKk_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4sD0Bvt3FKk_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4T2KBwRxi_g_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4T2KBwRxi_g_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4TDtUHo5cSE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4TDtUHo5cSE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4tF0Lt9VEp8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4tF0Lt9VEp8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4tH9knHaTd0_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4tH9knHaTd0_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4TXy2i036LU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4TXy2i036LU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4T_5clu_0OM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4T_5clu_0OM_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Ua6i_VDYU4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Ua6i_VDYU4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Udqs0trpMw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Udqs0trpMw_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4ueN2gGsH5Y_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4ueN2gGsH5Y_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4ufDENm_ECk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4ufDENm_ECk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Vg0PQuHTk0_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Vg0PQuHTk0_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4vGLTrW04UE_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4vGLTrW04UE_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4vsI0Kwn8jY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4vsI0Kwn8jY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4vWChPYkuwA_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4vWChPYkuwA_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4W8BYc8ZMaE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4W8BYc8ZMaE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Y5VcH7iK3Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Y5VcH7iK3Q_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4Yc71_dU3m4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4Yc71_dU3m4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4yJZ4VX8XQI_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4yJZ4VX8XQI_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4ymXDU-48EE_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4ymXDU-48EE_240-250.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4ZwGxgOwBUc_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4ZwGxgOwBUc_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4zZiWBp0b08_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4zZiWBp0b08_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\4_s5vHgfxnw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\4_s5vHgfxnw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5-aS_pyXesM_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5-aS_pyXesM_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5-tx4Fgqetc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5-tx4Fgqetc_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\50fuQm8B2Yg_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\50fuQm8B2Yg_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\50QEapyTPD4_480-490.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\50QEapyTPD4_480-490.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\51bsCRv6kI0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\51bsCRv6kI0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\52GYcHTcCgs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\52GYcHTcCgs_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\52odOK7G2kg_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\52odOK7G2kg_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\54yI3In3DrU_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\54yI3In3DrU_200-210.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\55qucu8Zs_I_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\55qucu8Zs_I_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\55vMO5LzMHM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\55vMO5LzMHM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\56Cm1AkbfbU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\56Cm1AkbfbU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\577NM64YL18_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\577NM64YL18_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\588osm3C4bw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\588osm3C4bw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\58f4AsxOYhU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\58f4AsxOYhU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\58JwiVM8bYM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\58JwiVM8bYM_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\59Mt7J_0KT4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\59Mt7J_0KT4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5aCDam9_Ps4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5aCDam9_Ps4_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5AdeNHlPnvs_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5AdeNHlPnvs_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5a_Qxd4ECTo_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5a_Qxd4ECTo_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5BEVY0vaygg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5BEVY0vaygg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5blPLHS0Cko_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5blPLHS0Cko_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5bn7PPKcqSA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5bn7PPKcqSA_0-10.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5bsUYmXIgMA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5bsUYmXIgMA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5C70IZwHA5g_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5C70IZwHA5g_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5CtvEcPtknI_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5CtvEcPtknI_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5D4siJjh1j0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5D4siJjh1j0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5DDg2CzAmgE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5DDg2CzAmgE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5DNl3DX4rr0_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5DNl3DX4rr0_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5F8zpfwFKl0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5F8zpfwFKl0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5FbQu7QTme0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5FbQu7QTme0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5FlNBuS7YgM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5FlNBuS7YgM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5fPxUI0Fl-4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5fPxUI0Fl-4_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5gh5H0QqJl0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5gh5H0QqJl0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5gyMt0YzPQ0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5gyMt0YzPQ0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5h5NdW6cYY0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5h5NdW6cYY0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5i0zq91Ocz0_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5i0zq91Ocz0_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5ieMy-PAKA0_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5ieMy-PAKA0_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5iPTcL50mvw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5iPTcL50mvw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5iUwBOf4yek_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5iUwBOf4yek_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5J6CjNc8Njo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5J6CjNc8Njo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5JkPsWsq3E8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5JkPsWsq3E8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5JQIsqc8HBc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5JQIsqc8HBc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5jQIuYPAODg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5jQIuYPAODg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5JqTvKNXzOw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5JqTvKNXzOw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5JRvGMTjEzQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5JRvGMTjEzQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5keRbrVx-G4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5keRbrVx-G4_30-40.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5KvjUzQbMT4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5KvjUzQbMT4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5LX2Unga1p4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5LX2Unga1p4_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5lZFGZXH20E_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5lZFGZXH20E_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5mLYN-F2Oek_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5mLYN-F2Oek_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5mmUQUwr6tI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5mmUQUwr6tI_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5MOJnA715fA_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5MOJnA715fA_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5n8I-br2n1U_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5n8I-br2n1U_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5nJr7iar6ZM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5nJr7iar6ZM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5QtjEBcZR6M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5QtjEBcZR6M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5qVc9y3TNnY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5qVc9y3TNnY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5s0yPPrQWxs_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5s0yPPrQWxs_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5tNOauvQWQQ_470-480.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5tNOauvQWQQ_470-480.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5Tq56BN8PCQ_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5Tq56BN8PCQ_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5tt_GKV13G0_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5tt_GKV13G0_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5UmoK5WAW8Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5UmoK5WAW8Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5UXnulANF8g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5UXnulANF8g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5w3s2T0VBug_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5w3s2T0VBug_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5xAzHL8Zlcs_480-490.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5xAzHL8Zlcs_480-490.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5XNalwqtkFg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5XNalwqtkFg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5ZpVhmhVYoI_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5ZpVhmhVYoI_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5ZX9Ig7XXsw_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5ZX9Ig7XXsw_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\5_orEetudIA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\5_orEetudIA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6-CMq6xw0fg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6-CMq6xw0fg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6-MdbipzKS0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6-MdbipzKS0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\60OIHit4Q-M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\60OIHit4Q-M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\62L5kn1qFeY_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\62L5kn1qFeY_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\63jbksEqycQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\63jbksEqycQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\64auWicQqZY_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\64auWicQqZY_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\65KYS3lIRII_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\65KYS3lIRII_380-390.mid\n","1/1 [==============================] - 0s 648us/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\669Fk7afszw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\669Fk7afszw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\66B46E_hrrk_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\66B46E_hrrk_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6807299U5eg_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6807299U5eg_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\682ODyTqKyw_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\682ODyTqKyw_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\68DacKw1hlE_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\68DacKw1hlE_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\68XchGI6H-4_570-580.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\68XchGI6H-4_570-580.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6AC84nr6ckM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6AC84nr6ckM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6ayVxYbKBe0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6ayVxYbKBe0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6BitLl5Bnxw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6BitLl5Bnxw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6C0HoQe4Y-Y_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6C0HoQe4Y-Y_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6c1vNidtVTc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6c1vNidtVTc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6CaZAITdAsk_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6CaZAITdAsk_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6cQbxwbBqqI_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6cQbxwbBqqI_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6dFCMXNlmzQ_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6dFCMXNlmzQ_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6evOjRxZlHI_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6evOjRxZlHI_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6EwEo0JQkTg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6EwEo0JQkTg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6F8qv0JBWkE_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6F8qv0JBWkE_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6gTrMRQPZMU_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6gTrMRQPZMU_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6HQqly6duac_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6HQqly6duac_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6ieXDFjLKNo_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6ieXDFjLKNo_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6Ig6zwBn4b4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6Ig6zwBn4b4_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6II4JGJDyZo_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6II4JGJDyZo_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6iyinlZEgS4_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6iyinlZEgS4_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6iZ49s7eH5g_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6iZ49s7eH5g_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6J3X0whM_-4_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6J3X0whM_-4_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6jdeSAmkzEU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6jdeSAmkzEU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6jeq5lP5Up0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6jeq5lP5Up0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6JJMlY3Go9s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6JJMlY3Go9s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6jZ8VNANHwM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6jZ8VNANHwM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6k4lcF9IGUk_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6k4lcF9IGUk_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6k6tF0s0lNs_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6k6tF0s0lNs_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6Kb0q9J8lPA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6Kb0q9J8lPA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6KqFiP_ux5U_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6KqFiP_ux5U_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6KXd7l5pThg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6KXd7l5pThg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6L8066DGqcA_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6L8066DGqcA_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6lPgzqrvHHw_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6lPgzqrvHHw_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6lPw0wKu7_M_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6lPw0wKu7_M_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6N1LWG4aztA_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6N1LWG4aztA_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6nWWTNVRDjw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6nWWTNVRDjw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6o6DsSnbpxE_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6o6DsSnbpxE_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6OcoDIrbMtY_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6OcoDIrbMtY_130-140.mid\n","1/1 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6og50XOZeIk_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6og50XOZeIk_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6OVb3rjcB3Q_570-580.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6OVb3rjcB3Q_570-580.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6pHo6fPdPvM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6pHo6fPdPvM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6PquRVe1Wa4_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6PquRVe1Wa4_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6QAZJ4H_5rA_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6QAZJ4H_5rA_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6QfM3BRp-78_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6QfM3BRp-78_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6QHfXuVLhe0_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6QHfXuVLhe0_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6ragcEJVErI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6ragcEJVErI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6SB2FIU9SBc_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6SB2FIU9SBc_200-210.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6Sdu56gquJE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6Sdu56gquJE_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6sWVG6GyJBU_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6sWVG6GyJBU_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6TSluKI0X54_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6TSluKI0X54_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6UJhTZgnVro_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6UJhTZgnVro_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6VJ_auuKzss_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6VJ_auuKzss_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6vM7Kv42Uv0_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6vM7Kv42Uv0_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6XHdybfV5Cw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6XHdybfV5Cw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6XZGmRuaOfo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6XZGmRuaOfo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6yB6plsrjO0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6yB6plsrjO0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6Yh7Cdm2GgY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6Yh7Cdm2GgY_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\6zgvEiJJrM8_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\6zgvEiJJrM8_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\71hqRT9U0wg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\71hqRT9U0wg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\73YTz8RC2Fo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\73YTz8RC2Fo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\74p3DLeDCHE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\74p3DLeDCHE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\752bW5cjXzw_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\752bW5cjXzw_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\75UH33tO0Bo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\75UH33tO0Bo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\75_dMqpSM4o_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\75_dMqpSM4o_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\769EHEG4Mqc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\769EHEG4Mqc_0-10.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\76ON0Ixrr9s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\76ON0Ixrr9s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\770ZkZhGy6A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\770ZkZhGy6A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\78BtX0oNXHQ_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\78BtX0oNXHQ_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\78S8DnvLQDY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\78S8DnvLQDY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\79tuMIiWMZ4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\79tuMIiWMZ4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7avMUhHOCR8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7avMUhHOCR8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7B1OAtD_VIA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7B1OAtD_VIA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7chwYGGSkmE_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7chwYGGSkmE_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7cvqeU9Wh-I_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7cvqeU9Wh-I_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7cw7rDLcujI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7cw7rDLcujI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7DIPyJB4osY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7DIPyJB4osY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7dmT4SgS_EM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7dmT4SgS_EM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7eZTmLV9gcY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7eZTmLV9gcY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7FHzw4HV75Y_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7FHzw4HV75Y_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7FkuqqdWRhw_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7FkuqqdWRhw_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7fVfG0DrLjI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7fVfG0DrLjI_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7h6nTyP7d9o_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7h6nTyP7d9o_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7hKG33wkr0k_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7hKG33wkr0k_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7Ht_Vu1D8nc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7Ht_Vu1D8nc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7IllUjk5fk0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7IllUjk5fk0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7IndxxjZe1c_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7IndxxjZe1c_70-80.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7ITwarmdyfI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7ITwarmdyfI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7JE2eBK1f9M_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7JE2eBK1f9M_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7JMN4DdhwsM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7JMN4DdhwsM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7jWRIjFaoeU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7jWRIjFaoeU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7k3M0pQvzhY_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7k3M0pQvzhY_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7k3OZ_fPXuM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7k3OZ_fPXuM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7KCikXm6hic_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7KCikXm6hic_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7kEeYQx2VLE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7kEeYQx2VLE_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7KIn0zojwu8_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7KIn0zojwu8_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7lG2zPKo9e4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7lG2zPKo9e4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7LlKoQAvXUc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7LlKoQAvXUc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7LlnLjZOqVI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7LlnLjZOqVI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7lV4IvuW2lk_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7lV4IvuW2lk_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7Msk_hkz6zk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7Msk_hkz6zk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7MuFNZHhrOE_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7MuFNZHhrOE_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7muzlOrbDu8_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7muzlOrbDu8_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7NF2kcEfMBI_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7NF2kcEfMBI_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7NnvEryyYdo_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7NnvEryyYdo_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7nrOZXbpXBo_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7nrOZXbpXBo_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7NtM1MM76s0_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7NtM1MM76s0_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7OgH3B49_E4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7OgH3B49_E4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7OjXHfVoI64_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7OjXHfVoI64_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7pdrGzdWMzI_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7pdrGzdWMzI_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7PtHb9jQCtg_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7PtHb9jQCtg_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7pYavsK9sPg_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7pYavsK9sPg_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7p_Mnxl4Vq8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7p_Mnxl4Vq8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7qaRlUc4fb0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7qaRlUc4fb0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7RtQpW2dSU4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7RtQpW2dSU4_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7RUkkhkqyUw_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7RUkkhkqyUw_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7S3fU4RHabw_470-480.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7S3fU4RHabw_470-480.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7TmKzUgWiRU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7TmKzUgWiRU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7uKkUTml-DA_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7uKkUTml-DA_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7Us4WHDmfeA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7Us4WHDmfeA_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7V0G65FK2VQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7V0G65FK2VQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7Vjp9y6wvkY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7Vjp9y6wvkY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7WR-hMV2RKs_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7WR-hMV2RKs_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7xD_Ib3VS_w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7xD_Ib3VS_w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7XMqcbZKNNw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7XMqcbZKNNw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7XQN9XDnRm4_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7XQN9XDnRm4_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7y9RfZXJZsk_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7y9RfZXJZsk_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7ym-LzgwSPE_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7ym-LzgwSPE_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7YtKrL6ScXA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7YtKrL6ScXA_30-40.mid\n","1/1 [==============================] - 0s 12ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7ZW8xO37bA4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7ZW8xO37bA4_10-20.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7ZXz3Xa7APs_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7ZXz3Xa7APs_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7_0g3tEcM0w_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7_0g3tEcM0w_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7_q36NyJtQY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7_q36NyJtQY_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7_Sr2zv1sQc_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7_Sr2zv1sQc_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\7_yBcHaoR0w_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\7_yBcHaoR0w_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\81SgTHg66QY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\81SgTHg66QY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\86YDiQjYU1U_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\86YDiQjYU1U_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\89eBh_Djflw_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\89eBh_Djflw_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8akqVDDGsNQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8akqVDDGsNQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8BJljuSm2Aw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8BJljuSm2Aw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8CY7G2NrlxY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8CY7G2NrlxY_30-40.mid\n","1/1 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8dE1x--TuF8_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8dE1x--TuF8_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8DQbnR7hwpc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8DQbnR7hwpc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8DTKCAv9ods_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8DTKCAv9ods_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8FawGISo8wY_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8FawGISo8wY_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8fibq2VXibw_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8fibq2VXibw_90-100.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8fInAz_GICs_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8fInAz_GICs_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8FZb_R2UANY_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8FZb_R2UANY_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8GKbDSu9Xd0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8GKbDSu9Xd0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8Ha5qGnT7lg_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8Ha5qGnT7lg_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8HHrlxQuZKE_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8HHrlxQuZKE_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8hO1S9VIfPY_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8hO1S9VIfPY_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8hSmQpOPXJE_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8hSmQpOPXJE_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8jDanS4ZzRc_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8jDanS4ZzRc_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8kH-dzSBthI_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8kH-dzSBthI_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8KIoQ2HZ0Hg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8KIoQ2HZ0Hg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8KUV2TFTpGo_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8KUV2TFTpGo_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8LP_wbFLaJE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8LP_wbFLaJE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8LYWfpPUokc_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8LYWfpPUokc_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8m-a_6wLTkU_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8m-a_6wLTkU_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8MKemM0h5mE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8MKemM0h5mE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8NIxqHJrL68_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8NIxqHJrL68_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8nJ2MhvhnJ0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8nJ2MhvhnJ0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8Nrp4jUZeGE_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8Nrp4jUZeGE_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8ntKBILZ06k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8ntKBILZ06k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8OsmFmhNjoA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8OsmFmhNjoA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8oTTgXIO0-I_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8oTTgXIO0-I_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8oUI02eK3SM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8oUI02eK3SM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8pc8fjPIV-Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8pc8fjPIV-Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8PcfPX11Hjg_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8PcfPX11Hjg_230-240.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8pit9UV69S8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8pit9UV69S8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8pYHLfKqHL4_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8pYHLfKqHL4_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8q0An6WY7_c_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8q0An6WY7_c_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8qeTEfOqB0A_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8qeTEfOqB0A_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8r1y_Bz4VfQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8r1y_Bz4VfQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8tY6nioUQIw_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8tY6nioUQIw_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8UhdwnsckJ8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8UhdwnsckJ8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8WPG0dD20lg_540-550.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8WPG0dD20lg_540-550.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8wty3wJfmEY_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8wty3wJfmEY_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8XGXHDMIJw4_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8XGXHDMIJw4_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8Y0FRjkX9xI_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8Y0FRjkX9xI_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8yiJOImd6k0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8yiJOImd6k0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8Yt55huZGZc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8Yt55huZGZc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8Z5xnSxUmGE_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8Z5xnSxUmGE_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8zcogfmAD_o_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8zcogfmAD_o_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8zCZzzAaC4I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8zCZzzAaC4I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\8zGJ9N7c6pE_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\8zGJ9N7c6pE_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9-R70gSqvrc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9-R70gSqvrc_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\91AmOKytRUM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\91AmOKytRUM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\92k_81uqMSM_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\92k_81uqMSM_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\92QYLjfo68Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\92QYLjfo68Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\92sRFZvCnWo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\92sRFZvCnWo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\940MNbCeobw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\940MNbCeobw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\95ThRxhl-ug_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\95ThRxhl-ug_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\98YBS2tdpdU_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\98YBS2tdpdU_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\99ZgIQwLC60_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\99ZgIQwLC60_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9A4VNkMdwhk_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9A4VNkMdwhk_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9A_OmOetiuw_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9A_OmOetiuw_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9BHvpWP2V9Y_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9BHvpWP2V9Y_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Cfs00bZRCg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Cfs00bZRCg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9CJu43AvIds_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9CJu43AvIds_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9DCJTAzUwNc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9DCJTAzUwNc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9dx9IhSqwC4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9dx9IhSqwC4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9EUXyEQZqLo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9EUXyEQZqLo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9gCeNCnWZhE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9gCeNCnWZhE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9gkppwB5CXA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9gkppwB5CXA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9GRNQKSsbvU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9GRNQKSsbvU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9HQNvz4eZPU_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9HQNvz4eZPU_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9IdAIIywBfY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9IdAIIywBfY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Ijpv6e57a4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Ijpv6e57a4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9InBmD_Miek_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9InBmD_Miek_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9iYxf1hS4Yk_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9iYxf1hS4Yk_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9jeEfi6nDak_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9jeEfi6nDak_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9JeN1ld-3fY_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9JeN1ld-3fY_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9K8EePrEDdo_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9K8EePrEDdo_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9KK6rg03bC8_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9KK6rg03bC8_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9kt7rsziUVQ_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9kt7rsziUVQ_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Lst8RagMYs_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Lst8RagMYs_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9m0tNvskmTc_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9m0tNvskmTc_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9M4IT3lOU10_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9M4IT3lOU10_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9NJEKpPeWpE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9NJEKpPeWpE_0-10.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9nVpyqfyBSE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9nVpyqfyBSE_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9ogEGxsJcSY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9ogEGxsJcSY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9ohu45KlgYA_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9ohu45KlgYA_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9oiSwXk8Nsk_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9oiSwXk8Nsk_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9PMoI31ncIs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9PMoI31ncIs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Qd6AdTq3Ls_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Qd6AdTq3Ls_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9QEm6u4bowQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9QEm6u4bowQ_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Qle4fgMbzk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Qle4fgMbzk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9QYo50tFm6w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9QYo50tFm6w_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9r01cpNx2vk_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9r01cpNx2vk_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Rx57dlJtIA_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Rx57dlJtIA_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9TkW1M_ZRr0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9TkW1M_ZRr0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Tl2l3bsLpE_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Tl2l3bsLpE_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9UD7qz7DuVY_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9UD7qz7DuVY_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9UOPRQhNzQ8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9UOPRQhNzQ8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9vbsI9xFuo8_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9vbsI9xFuo8_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9VE1-3q27Qg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9VE1-3q27Qg_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9WzzYYWpeyA_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9WzzYYWpeyA_130-140.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9x7jWb4lE7c_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9x7jWb4lE7c_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9xV0nmojVeg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9xV0nmojVeg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Y8NR6nDxjk_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Y8NR6nDxjk_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9z4YXc9rjTo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9z4YXc9rjTo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9Z6Q0X60rmo_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9Z6Q0X60rmo_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9ZAmdxKLnhs_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9ZAmdxKLnhs_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9ZeoYezrI7Q_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9ZeoYezrI7Q_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9ZilD_4pi7E_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9ZilD_4pi7E_0-10.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9zmQwBUFwd4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9zmQwBUFwd4_0-10.mid\n","1/1 [==============================] - 0s 11ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9ZUzftiN2uw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9ZUzftiN2uw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\9zW-E0XdWdw_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\9zW-E0XdWdw_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\a-11dtG7aK4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\a-11dtG7aK4_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\a-3cZREZh3k_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\a-3cZREZh3k_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A-7dmBdsFXc_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A-7dmBdsFXc_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A-oSBMP-Zy4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A-oSBMP-Zy4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\a-P0p_UtagM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\a-P0p_UtagM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A0XXmVts1y0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A0XXmVts1y0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A2bI-MIIJfU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A2bI-MIIJfU_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A2NtJ12KIuU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A2NtJ12KIuU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A2pgKzeDRqg_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A2pgKzeDRqg_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\a2QxlP5DAYQ_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\a2QxlP5DAYQ_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A2WdjyKQ57A_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A2WdjyKQ57A_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\a2Wuroc8DQU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\a2Wuroc8DQU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A3vsvL-Yx0Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A3vsvL-Yx0Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A446kjocnCg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A446kjocnCg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\a4BjqKd8FsI_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\a4BjqKd8FsI_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\a4jcJ7QZ-OQ_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\a4jcJ7QZ-OQ_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A4jSRfZ6yd0_440-450.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A4jSRfZ6yd0_440-450.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A5fPSkTvjmY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A5fPSkTvjmY_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A6HJBIU1rD0_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A6HJBIU1rD0_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A6ilKRqIDH4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A6ilKRqIDH4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A7RgbrJYe_s_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A7RgbrJYe_s_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A8b-0yWXBCE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A8b-0yWXBCE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A8CJ4YSsUgs_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A8CJ4YSsUgs_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A9ECxUIqw6s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A9ECxUIqw6s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AaajkQEU3A0_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AaajkQEU3A0_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AAFsg91kje4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AAFsg91kje4_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AagemOzvoZE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AagemOzvoZE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Aak-VLHtFPM_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Aak-VLHtFPM_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AAoqx07aTRI_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AAoqx07aTRI_20-30.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AAP5pAB-4jM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AAP5pAB-4jM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AareFwTIg1s_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AareFwTIg1s_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AaVUuKl8294_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AaVUuKl8294_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AAWe4zRLVVU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AAWe4zRLVVU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aBEiuYSSEH0_550-560.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aBEiuYSSEH0_550-560.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ABr4Q_ecoPw_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ABr4Q_ecoPw_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ABSLnckbB8w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ABSLnckbB8w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ABVYSaLu_VM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ABVYSaLu_VM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ABWE9tjTvuI_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ABWE9tjTvuI_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aBXntqgPo6Q_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aBXntqgPo6Q_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aC3IBcRNyro_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aC3IBcRNyro_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ac4M-EkdkDs_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ac4M-EkdkDs_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aCA4yiPfFIg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aCA4yiPfFIg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\acEHGV7Gq6U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\acEHGV7Gq6U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aCTm1TcL7z8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aCTm1TcL7z8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aCUZuMblJPg_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aCUZuMblJPg_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ac_8oRMgDz0_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ac_8oRMgDz0_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AD3aI9avJ8Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AD3aI9avJ8Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ad6UhYwTXXQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ad6UhYwTXXQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ade0UZnb6dw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ade0UZnb6dw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ADffHhHMtjU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ADffHhHMtjU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\adHhqDnyZv8_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\adHhqDnyZv8_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aDlWOvCdNMk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aDlWOvCdNMk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AdxKsUW2mAo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AdxKsUW2mAo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ADxuhHNZVCc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ADxuhHNZVCc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\adYFXYPqo2M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\adYFXYPqo2M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ae8o_FMI0Xs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ae8o_FMI0Xs_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aeDZVfGk7bk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aeDZVfGk7bk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aek3GoFr5MI_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aek3GoFr5MI_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AElgGuUSSKE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AElgGuUSSKE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aeujZtBvMFY_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aeujZtBvMFY_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AEwkS57P4eE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AEwkS57P4eE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AeXDtbfpQlQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AeXDtbfpQlQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aE_CVWMWK74_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aE_CVWMWK74_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AF7sah5a_DE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AF7sah5a_DE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\afavVsmFWds_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\afavVsmFWds_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\afb7pI_01O4_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\afb7pI_01O4_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AFwmMFq_xlc_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AFwmMFq_xlc_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AgCSBCsHkMk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AgCSBCsHkMk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AgJH6Ul1EFg_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AgJH6Ul1EFg_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\agK1OkzW5Yg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\agK1OkzW5Yg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AGNqX_OL-dU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AGNqX_OL-dU_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AGsMCWB1tTk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AGsMCWB1tTk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AgtY6m-b3Gk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AgtY6m-b3Gk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AgVUGzrzJ20_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AgVUGzrzJ20_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\agw-ujSdX0A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\agw-ujSdX0A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AHmcuClSTL4_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AHmcuClSTL4_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aHZdDmYFZN0_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aHZdDmYFZN0_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AI9P6HoiJy8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AI9P6HoiJy8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AiGGDpbgp6I_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AiGGDpbgp6I_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aIIEI33EUqI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aIIEI33EUqI_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aiJj3Z6pu9s_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aiJj3Z6pu9s_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ail32Z1T4QM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ail32Z1T4QM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aItOEVYnpHA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aItOEVYnpHA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AJeRSlZuZbk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AJeRSlZuZbk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aJHv6TV7JpY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aJHv6TV7JpY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AJj6GGLaIfI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AJj6GGLaIfI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AjjQqd0eLzw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AjjQqd0eLzw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AjLuenrAsbE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AjLuenrAsbE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AJTU5RhF3S4_550-560.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AJTU5RhF3S4_550-560.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AJw-x30L46E_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AJw-x30L46E_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ajy9PM2SJ6c_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ajy9PM2SJ6c_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ak7R0_8aKwI_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ak7R0_8aKwI_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AkbCw7oVkw0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AkbCw7oVkw0_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Akg1n9IWSrw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Akg1n9IWSrw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aKhM6zyL--k_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aKhM6zyL--k_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AKI0VrXEDww_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AKI0VrXEDww_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ALcCb2HJmG8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ALcCb2HJmG8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aLnBwjLUZao_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aLnBwjLUZao_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ALU-1AILj1c_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ALU-1AILj1c_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AlVr7-ntuqw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AlVr7-ntuqw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Al_OdIuqoe0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Al_OdIuqoe0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AmAThmRphk0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AmAThmRphk0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\An-4jPvUT14_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\An-4jPvUT14_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ANaaOqwO0Uo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ANaaOqwO0Uo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AnErEDywInE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AnErEDywInE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aNJEh3_Vmps_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aNJEh3_Vmps_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aNjtfIoVzas_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aNjtfIoVzas_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AnMR6SOBa9k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AnMR6SOBa9k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ao-TFiShaWU_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ao-TFiShaWU_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aO0QzRPiEC4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aO0QzRPiEC4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AobHGHJSd-s_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AobHGHJSd-s_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AOgbZUl0y0A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AOgbZUl0y0A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aOGNUGgTQ8k_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aOGNUGgTQ8k_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ap7xvCBtljs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ap7xvCBtljs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aPAa2sfhS7k_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aPAa2sfhS7k_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aPQTrv2B1sw_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aPQTrv2B1sw_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\APSbmhJam74_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\APSbmhJam74_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\APTh9uhf7WQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\APTh9uhf7WQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\APUDprnfOIs_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\APUDprnfOIs_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aq3vov8-fw8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aq3vov8-fw8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aQdZtz90Yzw_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aQdZtz90Yzw_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aqhhfkXKJ1o_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aqhhfkXKJ1o_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AqSV_WKZxEc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AqSV_WKZxEc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aRGAnD12qdw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aRGAnD12qdw_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\argBwTHDDVI_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\argBwTHDDVI_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Aro-HcWNsHI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Aro-HcWNsHI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ARXTRdKCupM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ARXTRdKCupM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aryufzYGhbM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aryufzYGhbM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\as7MhTe961k_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\as7MhTe961k_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\asT8yaJPP1s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\asT8yaJPP1s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aSyRV5j2zV4_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aSyRV5j2zV4_320-330.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\At5v5ZZQHmw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\At5v5ZZQHmw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aT7LGemDB40_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aT7LGemDB40_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aTeOMq8ave8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aTeOMq8ave8_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\atWaDoSyGgY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\atWaDoSyGgY_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AtWf5OAE8aM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AtWf5OAE8aM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AU1l1i0H0j0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AU1l1i0H0j0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AuG9i5cwGW0_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AuG9i5cwGW0_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aUH12rRIVDw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aUH12rRIVDw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aupCwPVWsMo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aupCwPVWsMo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AUPmWhim37Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AUPmWhim37Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AuvFmMpgj70_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AuvFmMpgj70_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AuZNuyR2OJs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AuZNuyR2OJs_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\av-1Ih0S82s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\av-1Ih0S82s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AVG-Wmdd2yU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AVG-Wmdd2yU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AVmJF1uaRuE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AVmJF1uaRuE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aVNcweinmEM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aVNcweinmEM_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AVogdV8khxc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AVogdV8khxc_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AVPm96vrUQw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AVPm96vrUQw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AVsNJgR_K6w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AVsNJgR_K6w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AVVfOYSmexM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AVVfOYSmexM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aW6greyYuO4_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aW6greyYuO4_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\awax48X8YlU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\awax48X8YlU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aWK9CcvOK9w_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aWK9CcvOK9w_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ax8hXst_b5g_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ax8hXst_b5g_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\axb48YrvRmw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\axb48YrvRmw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aXDgw2fLHAA_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aXDgw2fLHAA_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\axqtExFY5-s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\axqtExFY5-s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aY8-pXDdwiw_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aY8-pXDdwiw_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AYln23c8g6w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AYln23c8g6w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AYOlvoM5bjY_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AYOlvoM5bjY_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aYoRcnmz6ZE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aYoRcnmz6ZE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\aYrjw3gjGuk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\aYrjw3gjGuk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AY_yCk4eTTI_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AY_yCk4eTTI_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AzGtPHlrlzU_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AzGtPHlrlzU_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AzhfZ8rNhRk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AzhfZ8rNhRk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\AzsBSUmhl1M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\AzsBSUmhl1M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\azyNUtTHvaE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\azyNUtTHvaE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A_NkQM85g6Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A_NkQM85g6Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\A_oaLt-n4fQ_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\A_oaLt-n4fQ_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\a_r8wKJ8ePw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\a_r8wKJ8ePw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B-1QW7g81gA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B-1QW7g81gA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b-7oO1Rw-fo_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b-7oO1Rw-fo_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b-Cr0EWwaTk_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b-Cr0EWwaTk_140-150.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b-Y-AjW6MJ0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b-Y-AjW6MJ0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B00nfVc4FPI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B00nfVc4FPI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b12xqPnM0So_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b12xqPnM0So_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B1beLwV4yzw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B1beLwV4yzw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B1ixRtiUJ-U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B1ixRtiUJ-U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b1j-hD9zs6Q_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b1j-hD9zs6Q_50-60.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B1vY7kxQ9Xg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B1vY7kxQ9Xg_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b2XAPiRUoN4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b2XAPiRUoN4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B2yLFcmZ51I_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B2yLFcmZ51I_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B3lq6U4PDZo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B3lq6U4PDZo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B3q2wHpzhoM_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B3q2wHpzhoM_110-120.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B3WaJ_3M0vw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B3WaJ_3M0vw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B41tuPoJ61c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B41tuPoJ61c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B496Qv0CuOQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B496Qv0CuOQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b4FomUpNaJE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b4FomUpNaJE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B4KIQtk7fT4_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B4KIQtk7fT4_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B4lGhVjoMTk_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B4lGhVjoMTk_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B5XTBvnpwqU_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B5XTBvnpwqU_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b62RgDBmly8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b62RgDBmly8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b6hr31Qaemg_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b6hr31Qaemg_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b8cgQBzBXi8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b8cgQBzBXi8_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b8okzVltB5Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b8okzVltB5Q_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B8pesuUc8Ek_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B8pesuUc8Ek_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B90BOtSOD2Q_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B90BOtSOD2Q_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b98BJ36K1wo_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b98BJ36K1wo_200-210.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B9IAl-ygE2k_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B9IAl-ygE2k_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B9K58KYq-Cs_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B9K58KYq-Cs_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B9ME0Vcm_xA_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B9ME0Vcm_xA_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b9rgWct9ivI_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b9rgWct9ivI_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\b9yT3nGcD_I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\b9yT3nGcD_I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ba5xPgcHN_0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ba5xPgcHN_0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bAJrcYJgllE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bAJrcYJgllE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BaMBwXQwK3g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BaMBwXQwK3g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Bap5P9buB0Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Bap5P9buB0Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bBfi3iEu9fk_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bBfi3iEu9fk_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bBGcQ2-W768_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bBGcQ2-W768_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BBmXMoI9Qus_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BBmXMoI9Qus_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bBy0NCoCEHc_540-550.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bBy0NCoCEHc_540-550.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BC7dI3lQ2Cg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BC7dI3lQ2Cg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bciw4Tqp6h4_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bciw4Tqp6h4_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BcVapmCbULQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BcVapmCbULQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bcybO-SMY5E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bcybO-SMY5E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Bd0PbyrG6H4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Bd0PbyrG6H4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Bd9TjPP31U0_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Bd9TjPP31U0_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BdhaR2QUGqY_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BdhaR2QUGqY_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BdKiPR3kdjo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BdKiPR3kdjo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BEEknOFrVdU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BEEknOFrVdU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BEhIGoq9tow_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BEhIGoq9tow_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BEwNrjvNiYs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BEwNrjvNiYs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bf8JlTKzOs8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bf8JlTKzOs8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BfUoopDpmmY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BfUoopDpmmY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BGD7J6MP2C8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BGD7J6MP2C8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Bgsy5UpXx8I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Bgsy5UpXx8I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BgTB_xt11bA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BgTB_xt11bA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bg_QoesbfOA_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bg_QoesbfOA_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bha-d3HXdMI_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bha-d3HXdMI_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BHDhHO7J-Oo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BHDhHO7J-Oo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bHiRX6QYwEk_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bHiRX6QYwEk_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bHNdoIWxXDk_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bHNdoIWxXDk_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BhYaXU1MVcQ_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BhYaXU1MVcQ_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BI8YQ3ueD24_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BI8YQ3ueD24_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BiPwCMlghhQ_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BiPwCMlghhQ_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BiqPn3d_dKM_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BiqPn3d_dKM_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bJ6e9Ja1ahQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bJ6e9Ja1ahQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BjIksWR4oKw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BjIksWR4oKw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BjqhHeJD28U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BjqhHeJD28U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bJVogLOURmc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bJVogLOURmc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BK2laUCyaH0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BK2laUCyaH0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BkjpjAohg-0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BkjpjAohg-0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bKm2_67xtVs_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bKm2_67xtVs_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bkQrvXXIRng_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bkQrvXXIRng_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bKS_m7JObxg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bKS_m7JObxg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bkXrQyDbKtk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bkXrQyDbKtk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bkYWnzw_5Bs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bkYWnzw_5Bs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bkzGHRpx5MM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bkzGHRpx5MM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bl-eQ8XD5CY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bl-eQ8XD5CY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Bl-lCgr5hGY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Bl-lCgr5hGY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bl8PgmZ9iOc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bl8PgmZ9iOc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BlhUt8AJJO8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BlhUt8AJJO8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bLjOJRg2P_Q_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bLjOJRg2P_Q_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\blsYgo-B1k8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\blsYgo-B1k8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bm5IT7e2vvI_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bm5IT7e2vvI_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BM9XDXA-CUE_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BM9XDXA-CUE_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BMgYWTTJv3s_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BMgYWTTJv3s_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BMPmavj4keA_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BMPmavj4keA_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bmVd2Zj8_Cc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bmVd2Zj8_Cc_60-70.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BMxgDBoPv_0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BMxgDBoPv_0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BN6W6OQnVoE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BN6W6OQnVoE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BnkDQXlrIX4_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BnkDQXlrIX4_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bNvp4y9WSGM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bNvp4y9WSGM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BojCkFK3pNg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BojCkFK3pNg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bOOJRGRy0zc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bOOJRGRy0zc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bpaq5wQKOkU_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bpaq5wQKOkU_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bpKbpKZB0Q0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bpKbpKZB0Q0_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BpLUOKHl51E_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BpLUOKHl51E_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bPWbeWf5xNI_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bPWbeWf5xNI_160-170.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bPYbRSI16IY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bPYbRSI16IY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bQ9vpp_yXvk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bQ9vpp_yXvk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bqeVxA97TQU_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bqeVxA97TQU_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BqIZipifARo_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BqIZipifARo_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bqMgL5qmZ-k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bqMgL5qmZ-k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bqPCtwibgPg_440-450.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bqPCtwibgPg_440-450.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BquHBzP5Ep0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BquHBzP5Ep0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bqvl7IbPteU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bqvl7IbPteU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BQ_KrefFiTw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BQ_KrefFiTw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\br4A2uNud50_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\br4A2uNud50_200-210.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BR5MDhvcGM8_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BR5MDhvcGM8_60-70.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BrCW3BA8TIQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BrCW3BA8TIQ_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Brc_nOquNbY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Brc_nOquNbY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\brEMnFXsTqo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\brEMnFXsTqo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BRTHyoVgZT0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BRTHyoVgZT0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BS2ZnUhmHj4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BS2ZnUhmHj4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BscoQHJrNm8_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BscoQHJrNm8_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BSe5J0KlN3k_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BSe5J0KlN3k_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BsLFQV8HVZE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BsLFQV8HVZE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bSX5-VPL8rE_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bSX5-VPL8rE_80-90.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bsz_enSJSVk_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bsz_enSJSVk_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BT4env-Tw2o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BT4env-Tw2o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bt7rDryN7G4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bt7rDryN7G4_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bt8iHoIf2mo_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bt8iHoIf2mo_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BtdzVnXZ0i4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BtdzVnXZ0i4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bTLgeqCaYMY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bTLgeqCaYMY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bTlp5Qr99RY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bTlp5Qr99RY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BTMWpYzpu5g_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BTMWpYzpu5g_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bTuKGXDrqdQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bTuKGXDrqdQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bTVl2GeNfqI_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bTVl2GeNfqI_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BUDb8YieUgU_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BUDb8YieUgU_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BurGML_ZqSA_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BurGML_ZqSA_100-110.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BUzsQ6WohH4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BUzsQ6WohH4_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bVc7-sZAi6s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bVc7-sZAi6s_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BVt8RgNrwbQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BVt8RgNrwbQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bVtHAk5w2Z8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bVtHAk5w2Z8_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bwHPVG6vbNQ_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bwHPVG6vbNQ_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BWKQXn5xDwo_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BWKQXn5xDwo_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BWVovghBe2c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BWVovghBe2c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Bx1HZVX4UxM_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Bx1HZVX4UxM_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Bx726MYz6Uo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Bx726MYz6Uo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BxbB2_N5Xtk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BxbB2_N5Xtk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BXcEsM8ykhE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BXcEsM8ykhE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bxF2vxTzlvo_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bxF2vxTzlvo_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bxoJOfGx3hM_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bxoJOfGx3hM_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BxQSEvHdyjQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BxQSEvHdyjQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BXUS7pTYDzI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BXUS7pTYDzI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BXv69uAoHk4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BXv69uAoHk4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bxZeGrM_0ac_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bxZeGrM_0ac_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\by57LpTlGbs_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\by57LpTlGbs_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BYi0fAZtBls_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BYi0fAZtBls_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BYnYTgeM6Go_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BYnYTgeM6Go_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ByOqw8M2U-Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ByOqw8M2U-Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\BYwS1dJRTi0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\BYwS1dJRTi0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bY_EvbARc5Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bY_EvbARc5Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bZJoTauRldE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bZJoTauRldE_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bzOeufhFITk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bzOeufhFITk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bztxC9EFfCk_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bztxC9EFfCk_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bZuXMxR2S4U_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bZuXMxR2S4U_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\bZXQlQnleL4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\bZXQlQnleL4_10-20.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B_ohqOgK6T8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B_ohqOgK6T8_0-10.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\B_tbkQYT9N0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\B_tbkQYT9N0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C-7ubPOCeJk_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C-7ubPOCeJk_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c-85TtcfVSI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c-85TtcfVSI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c-8SLUH5pp4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c-8SLUH5pp4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C-NYmja61zE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C-NYmja61zE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C0AQyOVGvFM_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C0AQyOVGvFM_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C0sSgrr5xrQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C0sSgrr5xrQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c1hLduV1p88_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c1hLduV1p88_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c2akbbdS7I4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c2akbbdS7I4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C33WdI64FiY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C33WdI64FiY_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C3Jhu77uffQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C3Jhu77uffQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C3o8pEsAu5U_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C3o8pEsAu5U_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C3s-DmHtDUg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C3s-DmHtDUg_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c3T1gWSVp6c_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c3T1gWSVp6c_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C4-mZ1jGQ-E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C4-mZ1jGQ-E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c4ftOyl3j_Y_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c4ftOyl3j_Y_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C5MhO2HM2Wg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C5MhO2HM2Wg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c5NGOcNyF4g_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c5NGOcNyF4g_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C5Zs-Lb2rIM_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C5Zs-Lb2rIM_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C6-JxDWYJ-A_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C6-JxDWYJ-A_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c6Fiz5IznkU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c6Fiz5IznkU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C6m_OWe-JE4_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C6m_OWe-JE4_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C6roSYqchkk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C6roSYqchkk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C6ws4MxOH2Y_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C6ws4MxOH2Y_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c7IL4fDqs_I_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c7IL4fDqs_I_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C7WAx3n57Hk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C7WAx3n57Hk_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C8Euv69GR3U_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C8Euv69GR3U_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c8gD6153aNI_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c8gD6153aNI_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c8uE3Q8p9Jo_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c8uE3Q8p9Jo_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C8VECv8kicU_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C8VECv8kicU_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\C9e2k030QcY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\C9e2k030QcY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c9h4p6325Xo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c9h4p6325Xo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c9JyKnsegog_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c9JyKnsegog_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c9tRbWSk7c4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c9tRbWSk7c4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ca-rGWC4xPc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ca-rGWC4xPc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ca3b8qNUbsk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ca3b8qNUbsk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cabjr3xtcR4_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cabjr3xtcR4_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CAbNGe1PWoY_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CAbNGe1PWoY_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CaCjiFUL6Fg_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CaCjiFUL6Fg_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\caFMauLQvd4_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\caFMauLQvd4_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CAL5CgkKkR4_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CAL5CgkKkR4_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cBd0yZ27dtA_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cBd0yZ27dtA_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cbq6Q2htPRM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cbq6Q2htPRM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CBUAy9Zl6ZE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CBUAy9Zl6ZE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Cchf2QH63bI_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Cchf2QH63bI_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ccsgja0XsWE_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ccsgja0XsWE_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cCyfADwHiWs_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cCyfADwHiWs_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CD3OyaDW348_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CD3OyaDW348_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cd5BIQoHyPI_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cd5BIQoHyPI_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Cd7JefC6-Zw_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Cd7JefC6-Zw_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CdFutCUKTXI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CdFutCUKTXI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CdgQIiMdBa4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CdgQIiMdBa4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cdIvqn14xgI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cdIvqn14xgI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cdUk-F-5NCI_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cdUk-F-5NCI_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CdWA-SNcYpM_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CdWA-SNcYpM_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ce-Xok6SRPU_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ce-Xok6SRPU_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ce03XKuyDtk_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ce03XKuyDtk_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CeaWlENtRio_530-540.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CeaWlENtRio_530-540.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cf-IIqhveKw_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cf-IIqhveKw_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Cf1zNtZEcc8_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Cf1zNtZEcc8_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cF7317DK0NQ_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cF7317DK0NQ_80-90.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cfeTMVWFHLo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cfeTMVWFHLo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cFIZraIPAXE_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cFIZraIPAXE_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CfRzy-RtqnQ_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CfRzy-RtqnQ_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cG1dpyC8gV4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cG1dpyC8gV4_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CgK0DU3KFBc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CgK0DU3KFBc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cGorUmWMrwo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cGorUmWMrwo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cGrQw46ftj0_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cGrQw46ftj0_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cGUhG5PZp0A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cGUhG5PZp0A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\chfTjqlrFQQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\chfTjqlrFQQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cHGziT0hrZU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cHGziT0hrZU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cHMDIt3-TsE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cHMDIt3-TsE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CHo8wKj9J1w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CHo8wKj9J1w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ChqJYrmQIN4_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ChqJYrmQIN4_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CHufyCHSF1U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CHufyCHSF1U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\chw8sAKOM5k_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\chw8sAKOM5k_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\chwqnnaiYXw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\chwqnnaiYXw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ciJOulWFhfA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ciJOulWFhfA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CIoEXRnAr-Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CIoEXRnAr-Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cJ80eZY03Yg_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cJ80eZY03Yg_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cJD5JFWnxNo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cJD5JFWnxNo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cjTrK-kA6x0_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cjTrK-kA6x0_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ck-1kRnHqro_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ck-1kRnHqro_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CKEPPcaCjbw_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CKEPPcaCjbw_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CkgzMSbE68M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CkgzMSbE68M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CKkbZCb9Y18_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CKkbZCb9Y18_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cKmK-nFdMXM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cKmK-nFdMXM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CKO35LsM0XI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CKO35LsM0XI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ckOe-8qdaew_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ckOe-8qdaew_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ck_bvV8Aa-k_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ck_bvV8Aa-k_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\clefr8E-iZQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\clefr8E-iZQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cLIump75aC0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cLIump75aC0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ClK_qf_Twm8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ClK_qf_Twm8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ClNTn1wtq7E_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ClNTn1wtq7E_90-100.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CLx4iYWSB1c_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CLx4iYWSB1c_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cm62raVagEE_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cm62raVagEE_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CMfAu72qma0_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CMfAu72qma0_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cMhajmOBr0c_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cMhajmOBr0c_210-220.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cmJj7SxQEp8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cmJj7SxQEp8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cn-SilfYLZo_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cn-SilfYLZo_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CN2QSmhP-HI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CN2QSmhP-HI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Cn3xoxvbkF0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Cn3xoxvbkF0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cnmedj0fYTQ_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cnmedj0fYTQ_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CnTMm-bzssM_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CnTMm-bzssM_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cnvmLwFZr28_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cnvmLwFZr28_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CodqNx1ukOc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CodqNx1ukOc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\COe_UKKVpVo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\COe_UKKVpVo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cOgNXgF21u4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cOgNXgF21u4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\coG_EznBmzE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\coG_EznBmzE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\colnyHv9CAA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\colnyHv9CAA_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cor2HckYTE8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cor2HckYTE8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cOsm3r-xKEE_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cOsm3r-xKEE_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CP3phqztym0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CP3phqztym0_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cp8t27oT_ww_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cp8t27oT_ww_0-10.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CPr0YRTcaKg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CPr0YRTcaKg_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CPX6f-Awx-0_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CPX6f-Awx-0_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cqeVEFFzz7E_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cqeVEFFzz7E_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CQlh4k5pXKA_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CQlh4k5pXKA_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cQpK9zs_uv0_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cQpK9zs_uv0_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CqtknE729Lw_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CqtknE729Lw_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cQWJeYfyw8Y_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cQWJeYfyw8Y_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cQX-WgT0ACQ_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cQX-WgT0ACQ_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CrbZHPkHeV4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CrbZHPkHeV4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CRDDdjDinYc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CRDDdjDinYc_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CretxKgW4Jk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CretxKgW4Jk_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CRHEuoCnI74_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CRHEuoCnI74_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CRIFRYhiKUA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CRIFRYhiKUA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CrkxrgTiVyk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CrkxrgTiVyk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\crToMuDxmL8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\crToMuDxmL8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CRUd8kY3L70_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CRUd8kY3L70_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cs-zcTX2tRA_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cs-zcTX2tRA_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cS2gRhH6it4_560-570.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cS2gRhH6it4_560-570.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cSBRb4KF5xs_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cSBRb4KF5xs_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cT-KZPVpU9M_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cT-KZPVpU9M_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ctJI7pCbxAo_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ctJI7pCbxAo_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cTzJlLzN-xU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cTzJlLzN-xU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cu0k3Uclp1I_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cu0k3Uclp1I_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CudxWnS7ukw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CudxWnS7ukw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CuUu6L5hhMs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CuUu6L5hhMs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CVgLrsBPt4o_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CVgLrsBPt4o_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CVLqZyUwqv8_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CVLqZyUwqv8_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Cwbtn_h6TP8_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Cwbtn_h6TP8_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CwHSb1NOi4c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CwHSb1NOi4c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CwImmV7q1MY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CwImmV7q1MY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CWKBzt-v8w4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CWKBzt-v8w4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CwmUMySSNQc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CwmUMySSNQc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cWOohqFud6g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cWOohqFud6g_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CWQvCCRuU6k_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CWQvCCRuU6k_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cWvkOY6OKss_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cWvkOY6OKss_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cX926M1_LqM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cX926M1_LqM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cXEJWtj2kT8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cXEJWtj2kT8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CxgVq6eovRU_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CxgVq6eovRU_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CxTFgimfNfA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CxTFgimfNfA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cY3g6N5Sokk_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cY3g6N5Sokk_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Cy3HWnwMLyI_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Cy3HWnwMLyI_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CyiPyjYX6AE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CyiPyjYX6AE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cYRsnYEPIiM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cYRsnYEPIiM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\cYSW6Y884dA_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\cYSW6Y884dA_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CzHZNJEV-3o_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CzHZNJEV-3o_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CzMNiypg1I8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CzMNiypg1I8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CZoPTJNmiCw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CZoPTJNmiCw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CZuH43NPynA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CZuH43NPynA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CZWLPPO0KL4_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CZWLPPO0KL4_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\CZZSQ6rd8h0_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\CZZSQ6rd8h0_110-120.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\c_a74UO2ftg_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\c_a74UO2ftg_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d-KxsdWX9xE_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d-KxsdWX9xE_20-30.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D-p9s8y2z_U_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D-p9s8y2z_U_0-10.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D-PxXM2I5gY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D-PxXM2I5gY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D0L-M4trkpw_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D0L-M4trkpw_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d1nz5tZckSA_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d1nz5tZckSA_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d1VB1vA-UsI_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d1VB1vA-UsI_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d20qTsF6ll8_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d20qTsF6ll8_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d2gHgzfC-Oo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d2gHgzfC-Oo_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D2w3qHmJrdU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D2w3qHmJrdU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d352jaSSiFw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d352jaSSiFw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D3f5VIJYR7M_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D3f5VIJYR7M_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D3FyfFIKLVc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D3FyfFIKLVc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D3ht_xXl5S0_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D3ht_xXl5S0_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D4GVgBX1eYc_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D4GVgBX1eYc_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d61plJ66vE8_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d61plJ66vE8_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D644BWAUOXo_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D644BWAUOXo_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d6nURbq86zM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d6nURbq86zM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d6w3d9S1LVM_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d6w3d9S1LVM_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D6xrH93lnoc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D6xrH93lnoc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D712KM8PE3I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D712KM8PE3I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D7pjR9cQChM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D7pjR9cQChM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D7z2Q-hH25s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D7z2Q-hH25s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D8-x1T8M4gk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D8-x1T8M4gk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D8zK7PHIkgA_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D8zK7PHIkgA_170-180.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D9893od03Sc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D9893od03Sc_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d9Oa-2_r2j0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d9Oa-2_r2j0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\d9r_kYpOvW8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\d9r_kYpOvW8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D9TuP8PKD6M_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D9TuP8PKD6M_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DA3fNvbZoBM_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DA3fNvbZoBM_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DA8lw6Mq0DY_360-370.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DA8lw6Mq0DY_360-370.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dAAwzwexvUQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dAAwzwexvUQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DaeJYtWgcoI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DaeJYtWgcoI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DaiVfxATCEE_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DaiVfxATCEE_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dakJh2CdT9Q_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dakJh2CdT9Q_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dalyCstquy8_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dalyCstquy8_150-160.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DAPGvg8qOAU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DAPGvg8qOAU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\darQBSIlol8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\darQBSIlol8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DAX9uKYlDvw_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DAX9uKYlDvw_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DB38NRSHw9A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DB38NRSHw9A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dBAeAk7dXnU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dBAeAk7dXnU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dbBlYyaFKTQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dbBlYyaFKTQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dbenNuhAW_I_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dbenNuhAW_I_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dbftWJH0OvA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dbftWJH0OvA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dbldb9tq8ng_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dbldb9tq8ng_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DCFrCX4HPO8_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DCFrCX4HPO8_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dcgwxlK3VVk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dcgwxlK3VVk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dDKUjMHerLs_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dDKUjMHerLs_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dEc7tV30KJo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dEc7tV30KJo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\deIj55UAxeo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\deIj55UAxeo_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DEnayQZiPGc_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DEnayQZiPGc_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DewyiIpkzi8_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DewyiIpkzi8_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DG5d4megH8g_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DG5d4megH8g_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DGbMEkQerYs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DGbMEkQerYs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DGlP6oTqe5Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DGlP6oTqe5Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DGON0D8E17Q_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DGON0D8E17Q_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DgqPgNqW2hE_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DgqPgNqW2hE_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DgVpK6r7JT4_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DgVpK6r7JT4_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dh9XweTn6rI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dh9XweTn6rI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dHDosntsNho_560-570.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dHDosntsNho_560-570.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dHGAXJ9RPJs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dHGAXJ9RPJs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DhnNZn8JjEQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DhnNZn8JjEQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dIPW9gLGSx8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dIPW9gLGSx8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\diSfkEkTVkE_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\diSfkEkTVkE_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dj-DWiV1z9g_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dj-DWiV1z9g_50-60.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DJHEBMNPc-A_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DJHEBMNPc-A_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Dk7ziLlNfeM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Dk7ziLlNfeM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DKBbLySEGic_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DKBbLySEGic_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DKflAAykh6A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DKflAAykh6A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dKJk3JavNzo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dKJk3JavNzo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dl1ljByerd8_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dl1ljByerd8_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DLDZrtwyY_Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DLDZrtwyY_Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dlhlQKTz3Vs_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dlhlQKTz3Vs_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DLJGT99uEh4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DLJGT99uEh4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DlU56FGTVEk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DlU56FGTVEk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dLUobee5JEs_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dLUobee5JEs_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DlVgHV1UobM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DlVgHV1UobM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dMAp3dvs3kE_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dMAp3dvs3kE_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dMfKImuNJjA_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dMfKImuNJjA_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DMwvY--3XD0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DMwvY--3XD0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dNK9bD3LNCc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dNK9bD3LNCc_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dNOHIxD0j_Q_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dNOHIxD0j_Q_160-170.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dNQh2iLVAoY_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dNQh2iLVAoY_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DNYDyXn6qso_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DNYDyXn6qso_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dO3VsX4rKNc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dO3VsX4rKNc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\doab948Y_X4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\doab948Y_X4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DOb8htND5_o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DOb8htND5_o_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\doHRurF8bf8_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\doHRurF8bf8_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\doX8FjlNPf8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\doX8FjlNPf8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DP2vmsftZHY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DP2vmsftZHY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DP72GDe6AAs_18-28.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DP72GDe6AAs_18-28.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DpAfyjjQJyk_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DpAfyjjQJyk_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dPCj4WhTZ3c_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dPCj4WhTZ3c_40-50.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dPM24O4my-Q_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dPM24O4my-Q_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DpS_TigOHWo_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DpS_TigOHWo_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dqJSTTS7HTY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dqJSTTS7HTY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dql-sQqgVXI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dql-sQqgVXI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DQrdOgRb-oA_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DQrdOgRb-oA_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DQ_gcdLhAsY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DQ_gcdLhAsY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Dr4Ijx7Q9jk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Dr4Ijx7Q9jk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\drJaSu3AWhQ_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\drJaSu3AWhQ_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\drqKxGmdf8Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\drqKxGmdf8Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DRU-IFx-7yQ_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DRU-IFx-7yQ_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dS8AZdmn8Wk_560-570.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dS8AZdmn8Wk_560-570.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dsf3agfkJDY_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dsf3agfkJDY_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dsibOgkezN8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dsibOgkezN8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dSJpZQ8u_xY_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dSJpZQ8u_xY_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dSs4xfvATjc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dSs4xfvATjc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dsU3B0W3TMs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dsU3B0W3TMs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dSyue3RJllA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dSyue3RJllA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dT7uHHQEYHQ_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dT7uHHQEYHQ_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DTnCrtCro44_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DTnCrtCro44_30-40.mid\n","31/31 [==============================] - 0s 15ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dTsOP7Nfnpg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dTsOP7Nfnpg_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dTVkk4GSmNA_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dTVkk4GSmNA_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Du3Q6NdsSso_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Du3Q6NdsSso_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DU3Vlaa8rU0_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DU3Vlaa8rU0_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DU5pD63Pv30_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DU5pD63Pv30_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DueNcVFHI0k_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DueNcVFHI0k_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dUhE6H72Qpg_540-550.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dUhE6H72Qpg_540-550.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dUlQepCYXgw_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dUlQepCYXgw_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\duMRKOb4E2w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\duMRKOb4E2w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DUmXpq-Cksg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DUmXpq-Cksg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DUNOn71oGCw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DUNOn71oGCw_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Dv21JlCT4_k_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Dv21JlCT4_k_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DV5mynb77JM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DV5mynb77JM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dvDSgmqbrM0_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dvDSgmqbrM0_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DvN5813H7Bo_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DvN5813H7Bo_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dVUgd8ot6BE_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dVUgd8ot6BE_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DVuWm53IlVw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DVuWm53IlVw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dW4eW0Xreik_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dW4eW0Xreik_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dw4YwJppiec_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dw4YwJppiec_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DW7Qe-50X_A_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DW7Qe-50X_A_250-260.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dwAo0dKCyBI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dwAo0dKCyBI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dwFtlQLdbq0_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dwFtlQLdbq0_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dwSj0Rr3vFc_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dwSj0Rr3vFc_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DX4_QlYLq30_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DX4_QlYLq30_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Dx58W7opw5A_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Dx58W7opw5A_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DXd83S6NHLg_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DXd83S6NHLg_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DXeiJpZXVAI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DXeiJpZXVAI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DY7ko7iQCug_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DY7ko7iQCug_30-40.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DYp8940tHso_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DYp8940tHso_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DYpjbiyPUho_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DYpjbiyPUho_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DyPmDDN8m78_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DyPmDDN8m78_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DysXetu2I0E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DysXetu2I0E_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dYVy7moyQCc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dYVy7moyQCc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dy_yFZ6dL34_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dy_yFZ6dL34_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\DZ3EShJzOOc_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\DZ3EShJzOOc_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dzPPmuFUicc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dzPPmuFUicc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dztizAgcQ08_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dztizAgcQ08_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\dzW5M4sCphI_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\dzW5M4sCphI_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\D_usHKfOXCw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\D_usHKfOXCw_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E16FgDFQI_w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E16FgDFQI_w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e1KHGfMekek_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e1KHGfMekek_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e1PG31QlQmc_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e1PG31QlQmc_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E29kpquu8W4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E29kpquu8W4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E2gstPe3Im4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E2gstPe3Im4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e2tZmQI8ICw_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e2tZmQI8ICw_230-240.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E2v025Ilsqo_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E2v025Ilsqo_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E3F9bzeCgTQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E3F9bzeCgTQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E3iPiZlT6f8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E3iPiZlT6f8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e4abjaPD9R0_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e4abjaPD9R0_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e4EwrAN6lvU_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e4EwrAN6lvU_340-350.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e4R2O7XpIXU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e4R2O7XpIXU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E4To9BC2jx8_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E4To9BC2jx8_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e57SBRbMXbI_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e57SBRbMXbI_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e5SK6olIYcY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e5SK6olIYcY_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E6B81rrUlnE_440-450.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E6B81rrUlnE_440-450.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E6JR3htwgyE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E6JR3htwgyE_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E7D42u8a5gc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E7D42u8a5gc_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E7q_QwLYI8U_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E7q_QwLYI8U_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e7WPFeDPFB4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e7WPFeDPFB4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e8wnUU5pIWE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e8wnUU5pIWE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e8xkukid_2o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e8xkukid_2o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e9ptOl22Duc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e9ptOl22Duc_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eAFKjP7o1as_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eAFKjP7o1as_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EaGhKzpkNso_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EaGhKzpkNso_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eayGg2OlHOw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eayGg2OlHOw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EayN_Jj0740_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EayN_Jj0740_90-100.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eBF0zRHCbZE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eBF0zRHCbZE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eBlyC9bJacs_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eBlyC9bJacs_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EBpa2CADNJA_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EBpa2CADNJA_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EC4GbkL3XvI_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EC4GbkL3XvI_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EcEDVL6vn_w_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EcEDVL6vn_w_340-350.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\echeYDYFhlY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\echeYDYFhlY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ECP7EJka6N8_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ECP7EJka6N8_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eCyMTN6Hg5k_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eCyMTN6Hg5k_140-150.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EC_JNTVDrok_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EC_JNTVDrok_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\edKvAj0fYxQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\edKvAj0fYxQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ee6MP1bIRUA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ee6MP1bIRUA_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eezaOfrLOkM_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eezaOfrLOkM_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EFlGHxV5WsY_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EFlGHxV5WsY_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\efTVnvwI2PQ_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\efTVnvwI2PQ_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EfUUgsioXyU_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EfUUgsioXyU_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EGIeykrN4eg_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EGIeykrN4eg_410-420.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EgwGYmAH0BA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EgwGYmAH0BA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ehJKd9HLA04_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ehJKd9HLA04_370-380.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ehks1uuwR3s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ehks1uuwR3s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EHm7vLZewS0_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EHm7vLZewS0_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eI4PbSh6g_Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eI4PbSh6g_Y_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EieK70X8lnw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EieK70X8lnw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eiFyXXqd9Rk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eiFyXXqd9Rk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eISYX9koocM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eISYX9koocM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eiUjc4UPnSs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eiUjc4UPnSs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eiyyoUt64Zc_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eiyyoUt64Zc_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EIzBD62ja8E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EIzBD62ja8E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EJMUwh1vY2s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EJMUwh1vY2s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EkMgPJfSL04_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EkMgPJfSL04_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EkmHGd0U8yE_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EkmHGd0U8yE_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ekoh6TJpA88_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ekoh6TJpA88_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EKt_KEbqQfQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EKt_KEbqQfQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EKZvq0dUk50_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EKZvq0dUk50_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EL2DtgPD4J4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EL2DtgPD4J4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ELhxZhWsGM8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ELhxZhWsGM8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eM0PkfqGmIE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eM0PkfqGmIE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\em7akjDUsWk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\em7akjDUsWk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Emc18GpAeRY_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Emc18GpAeRY_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\emDU4QvdwVk_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\emDU4QvdwVk_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EmSZKb0LdVM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EmSZKb0LdVM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\en0haa37gnk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\en0haa37gnk_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\en56uOGTwzg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\en56uOGTwzg_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EnewI6fNhVA_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EnewI6fNhVA_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EnJ8zV3vaJA_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EnJ8zV3vaJA_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EN_FOFkxAEw_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EN_FOFkxAEw_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EOaQnfDjVyo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EOaQnfDjVyo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eOmQbJljnqE_580-590.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eOmQbJljnqE_580-590.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Eop_sG9FVgA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Eop_sG9FVgA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EoZH1gyRlr4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EoZH1gyRlr4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EPjfqS5NvCY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EPjfqS5NvCY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EptdhC17avY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EptdhC17avY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EPvnkbo5wrI_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EPvnkbo5wrI_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eQHQWb6FCio_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eQHQWb6FCio_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EQHrQIaQNv8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EQHrQIaQNv8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EQSv7DIJJtw_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EQSv7DIJJtw_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eQTK2fo3RoE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eQTK2fo3RoE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EQVZLtlDkHw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EQVZLtlDkHw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EremEyLrdUY_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EremEyLrdUY_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\erHadqauC8A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\erHadqauC8A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eRiGPyewJpI_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eRiGPyewJpI_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Es9FNjZ-SHI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Es9FNjZ-SHI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ESbtW0CUmp4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ESbtW0CUmp4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eSesh6vnek8_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eSesh6vnek8_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ESFANzZTdYM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ESFANzZTdYM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EsHXnkZ_W2c_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EsHXnkZ_W2c_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eSIxvnEQ6R0_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eSIxvnEQ6R0_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\esIzFH7vYLY_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\esIzFH7vYLY_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eSsadT6mh7g_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eSsadT6mh7g_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EsssGCL-Axw_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EsssGCL-Axw_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eStzDzEopDI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eStzDzEopDI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ET6HVZ8muVE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ET6HVZ8muVE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ET7yQfaiF_8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ET7yQfaiF_8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ETl0hYRlVmg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ETl0hYRlVmg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EtmKuWPpjG0_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EtmKuWPpjG0_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\etmmUjsRNRs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\etmmUjsRNRs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\euAQCWBX6ns_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\euAQCWBX6ns_40-50.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EUmfsCvmkgo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EUmfsCvmkgo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EUNTykrvpok_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EUNTykrvpok_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Euu6zlJQSD0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Euu6zlJQSD0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eUZ-v8GEcNk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eUZ-v8GEcNk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\evG8CQRCdV8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\evG8CQRCdV8_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eVjcfdxSFKQ_550-560.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eVjcfdxSFKQ_550-560.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\evy2azZk3kE_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\evy2azZk3kE_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ev_YCCuGVSs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ev_YCCuGVSs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eW8se7t0s-U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eW8se7t0s-U_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EwDiNj_5PEg_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EwDiNj_5PEg_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eWGGj4duzIo_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eWGGj4duzIo_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eWNERam16Hg_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eWNERam16Hg_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EwoCbcSXlSM_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EwoCbcSXlSM_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eWqD_VOympU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eWqD_VOympU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eWSA0xubW7I_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eWSA0xubW7I_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eWwWwoQLtVg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eWwWwoQLtVg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ex0ukzO5z9M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ex0ukzO5z9M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ex18Xwznj60_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ex18Xwznj60_30-40.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eX1Hynef5Rc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eX1Hynef5Rc_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\exD5okdopWc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\exD5okdopWc_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ExghbCGRBx0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ExghbCGRBx0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eXrJL1VUQNE_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eXrJL1VUQNE_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EXRKJRL0TDU_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EXRKJRL0TDU_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eXWBC3XfiXY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eXWBC3XfiXY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eyFBIA_HOmE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eyFBIA_HOmE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eYngZ5It0b8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eYngZ5It0b8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EyO5vB4eqo0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EyO5vB4eqo0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eyY6f4iQDH4_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eyY6f4iQDH4_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eZ8yopmYtPM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eZ8yopmYtPM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EZAwPnGOJPE_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EZAwPnGOJPE_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ezayBI_xOVk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ezayBI_xOVk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EZb1wQsg6CU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EZb1wQsg6CU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eZC1AP_JjXM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eZC1AP_JjXM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EZi80fUpBfE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EZi80fUpBfE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EZJzzWEDtQo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EZJzzWEDtQo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eZNnuRvrZDU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eZNnuRvrZDU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ezodz2aZnzQ_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ezodz2aZnzQ_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\EzP7PB2x670_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\EzP7PB2x670_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\eZrrzGgTpfk_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\eZrrzGgTpfk_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E_34BmDVnOI_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E_34BmDVnOI_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E_IG2ubeTME_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E_IG2ubeTME_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\E_kgtQ93Q1s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\E_kgtQ93Q1s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\e_W17jp40G4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\e_W17jp40G4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f1NV9qTjOv8_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f1NV9qTjOv8_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f1UMPPWbCrU_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f1UMPPWbCrU_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F1uXNtotVsg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F1uXNtotVsg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F1X7egd8Us0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F1X7egd8Us0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f1_YKSYgtbI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f1_YKSYgtbI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F2ekiX14ID4_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F2ekiX14ID4_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f3l6KnC8930_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f3l6KnC8930_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F3uf_RleI3E_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F3uf_RleI3E_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f4jW2H6V7gk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f4jW2H6V7gk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F5e-SEICJP4_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F5e-SEICJP4_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f5eMUCSZCjc_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f5eMUCSZCjc_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F5xnAYHuGlo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F5xnAYHuGlo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F5zDEHggiMg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F5zDEHggiMg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f6H0TMWDaZg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f6H0TMWDaZg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f6wrXzvByrg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f6wrXzvByrg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F7JllgnefSI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F7JllgnefSI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f7OQTtTdgrA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f7OQTtTdgrA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F7Y1T-rQ2JU_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F7Y1T-rQ2JU_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f8fUFmjqXZo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f8fUFmjqXZo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F8MCOgWhgvY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F8MCOgWhgvY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f8nysknTFUo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f8nysknTFUo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f8QGA4vN6HY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f8QGA4vN6HY_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F8wGRd9332s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F8wGRd9332s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\F9LJIyqQFe8_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\F9LJIyqQFe8_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fa0lR26K23E_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fa0lR26K23E_450-460.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Fa1c4qfBqzE_22-32.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Fa1c4qfBqzE_22-32.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Fa1KdG8niq0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Fa1KdG8niq0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FaD9qs2ACpI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FaD9qs2ACpI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fAfk9yrGhWw_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fAfk9yrGhWw_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FAhfuP_xh5Y_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FAhfuP_xh5Y_450-460.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fAHYe-qmFnU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fAHYe-qmFnU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FaRrq7cYu84_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FaRrq7cYu84_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fBEGBuO3RXg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fBEGBuO3RXg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FbV2Lgt3H1Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FbV2Lgt3H1Q_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FBXBDe3OU5s_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FBXBDe3OU5s_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fcpVyvn5vKk_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fcpVyvn5vKk_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FCvs17jk10A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FCvs17jk10A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FcwWl5JBnoU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FcwWl5JBnoU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FCzMqo8kh1o_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FCzMqo8kh1o_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fD1xB9lDbPQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fD1xB9lDbPQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FDO5BekX478_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FDO5BekX478_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FdPaa6WR2F8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FdPaa6WR2F8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FdvGsAq99r0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FdvGsAq99r0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FDYIdBZUl2Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FDYIdBZUl2Y_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fe10sxFSz_I_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fe10sxFSz_I_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fE7tbn6Fnw4_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fE7tbn6Fnw4_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\feC0L9MtghM_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\feC0L9MtghM_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fEfe8jznp5Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fEfe8jznp5Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fEFeRM5bT8o_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fEFeRM5bT8o_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fEHsR679g1M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fEHsR679g1M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FENJIDecy5s_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FENJIDecy5s_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fer_4HvG3aY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fer_4HvG3aY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fESsP6ZnVKA_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fESsP6ZnVKA_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FEuXIeWoCQQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FEuXIeWoCQQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FF0VaBxb27w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FF0VaBxb27w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fFYMsrMGQtU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fFYMsrMGQtU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Fg8yzA7zifw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Fg8yzA7zifw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fgCTFyzKQtk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fgCTFyzKQtk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FGoDfNZezh0_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FGoDfNZezh0_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FgUSmmTEE3M_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FgUSmmTEE3M_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FGZ0sLt4dXA_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FGZ0sLt4dXA_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Fh53p0Tnnxg_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Fh53p0Tnnxg_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fH9CY48sfJY_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fH9CY48sfJY_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FHC7gN3NnX8_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FHC7gN3NnX8_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fHNAxa0QaOM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fHNAxa0QaOM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fhs7AkJsYao_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fhs7AkJsYao_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fhWzjWZqzvs_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fhWzjWZqzvs_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fiAcNMpd2vM_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fiAcNMpd2vM_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FiKY19GK6-8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FiKY19GK6-8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FI_Dl0Cmd38_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FI_Dl0Cmd38_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fJ6ZeWYfLjA_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fJ6ZeWYfLjA_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fjj9NJX8GB0_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fjj9NJX8GB0_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fjxD32KIHgE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fjxD32KIHgE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FKBryvLMTY4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FKBryvLMTY4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FKChZXXhufE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FKChZXXhufE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fkgaF6Oj5Q4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fkgaF6Oj5Q4_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fKni4PUSxu4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fKni4PUSxu4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FkpJaXzgMBQ_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FkpJaXzgMBQ_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FLFmcZiRuzU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FLFmcZiRuzU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FLJPxFCPeDY_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FLJPxFCPeDY_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\flLjMZMydXc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\flLjMZMydXc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Fm6ss1PBC1Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Fm6ss1PBC1Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fmHbWq-7-iQ_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fmHbWq-7-iQ_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FMjUGdTn7lU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FMjUGdTn7lU_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FMr1WHtXJbc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FMr1WHtXJbc_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FNnKFUkFJ5M_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FNnKFUkFJ5M_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FoFMRXlNJ6Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FoFMRXlNJ6Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fow1TC_MpHs_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fow1TC_MpHs_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fp0oCFL6w4o_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fp0oCFL6w4o_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fpbtmY9VfCw_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fpbtmY9VfCw_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fpdgtpBOh-c_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fpdgtpBOh-c_40-50.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fPIG7nrpgec_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fPIG7nrpgec_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fpVlYpgTKZI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fpVlYpgTKZI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fPYeqTFc3IQ_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fPYeqTFc3IQ_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fPYxUa1ZVAY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fPYxUa1ZVAY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fQiSoVDFRjo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fQiSoVDFRjo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fRpJfrfjoZo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fRpJfrfjoZo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\frqnZb8Ssjo_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\frqnZb8Ssjo_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FRZzUh9hcTo_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FRZzUh9hcTo_130-140.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FscE_AHEmFk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FscE_AHEmFk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FsCQmTluSDw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FsCQmTluSDw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fSJ4qAPHaVM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fSJ4qAPHaVM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Fsm-xDmyFKg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Fsm-xDmyFKg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FSQ3E4XbpPU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FSQ3E4XbpPU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fsTVRca31nI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fsTVRca31nI_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Fsv_syCvzsc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Fsv_syCvzsc_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fsXfBoNcLeM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fsXfBoNcLeM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fsXQHyg5qDI_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fsXQHyg5qDI_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ftaHv79hRoY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ftaHv79hRoY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FTdcanPJw6E_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FTdcanPJw6E_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FteW_2gNtD4_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FteW_2gNtD4_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fTGZEmn3BY4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fTGZEmn3BY4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ftKCLRd9_no_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ftKCLRd9_no_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fU9woCZqemw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fU9woCZqemw_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fUC45bzOOJw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fUC45bzOOJw_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FvdUm5j_oA0_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FvdUm5j_oA0_190-200.mid\n","1/1 [==============================] - 0s 11ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fvhbI-7e89s_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fvhbI-7e89s_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fvpDYGzdRmo_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fvpDYGzdRmo_120-130.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fvTh5m9RHZw_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fvTh5m9RHZw_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fvw3Bi0GONA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fvw3Bi0GONA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fWfQxB2pVrc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fWfQxB2pVrc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fWu8vVSSkNQ_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fWu8vVSSkNQ_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fWwV7o4VjEQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fWwV7o4VjEQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fWypK9RHJJI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fWypK9RHJJI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fw_cFbj9eHQ_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fw_cFbj9eHQ_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fxdWwzdeY_o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fxdWwzdeY_o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FxeA9blzUD8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FxeA9blzUD8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fXhN3_gGpQw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fXhN3_gGpQw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FxpV97ILuSo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FxpV97ILuSo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FXQxobF8FWw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FXQxobF8FWw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fxznho_kNPY_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fxznho_kNPY_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Fy51z2RwH3E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Fy51z2RwH3E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FY8bZRm_QiE_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FY8bZRm_QiE_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FYFapDVOFHg_440-450.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FYFapDVOFHg_440-450.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fYk2U9yJvps_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fYk2U9yJvps_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fyLctn3jNUs_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fyLctn3jNUs_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FYux89o7Hhk_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FYux89o7Hhk_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fYvUB-qy4IM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fYvUB-qy4IM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\FzG8ZQAhKrE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\FzG8ZQAhKrE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\fZjQBgPD1Ys_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\fZjQBgPD1Ys_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\f_NR19LpA_E_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\f_NR19LpA_E_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G-5UYGccne4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G-5UYGccne4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G-7BfzMgZL8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G-7BfzMgZL8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g-9SK0or81c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g-9SK0or81c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g-ghr5fAVpE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g-ghr5fAVpE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g-ZOluGhMoA_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g-ZOluGhMoA_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g0aOPWwNMFQ_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g0aOPWwNMFQ_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g0AXzsecS5M_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g0AXzsecS5M_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g0scnRzoo9M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g0scnRzoo9M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g0WLA0BKxOc_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g0WLA0BKxOc_240-250.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G13NEVAm6-o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G13NEVAm6-o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G18Nt0ZeEJQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G18Nt0ZeEJQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G22YfD5xxMU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G22YfD5xxMU_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g2H8i_TuhgI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g2H8i_TuhgI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G2JDDwIuNrQ_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G2JDDwIuNrQ_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G2uCAwYS6w0_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G2uCAwYS6w0_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G4fTKotMoWI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G4fTKotMoWI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g4xhZgKwiNo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g4xhZgKwiNo_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G6A9NKeK8ko_580-590.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G6A9NKeK8ko_580-590.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g6f-LxiT9Eo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g6f-LxiT9Eo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G6ihF82lvEA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G6ihF82lvEA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g75kz9ffcg0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g75kz9ffcg0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G7pD1K3jYg4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G7pD1K3jYg4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g8XTU3OalGs_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g8XTU3OalGs_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G9gsCU85c8k_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G9gsCU85c8k_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GaNjXwElAUE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GaNjXwElAUE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GAoGADilmV8_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GAoGADilmV8_450-460.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GAohd8KvONo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GAohd8KvONo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gAQiARaliPA_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gAQiARaliPA_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gAURHUoIK0M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gAURHUoIK0M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gb8PG-5i5YI_510-520.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gb8PG-5i5YI_510-520.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GbjtSTTEFK4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GbjtSTTEFK4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GBLKj2d0iC4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GBLKj2d0iC4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GBMlv6j0WJ8_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GBMlv6j0WJ8_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GBsate-JQAo_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GBsate-JQAo_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gBuLpP4klvI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gBuLpP4klvI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Gc8xf7CJiFY_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Gc8xf7CJiFY_240-250.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GcbCOmNiVm8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GcbCOmNiVm8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gcdqffsCWI8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gcdqffsCWI8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GcnLApOeCh0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GcnLApOeCh0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GcOOmVSM8Uw_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GcOOmVSM8Uw_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GcqCHmHXEjo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GcqCHmHXEjo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gCSShNsw-_A_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gCSShNsw-_A_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GcYeBWujhjw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GcYeBWujhjw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gD6UoStqCsg_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gD6UoStqCsg_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Gde1fn1Y1uM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Gde1fn1Y1uM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gDm4IphrlYg_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gDm4IphrlYg_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gDnJoHpSL4M_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gDnJoHpSL4M_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gDzi8N3BYMw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gDzi8N3BYMw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gEvCUcZ6w88_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gEvCUcZ6w88_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gEYTdeQiFv8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gEYTdeQiFv8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GF8QWSW0UbY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GF8QWSW0UbY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GFbSHWBjuuQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GFbSHWBjuuQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gffng5G4X4w_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gffng5G4X4w_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GFGwPa9d9XQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GFGwPa9d9XQ_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gfIqYbQQq10_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gfIqYbQQq10_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GFJNgqcX7u0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GFJNgqcX7u0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GFT6TeQx_0U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GFT6TeQx_0U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gFxLnprPgv4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gFxLnprPgv4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GG6XkHATIyw_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GG6XkHATIyw_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ggBivmG6yHQ_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ggBivmG6yHQ_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GglIHiqClGM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GglIHiqClGM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Gh4KBdcCU64_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Gh4KBdcCU64_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GHQlBD-6rkA_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GHQlBD-6rkA_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ghW2xZMvpIQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ghW2xZMvpIQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gHWMKew9Xq0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gHWMKew9Xq0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GHyUAl9Yaos_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GHyUAl9Yaos_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gI-ovjTWBzo_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gI-ovjTWBzo_340-350.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gigxzYegRqM_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gigxzYegRqM_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GinP_ZRgAoY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GinP_ZRgAoY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\giPa2vVEyVc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\giPa2vVEyVc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gIQ4QrKXjCc_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gIQ4QrKXjCc_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GiTmjE7az74_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GiTmjE7az74_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Gj6etuzTWlQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Gj6etuzTWlQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gjJWbtCShqo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gjJWbtCShqo_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gjujPd1lP8E_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gjujPd1lP8E_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GJYhDjThTHM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GJYhDjThTHM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gkMbHlNAFig_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gkMbHlNAFig_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GLIXnXZEOxY_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GLIXnXZEOxY_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GMFWnMRtfNI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GMFWnMRtfNI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gMgN50wSnNc_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gMgN50wSnNc_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GmGWvBNO8JI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GmGWvBNO8JI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GMtb7U-8IYM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GMtb7U-8IYM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gNjeps3EbJA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gNjeps3EbJA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GNjsxLdSwHI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GNjsxLdSwHI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gNpzuFPu6q8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gNpzuFPu6q8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GNu_hiHGEp0_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GNu_hiHGEp0_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gOhONZR_F7c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gOhONZR_F7c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GopccU3Am1w_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GopccU3Am1w_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GOTy3yhCylw_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GOTy3yhCylw_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GOujNXEtDmg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GOujNXEtDmg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Gow0TlxIx7U_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Gow0TlxIx7U_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gp1DYuoQH08_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gp1DYuoQH08_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gp7j9o2x9co_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gp7j9o2x9co_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gpEU6RafUf0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gpEU6RafUf0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gpNzFsxwy5k_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gpNzFsxwy5k_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GPSqrciDLog_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GPSqrciDLog_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GPwzpw_47Dg_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GPwzpw_47Dg_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GQbUpJFArKI_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GQbUpJFArKI_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GQbytKkt0tg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GQbytKkt0tg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gqkqzqCHM3A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gqkqzqCHM3A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gqROBgF7_DU_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gqROBgF7_DU_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GQz_u0Vc8Os_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GQz_u0Vc8Os_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GrbrWNohr6Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GrbrWNohr6Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GRdzFvQezUE_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GRdzFvQezUE_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\grE0lwTsSPg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\grE0lwTsSPg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gRGiTueWUVI_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gRGiTueWUVI_340-350.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gRn6OjQf2ZQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gRn6OjQf2ZQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Grtmre_r9yI_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Grtmre_r9yI_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GSAMEMX_oAg_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GSAMEMX_oAg_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gsBXngKgy-Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gsBXngKgy-Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gsEk62Efbh4_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gsEk62Efbh4_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gsIB8HjsRtw_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gsIB8HjsRtw_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GT9g4uqK9G8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GT9g4uqK9G8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gTO00a-LFYs_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gTO00a-LFYs_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gTX4SG70cEY_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gTX4SG70cEY_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GuHDy--gWiM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GuHDy--gWiM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GuJdy864xWM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GuJdy864xWM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GuQFhmGqdog_62-72.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GuQFhmGqdog_62-72.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\guRyU4B5LlA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\guRyU4B5LlA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Guu30szkA-0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Guu30szkA-0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GUwBLItoJXk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GUwBLItoJXk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GuYRF0no7hw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GuYRF0no7hw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\guYWKdxrtIg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\guYWKdxrtIg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gVMoI2ukbtc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gVMoI2ukbtc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gW33LYEvoaw_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gW33LYEvoaw_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GW6pti04qIo_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GW6pti04qIo_130-140.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gwBfZJ5IGOA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gwBfZJ5IGOA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GWcMqKYOJR4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GWcMqKYOJR4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GWcTd6XrQj4_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GWcTd6XrQj4_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gWRfk8nCcPs_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gWRfk8nCcPs_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GwTXkfuc5v8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GwTXkfuc5v8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GwxSvUoYSZg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GwxSvUoYSZg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GX-QhoihLeI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GX-QhoihLeI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gX9OuOKLLTQ_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gX9OuOKLLTQ_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gxAyZk01T3k_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gxAyZk01T3k_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GxeDIuOzxmU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GxeDIuOzxmU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GXLeUXSVFYU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GXLeUXSVFYU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gXOyw8a4_Xs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gXOyw8a4_Xs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gXzqZIoM5g8_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gXzqZIoM5g8_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gxzU5EqNL14_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gxzU5EqNL14_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gy6R280ZUMQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gy6R280ZUMQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GYCfrx0ruz4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GYCfrx0ruz4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GYx6HNQbP1w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GYx6HNQbP1w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GyxH8ep_Vx8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GyxH8ep_Vx8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\gz-4W-uEzhc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\gz-4W-uEzhc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Gz8RlHf3Czs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Gz8RlHf3Czs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\GzRvq0gJbj0_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\GzRvq0gJbj0_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\g_bgmnJ1b_g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\g_bgmnJ1b_g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\G_iJif-fC6E_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\G_iJif-fC6E_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\h-3DrDQC62k_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\h-3DrDQC62k_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\h0-6U948u7Y_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\h0-6U948u7Y_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H18aK9HhNSM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H18aK9HhNSM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\h2f_CKjQQg8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\h2f_CKjQQg8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H4rdJlSSt5Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H4rdJlSSt5Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H4tyvJJzSDk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H4tyvJJzSDk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\h542YbZuwkQ_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\h542YbZuwkQ_60-70.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H6qzijVEqZQ_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H6qzijVEqZQ_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H6rZwBc6aNM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H6rZwBc6aNM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\h6Y0KDtUNHw_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\h6Y0KDtUNHw_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H6Y_7Ax34-g_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H6Y_7Ax34-g_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\h7DOBV43UPQ_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\h7DOBV43UPQ_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\h7ty6D1LunA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\h7ty6D1LunA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\h9zF09TMgLU_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\h9zF09TMgLU_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ha-FS_CHmGw_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ha-FS_CHmGw_60-70.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HAEoz3VbaP8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HAEoz3VbaP8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hbCaMcbT8to_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hbCaMcbT8to_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hbqdthlv6CU_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hbqdthlv6CU_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hBQFoDI3NMI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hBQFoDI3NMI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hBT0bbJl1dU_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hBT0bbJl1dU_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HbX1ZIuD0ac_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HbX1ZIuD0ac_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HCCGZh-TxK0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HCCGZh-TxK0_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hCELSy7hVKE_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hCELSy7hVKE_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hCIB1E60Nbw_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hCIB1E60Nbw_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hc_UM8l_sTg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hc_UM8l_sTg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hdko95EitpI_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hdko95EitpI_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hdlnugbWjKA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hdlnugbWjKA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HdRPdh-cSTw_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HdRPdh-cSTw_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hDsA_ky9Hfw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hDsA_ky9Hfw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HDSV7Pzq8CA_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HDSV7Pzq8CA_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hDzmNYd_eaA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hDzmNYd_eaA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\He63KV_9Pwg_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\He63KV_9Pwg_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HEclHruM37s_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HEclHruM37s_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HEhogaw0vUg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HEhogaw0vUg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HEk4fx_XNNE_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HEk4fx_XNNE_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\heZw1TTrtTU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\heZw1TTrtTU_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HfBh3lZZi8Q_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HfBh3lZZi8Q_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HFH9tcIK_PM_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HFH9tcIK_PM_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hFj0KUzofNg_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hFj0KUzofNg_80-90.mid\n","31/31 [==============================] - 1s 17ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HflVPAOVL7U_2-12.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HflVPAOVL7U_2-12.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hFqZZrj0rnM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hFqZZrj0rnM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HFVM5pVTwkM_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HFVM5pVTwkM_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HfzEa06vDLg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HfzEa06vDLg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hgGCfJoYDUU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hgGCfJoYDUU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hgitRq_0410_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hgitRq_0410_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HH3ryAEP308_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HH3ryAEP308_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hH6thMA3640_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hH6thMA3640_120-130.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hHb0Eq1I7Fk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hHb0Eq1I7Fk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hheF-AgCqIg_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hheF-AgCqIg_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hhohfEC82JI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hhohfEC82JI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hHqrcLiKJRg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hHqrcLiKJRg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HhQTvaZtURY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HhQTvaZtURY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hHS5C0RKa8A_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hHS5C0RKa8A_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HHTgjmgTV6c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HHTgjmgTV6c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hhU78ykPr5w_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hhU78ykPr5w_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hhVFK9tYu84_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hhVFK9tYu84_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HHZGjS4g-w4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HHZGjS4g-w4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HIDXdH6R6T8_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HIDXdH6R6T8_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hIEj8msjg8E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hIEj8msjg8E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hij_QxDkIJI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hij_QxDkIJI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hj7VJnNq6A4_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hj7VJnNq6A4_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hjrl1KHEuqE_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hjrl1KHEuqE_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HJuR9WJ1iRY_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HJuR9WJ1iRY_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hk-1KRWTM-4_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hk-1KRWTM-4_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HkCYA4ax4jI_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HkCYA4ax4jI_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hKSg3zFB2dE_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hKSg3zFB2dE_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hkWcUtga1lw_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hkWcUtga1lw_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hkWOAj09_dY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hkWOAj09_dY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hl8OrRlMwi4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hl8OrRlMwi4_10-20.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hlbjpc48Vrs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hlbjpc48Vrs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hLn4HokDEmM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hLn4HokDEmM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hlquKjPgxmY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hlquKjPgxmY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HLsRePLObfI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HLsRePLObfI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hLwMYygjRfI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hLwMYygjRfI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HLz3N5nG8fQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HLz3N5nG8fQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hm0SeoNSGkc_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hm0SeoNSGkc_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hM88FG1_D5Q_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hM88FG1_D5Q_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HMJe5jS0Yt4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HMJe5jS0Yt4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hmkPWxTIwwU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hmkPWxTIwwU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HMQfp_qtF-M_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HMQfp_qtF-M_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HNf9eHqDT1A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HNf9eHqDT1A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hnk45Z0EAxg_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hnk45Z0EAxg_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hnlVKC7rxdg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hnlVKC7rxdg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hob0LAu8afQ_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hob0LAu8afQ_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HOIIp5NyFx0_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HOIIp5NyFx0_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HOkuea1wExA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HOkuea1wExA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hoPnrbKOEl8_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hoPnrbKOEl8_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hOSzGYKaJGE_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hOSzGYKaJGE_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hp-lgcs4VXY_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hp-lgcs4VXY_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hpiFoinUgvY_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hpiFoinUgvY_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HpkPTa1fQDE_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HpkPTa1fQDE_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hQ5OBio4Cy0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hQ5OBio4Cy0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HQ9HlWProm0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HQ9HlWProm0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HQb2jhmw1BE_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HQb2jhmw1BE_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hqCJarP-nVI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hqCJarP-nVI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hqQvatf1RUY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hqQvatf1RUY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hrCf8rMBtA8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hrCf8rMBtA8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hrgl_1rGGU4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hrgl_1rGGU4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hrOP9swUpyA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hrOP9swUpyA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HrPnGYGrvm0_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HrPnGYGrvm0_100-110.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hRQJgZVxRX0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hRQJgZVxRX0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HRVVqstIabc_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HRVVqstIabc_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HrwpdRe7meM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HrwpdRe7meM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HrxfNVYirCo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HrxfNVYirCo_30-40.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HRxTN4TH-80_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HRxTN4TH-80_0-10.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hSK405L-DlQ_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hSK405L-DlQ_170-180.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HSrzR9hhEe8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HSrzR9hhEe8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hSSzn4bIwZg_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hSSzn4bIwZg_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HS_ikHx4LIQ_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HS_ikHx4LIQ_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hTAWbHXCJ2A_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hTAWbHXCJ2A_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HtCkwxfAmzw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HtCkwxfAmzw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hTlIqICkbW8_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hTlIqICkbW8_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hTNKYJ6suII_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hTNKYJ6suII_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hTPxqUtlLdo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hTPxqUtlLdo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HTQySJM4Jhg_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HTQySJM4Jhg_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HtRjRuKnvjI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HtRjRuKnvjI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HtSznF9_784_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HtSznF9_784_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HtXtfCR-MUg_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HtXtfCR-MUg_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hu5pjj1KzK8_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hu5pjj1KzK8_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hu6sChY-Yps_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hu6sChY-Yps_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HU7oqkJeItQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HU7oqkJeItQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hUcuXIvDN2E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hUcuXIvDN2E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HuVgc2jf0Ec_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HuVgc2jf0Ec_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HVA9-fjtv6U_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HVA9-fjtv6U_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hvmCuosF0Xo_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hvmCuosF0Xo_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HvOSaS8sXQM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HvOSaS8sXQM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hVPQu1UJ2N8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hVPQu1UJ2N8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HVsXJDR1_Lw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HVsXJDR1_Lw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HvuHSr_yncE_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HvuHSr_yncE_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hVVrl9FkKnY_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hVVrl9FkKnY_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hwe6y-jSqdQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hwe6y-jSqdQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HwGK5RvNOFI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HwGK5RvNOFI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hWiAoE4u4y8_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hWiAoE4u4y8_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hwSOjoHFLn4_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hwSOjoHFLn4_40-50.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HWZdPxRzCWs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HWZdPxRzCWs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Hxf1seOpijE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Hxf1seOpijE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HXG8DnTpyPc_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HXG8DnTpyPc_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hXLo1l5gS-I_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hXLo1l5gS-I_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HXwX9f9ugZ4_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HXwX9f9ugZ4_340-350.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HY1KdNS19CM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HY1KdNS19CM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hyGuS5WiPk8_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hyGuS5WiPk8_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HyJ2YaNrA3U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HyJ2YaNrA3U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HYjSrwSm0T4_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HYjSrwSm0T4_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hYlSisv-VRU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hYlSisv-VRU_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HyXMWRU9Owc_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HyXMWRU9Owc_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hYy0na5oUzE_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hYy0na5oUzE_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HyyHwIK9SSI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HyyHwIK9SSI_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hZfCziBaGTI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hZfCziBaGTI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hzr2aY33EuI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hzr2aY33EuI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\HzXWXYxXyYA_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\HzXWXYxXyYA_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\hzznbzry5R8_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\hzznbzry5R8_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H_2ZPxy80Eo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H_2ZPxy80Eo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H_5wh4aMQe0_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H_5wh4aMQe0_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\H_He9_zHk8I_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\H_He9_zHk8I_80-90.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I-C14nCneBs_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I-C14nCneBs_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I-xPuRe9vF0_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I-xPuRe9vF0_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I-XYm2Ck2r8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I-XYm2Ck2r8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I-Z3gB6pfIA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I-Z3gB6pfIA_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I06TOd9pXng_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I06TOd9pXng_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I0q3IGmTkRo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I0q3IGmTkRo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I0skZ6yT36E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I0skZ6yT36E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I11AcD1sGes_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I11AcD1sGes_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I1fcUe9MoMw_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I1fcUe9MoMw_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I1wakVlpP6M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I1wakVlpP6M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I368EWBLIs4_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I368EWBLIs4_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I3qbB4Kq3Y0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I3qbB4Kq3Y0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I4Jp0kB2Ns0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I4Jp0kB2Ns0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I4Rhe1XViYg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I4Rhe1XViYg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I5CBPhpimtg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I5CBPhpimtg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I5KHYgtrVBw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I5KHYgtrVBw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I5mESbabhZY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I5mESbabhZY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i6dFcfV64RE_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i6dFcfV64RE_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I6eU2qRjJ7Y_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I6eU2qRjJ7Y_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i6k1yiyO5jQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i6k1yiyO5jQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I6wri5XQQbU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I6wri5XQQbU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i6WtNBpRll0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i6WtNBpRll0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i70a79YhlMk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i70a79YhlMk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i8bt6Mb0rUc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i8bt6Mb0rUc_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i8PFu7AiwaE_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i8PFu7AiwaE_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ia6-da2KdI0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ia6-da2KdI0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iaDrtIon6FU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iaDrtIon6FU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IAeYandwJqc_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IAeYandwJqc_70-80.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iaonijK95qA_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iaonijK95qA_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iaRDUksPv50_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iaRDUksPv50_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ib8pMT_ug7o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ib8pMT_ug7o_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IbD0zpcimgM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IbD0zpcimgM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iBezxlI_f_c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iBezxlI_f_c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iBh37YAaHMU_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iBh37YAaHMU_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iBH5X5SKirU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iBH5X5SKirU_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iCHskFoUvbw_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iCHskFoUvbw_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iCIa_pmLDqs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iCIa_pmLDqs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\icomsHXY8YA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\icomsHXY8YA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IcPbxJRbe5g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IcPbxJRbe5g_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ICtri0ElFZc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ICtri0ElFZc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IC_Wpalzzm8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IC_Wpalzzm8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\id5ibIqjRto_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\id5ibIqjRto_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IDHHAwqDpzU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IDHHAwqDpzU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\idUZsNLnyDg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\idUZsNLnyDg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iDvva_WCo-I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iDvva_WCo-I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ie5FO_BetOE_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ie5FO_BetOE_500-510.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iEcWlreXhGc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iEcWlreXhGc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ieef9l-gWN8_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ieef9l-gWN8_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ieEPKa3HiGo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ieEPKa3HiGo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iEMTTKA7NxU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iEMTTKA7NxU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IePfzUzlDng_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IePfzUzlDng_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iePMcLYozYY_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iePMcLYozYY_90-100.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iEQwupwwp0s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iEQwupwwp0s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IEVVHo9nr7g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IEVVHo9nr7g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ife1WaGirdQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ife1WaGirdQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IFimpFwvbz8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IFimpFwvbz8_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iFSaNmZyPQo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iFSaNmZyPQo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IFumVgqOVaM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IFumVgqOVaM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iFWtsT5zRKo_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iFWtsT5zRKo_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IGAzIIZRczw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IGAzIIZRczw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IGyDtKAU1u8_550-560.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IGyDtKAU1u8_550-560.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ihCl2ImrOYE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ihCl2ImrOYE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ihJT65fZaHY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ihJT65fZaHY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\II1oyaWPiD0_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\II1oyaWPiD0_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IiBgER0W8iA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IiBgER0W8iA_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IiJciyiQBDw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IiJciyiQBDw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IIK0EuHyb6w_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IIK0EuHyb6w_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IISJXKl1Ih4_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IISJXKl1Ih4_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IizUHzmcPGA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IizUHzmcPGA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ij1-640aafg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ij1-640aafg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IjP5kKfgBiI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IjP5kKfgBiI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IJw2o_Yg00Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IJw2o_Yg00Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ik-fXNjxw58_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ik-fXNjxw58_0-10.mid\n","22/32 [===================>..........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ikdb_jA9ehU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ikdb_jA9ehU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ikEuQPSBY-0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ikEuQPSBY-0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ikJKSqnTylI_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ikJKSqnTylI_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IKq2OF8jq1c_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IKq2OF8jq1c_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IL1n6jzABVw_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IL1n6jzABVw_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ILE12hEW5Ck_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ILE12hEW5Ck_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iLIBaMceZQc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iLIBaMceZQc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IlUcHzBzZvg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IlUcHzBzZvg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ime3FHuQG4k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ime3FHuQG4k_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\imIFtW4O5S0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\imIFtW4O5S0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iMmYVLSb1IY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iMmYVLSb1IY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IMnh-TIyFuE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IMnh-TIyFuE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iMTHDuW_xKc_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iMTHDuW_xKc_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\In44gO8Ej90_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\In44gO8Ej90_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\INBx8CrIWcg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\INBx8CrIWcg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\InKK8z21UYo_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\InKK8z21UYo_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\InQs7K9MqaI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\InQs7K9MqaI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Inuq5W98ktA_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Inuq5W98ktA_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IO5QJRyoqO8_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IO5QJRyoqO8_290-300.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IOzWDVGWRng_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IOzWDVGWRng_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iP46w2o_HCk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iP46w2o_HCk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IPO79GrOYjg_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IPO79GrOYjg_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ipow026xzVw_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ipow026xzVw_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IpYw4nKPx5o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IpYw4nKPx5o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iQ7qeIrssds_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iQ7qeIrssds_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iQAXwX28LLw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iQAXwX28LLw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IQbzpgmi4Ec_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IQbzpgmi4Ec_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iqEQBCrOLWc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iqEQBCrOLWc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iQfPmJ19ZUc_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iQfPmJ19ZUc_450-460.mid\n","22/32 [===================>..........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IqGB4nQIAcQ_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IqGB4nQIAcQ_210-220.mid\n","18/32 [===============>..............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iQJvAXOohoU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iQJvAXOohoU_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iqOPJWWKo90_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iqOPJWWKo90_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IqV9wp0IeAo_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IqV9wp0IeAo_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IQxr3xwAbKk_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IQxr3xwAbKk_40-50.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ir82jewhXCo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ir82jewhXCo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IrIKXhYuwuU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IrIKXhYuwuU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iS-iTbHndw8_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iS-iTbHndw8_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IS5V2yjPp3k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IS5V2yjPp3k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iS8YQGp2_ng_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iS8YQGp2_ng_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iSETDHfErjU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iSETDHfErjU_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iSw-5EjXgXc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iSw-5EjXgXc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ITg9o6Gwsbo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ITg9o6Gwsbo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ItLWKIhe58c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ItLWKIhe58c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ITq14s8h92I_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ITq14s8h92I_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ItSLkF6O3Mk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ItSLkF6O3Mk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ItstzW7xuDU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ItstzW7xuDU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\itT0_RhSipQ_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\itT0_RhSipQ_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iTV3Otwq_dI_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iTV3Otwq_dI_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iTWZsfVCyBs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iTWZsfVCyBs_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ITYv4126yhk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ITYv4126yhk_0-10.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IUD_ZYOh2MM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IUD_ZYOh2MM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iUHqyjf3NcQ_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iUHqyjf3NcQ_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IUjzBX2Qm4k_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IUjzBX2Qm4k_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iuNpXisjsLY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iuNpXisjsLY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iUxy2s5d60o_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iUxy2s5d60o_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iVBNoH6XgW4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iVBNoH6XgW4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IWbe-NSK6Ic_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IWbe-NSK6Ic_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IwdjPDw6o5I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IwdjPDw6o5I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IwobTmzjOiQ_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IwobTmzjOiQ_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IwqD859w2_E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IwqD859w2_E_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iX53Jb72Nwk_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iX53Jb72Nwk_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iX_a2Ct0ya8_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iX_a2Ct0ya8_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IYiHhVWrh0w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IYiHhVWrh0w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IyJ3a5uuCOs_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IyJ3a5uuCOs_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IYtQfDsFVfA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IYtQfDsFVfA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\IYumekd1VMg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\IYumekd1VMg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iYWvaxU5OXk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iYWvaxU5OXk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Iz611KubW70_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Iz611KubW70_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\iZjIuV_cTe8_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\iZjIuV_cTe8_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\izVCz3P43p8_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\izVCz3P43p8_10-20.mid\n","1/1 [==============================] - 0s 12ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I_a9OhfTcIc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I_a9OhfTcIc_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i_d4JFg-zT0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i_d4JFg-zT0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i_G_0vgEYJg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i_G_0vgEYJg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I_kUf7vgVNM_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I_kUf7vgVNM_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\i_NNY_mgxIs_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\i_NNY_mgxIs_40-50.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\I_wT76iYBdQ_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\I_wT76iYBdQ_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j-93krRXAaY_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j-93krRXAaY_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j-TVVmVmygg_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j-TVVmVmygg_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j0FynYzQvcM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j0FynYzQvcM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J0lA7ZDfPLE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J0lA7ZDfPLE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J0RzvGnQxD0_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J0RzvGnQxD0_60-70.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J0t4VMnXDNM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J0t4VMnXDNM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j0UMI2DrnMA_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j0UMI2DrnMA_130-140.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J1-Qvl7u2TI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J1-Qvl7u2TI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J1gZRam89EE_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J1gZRam89EE_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J1nIXpnMe1U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J1nIXpnMe1U_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J2BDMndrvhA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J2BDMndrvhA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J2R8Ab25reU_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J2R8Ab25reU_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j3a60_lwWjE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j3a60_lwWjE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j3lH_Tevw5o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j3lH_Tevw5o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j43Dwqzd8w8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j43Dwqzd8w8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J48F0e0guSQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J48F0e0guSQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J4DrdTy52kg_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J4DrdTy52kg_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J4tjy-0CNm4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J4tjy-0CNm4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j5R0hwX27Gk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j5R0hwX27Gk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j6O_U9EseKQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j6O_U9EseKQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J7d3nuS9wqg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J7d3nuS9wqg_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J7fVdG7Zd3A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J7fVdG7Zd3A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J7jVR6y6REA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J7jVR6y6REA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j8FYy5YfK7k_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j8FYy5YfK7k_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J8lCxfaiHeo_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J8lCxfaiHeo_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J8pkQfYlJA4_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J8pkQfYlJA4_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j8z9a9A8LV4_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j8z9a9A8LV4_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J9PJI1UwIQ4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J9PJI1UwIQ4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\j9UZv0GOJ_I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\j9UZv0GOJ_I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\J9ZlahUawkg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\J9ZlahUawkg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JaGUY5ULTok_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JaGUY5ULTok_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jaJdPUAv6N0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jaJdPUAv6N0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jbe3VM-5xdc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jbe3VM-5xdc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jBmP7xTI_TA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jBmP7xTI_TA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JbWaSZPOh18_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JbWaSZPOh18_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JC41M7RPSec_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JC41M7RPSec_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Jcd63Ev7JXA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Jcd63Ev7JXA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JCfZpSEH77Y_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JCfZpSEH77Y_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jcZQhxb5lyw_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jcZQhxb5lyw_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jD0nqkyuHPg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jD0nqkyuHPg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jd94Ox7KJ9Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jd94Ox7KJ9Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JD9LYReBGXU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JD9LYReBGXU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JDBu-3VCyWc_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JDBu-3VCyWc_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jdEbwMS9xqo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jdEbwMS9xqo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JDrnf3vldLw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JDrnf3vldLw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JDWPJ1AiDKc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JDWPJ1AiDKc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Jdy08IPLKdw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Jdy08IPLKdw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\je1amtXOKF4_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\je1amtXOKF4_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\je96vkMY60c_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\je96vkMY60c_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JEJLTct-014_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JEJLTct-014_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JFGNmPzPXeA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JFGNmPzPXeA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JFJuEOZx1K4_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JFJuEOZx1K4_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jfxTOlXF3Kk_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jfxTOlXF3Kk_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jHEBYrI8zHE_540-550.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jHEBYrI8zHE_540-550.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jhgX0OOoytQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jhgX0OOoytQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JHkcCXF5vII_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JHkcCXF5vII_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jhQpTVVUQ9E_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jhQpTVVUQ9E_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jhsce15byHc_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jhsce15byHc_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JHvLuYk6TfI_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JHvLuYk6TfI_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JI26wmUPcrM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JI26wmUPcrM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ji5wvUUQjHY_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ji5wvUUQjHY_450-460.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JIoA1KsfioQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JIoA1KsfioQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jIoDR_eskaU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jIoDR_eskaU_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JjF1G5wgcvY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JjF1G5wgcvY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jjg0TCq3wbY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jjg0TCq3wbY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jjNxc9Zf9s8_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jjNxc9Zf9s8_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Jjr0_CbcYdg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Jjr0_CbcYdg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jjYXRmE19lQ_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jjYXRmE19lQ_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JKbUVdMJAO8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JKbUVdMJAO8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JKihzveDE5g_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JKihzveDE5g_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jKjj66pRXZA_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jKjj66pRXZA_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JL4Z2_5Q7sU_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JL4Z2_5Q7sU_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JL9Xxzf9e2A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JL9Xxzf9e2A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jlIbJVfnHB4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jlIbJVfnHB4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jlmCu2GMoG4_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jlmCu2GMoG4_240-250.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JLYb7DwCaQU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JLYb7DwCaQU_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JlzlNpttvVM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JlzlNpttvVM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JmbrGzgxrJ4_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JmbrGzgxrJ4_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JnfMv9ti9Sw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JnfMv9ti9Sw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JNwt0afB1fQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JNwt0afB1fQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JN_VJCJhC4Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JN_VJCJhC4Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JoBRbtAnbVM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JoBRbtAnbVM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JOhK7oq9KtU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JOhK7oq9KtU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JOkuwbhMxbQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JOkuwbhMxbQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\joLyjgORwDo_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\joLyjgORwDo_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JorNR3IXDyc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JorNR3IXDyc_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jP4M9V_Ka8k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jP4M9V_Ka8k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JP637fg_ZC0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JP637fg_ZC0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jPBg5cR8XeA_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jPBg5cR8XeA_170-180.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JpMHnsdsCiY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JpMHnsdsCiY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jPOWgfA0zAo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jPOWgfA0zAo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jPROsr_K710_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jPROsr_K710_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JPZlyvPNZj4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JPZlyvPNZj4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Jq2w30NYstQ_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Jq2w30NYstQ_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JqmOqYtQqB8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JqmOqYtQqB8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jQYSfy4DzIc_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jQYSfy4DzIc_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JR-1k8GHYAw_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JR-1k8GHYAw_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JRmfjBDKCpE_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JRmfjBDKCpE_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JrOV2Xz2djA_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JrOV2Xz2djA_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jrwhxVnvMdk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jrwhxVnvMdk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jR_wBfxgZwE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jR_wBfxgZwE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jS9u6X6TQmk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jS9u6X6TQmk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JSdALuTneBM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JSdALuTneBM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Jsk3ZUGvP-o_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Jsk3ZUGvP-o_410-420.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JSLqi_TsMzs_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JSLqi_TsMzs_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JSqyTVjYY6k_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JSqyTVjYY6k_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Js_3Aa214xY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Js_3Aa214xY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jtwRKyQ8-lg_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jtwRKyQ8-lg_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JU4CZ-GApu4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JU4CZ-GApu4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JU6GUqRqbtI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JU6GUqRqbtI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jUJNETNCxh0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jUJNETNCxh0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JUrYWttZJBM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JUrYWttZJBM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JUwu4xOs8K4_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JUwu4xOs8K4_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jV8kq0MpWMU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jV8kq0MpWMU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Jvj2WqgVy78_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Jvj2WqgVy78_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JvqCsVj0I4k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JvqCsVj0I4k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JvvnL7UnCGA_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JvvnL7UnCGA_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JV_IOR3DqiM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JV_IOR3DqiM_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JWNWCKdfpzM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JWNWCKdfpzM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jWQu301CEp8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jWQu301CEp8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jWTm17KZGI8_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jWTm17KZGI8_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jx27p7k2lSw_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jx27p7k2lSw_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jXi1dFAB0n8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jXi1dFAB0n8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JXS5eW7g4HY_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JXS5eW7g4HY_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JxwRvkjNJQ0_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JxwRvkjNJQ0_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jy0gitU1BFA_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jy0gitU1BFA_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JYYfw3id3ek_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JYYfw3id3ek_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jZi0VVWt72E_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jZi0VVWt72E_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jzij1UX73kU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jzij1UX73kU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JzJCn-puzS4_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JzJCn-puzS4_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\jZkHpNnXLB0_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\jZkHpNnXLB0_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JZnOGRCBW0I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JZnOGRCBW0I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JzRb1OVpat0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JzRb1OVpat0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JZWJlUdYpCU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JZWJlUdYpCU_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\JZyw6YUsGzo_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\JZyw6YUsGzo_200-210.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K-0qmhvJyzE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K-0qmhvJyzE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k-89m72W0j8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k-89m72W0j8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k-J2-Ou1Fm8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k-J2-Ou1Fm8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K-zkbbliQcI_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K-zkbbliQcI_150-160.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K0x_DxNxtbk_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K0x_DxNxtbk_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K1PzpuR6CqY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K1PzpuR6CqY_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K2h6UiZSoZ4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K2h6UiZSoZ4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k2uiJXN3L6E_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k2uiJXN3L6E_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k3A5xX8yfig_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k3A5xX8yfig_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k4kbpRRRgcQ_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k4kbpRRRgcQ_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k4ttuqKjiw0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k4ttuqKjiw0_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K55v5p5DEPE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K55v5p5DEPE_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K5ilD6nEJ-g_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K5ilD6nEJ-g_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k5kPBsMFlOc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k5kPBsMFlOc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K63Z_abB314_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K63Z_abB314_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K6DSH7MSeOA_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K6DSH7MSeOA_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k6F3gc8f8kI_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k6F3gc8f8kI_150-160.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K6KbEnGnymk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K6KbEnGnymk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k8AE-vqWbm4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k8AE-vqWbm4_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K8On7nUJuP8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K8On7nUJuP8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k9w2aaNKenE_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k9w2aaNKenE_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K9zE9x2ccJk_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K9zE9x2ccJk_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kAE7Ceg4VgQ_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kAE7Ceg4VgQ_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KauCO8zH5bw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KauCO8zH5bw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KB4e9v_5uTE_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KB4e9v_5uTE_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KB79k456DhI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KB79k456DhI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kbAMGp-TKJo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kbAMGp-TKJo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kbCh5HrmgN0_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kbCh5HrmgN0_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KbDLu4VozGg_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KbDLu4VozGg_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kbquMoJrhC0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kbquMoJrhC0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KChjW89XOF0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KChjW89XOF0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kCsmvK06SCA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kCsmvK06SCA_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KCs_VPmsnKo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KCs_VPmsnKo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kcTwJwdLTSo_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kcTwJwdLTSo_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KCytKo5LzCc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KCytKo5LzCc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Kd7aHdOwh0I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Kd7aHdOwh0I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KdNhYvN4Xoo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KdNhYvN4Xoo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KduU8kmRsLg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KduU8kmRsLg_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KDuusOmEMHg_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KDuusOmEMHg_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kdxW11WBlQE_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kdxW11WBlQE_150-160.mid\n","31/31 [==============================] - 1s 19ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KDzy3ZL626U_11-21.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KDzy3ZL626U_11-21.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KE-TVQhdCbs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KE-TVQhdCbs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\keHCWa6XfGY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\keHCWa6XfGY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KEp2NhraIZI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KEp2NhraIZI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kepd6_X_vS4_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kepd6_X_vS4_310-320.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KeSbjmMeyrY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KeSbjmMeyrY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KfAq7kxHjPk_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KfAq7kxHjPk_130-140.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KFB1raoIhoU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KFB1raoIhoU_80-90.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KfLxBjl-aBU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KfLxBjl-aBU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kgf4GdKlSWs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kgf4GdKlSWs_30-40.mid\n","1/1 [==============================] - 0s 11ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KgMD2_Yhw7Y_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KgMD2_Yhw7Y_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kgvx9drZXpk_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kgvx9drZXpk_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kH-F9JzC7eE_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kH-F9JzC7eE_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kh6rmFg3U4k_480-490.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kh6rmFg3U4k_480-490.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KHjEIheD-Cg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KHjEIheD-Cg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\khQN5ylb3H0_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\khQN5ylb3H0_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\khVk4pTS0bE_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\khVk4pTS0bE_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KhXcEu7r6m8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KhXcEu7r6m8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ki7Bxz1CThI_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ki7Bxz1CThI_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kIEEDYowZhA_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kIEEDYowZhA_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KiFQFxJphjI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KiFQFxJphjI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KikHXfUanJk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KikHXfUanJk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kjcXM60HrRA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kjcXM60HrRA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KJHqQ5aKu8U_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KJHqQ5aKu8U_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KjJj5-HvSvQ_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KjJj5-HvSvQ_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kjmmzA6i5rk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kjmmzA6i5rk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KjMRf4egAyA_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KjMRf4egAyA_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kjn6I3AurgE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kjn6I3AurgE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kka6zUtE3h8_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kka6zUtE3h8_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KKgYvcfrxj4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KKgYvcfrxj4_110-120.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kKihNQ44dDQ_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kKihNQ44dDQ_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kkjNpwNcMWI_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kkjNpwNcMWI_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kko1uYyqJ_o_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kko1uYyqJ_o_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kkOGbgGJLF4_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kkOGbgGJLF4_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kKPGTMdz99A_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kKPGTMdz99A_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Kkqbi6c_40k_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Kkqbi6c_40k_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KlD1u-EDx_g_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KlD1u-EDx_g_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KLFoZA8btu4_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KLFoZA8btu4_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KlVO3gu-j70_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KlVO3gu-j70_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KmBaE7ozWow_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KmBaE7ozWow_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kMK10SknFAI_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kMK10SknFAI_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kMmjr8deHis_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kMmjr8deHis_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kmmK69N3Om0_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kmmK69N3Om0_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kMNL4Y4XMhc_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kMNL4Y4XMhc_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KMQmM12G9Z4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KMQmM12G9Z4_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kmZFn-CQ19A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kmZFn-CQ19A_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KN9vuaQvld0_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KN9vuaQvld0_10-20.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\knQuxZj9rTA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\knQuxZj9rTA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KnZeEWVHaLc_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KnZeEWVHaLc_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KoAGZ_dB8MM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KoAGZ_dB8MM_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KOb-tRHYK68_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KOb-tRHYK68_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kOBh4NZ4wZQ_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kOBh4NZ4wZQ_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Kojo5khAAS0_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Kojo5khAAS0_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KoP8T0QqzeM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KoP8T0QqzeM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kOREaTKeyZw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kOREaTKeyZw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kp5OxEzxuSg_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kp5OxEzxuSg_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KPG9s_s8siA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KPG9s_s8siA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KPnIFb7T7VM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KPnIFb7T7VM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KpRHRh9PaRU_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KpRHRh9PaRU_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kpsYSXR1wao_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kpsYSXR1wao_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KPymcVenomk_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KPymcVenomk_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Kqo7am5oq0U_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Kqo7am5oq0U_40-50.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KqtlecvEOGw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KqtlecvEOGw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kQw2NQ_eqyg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kQw2NQ_eqyg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kR2yBlL6nFU_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kR2yBlL6nFU_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KrK8Giu9ZUc_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KrK8Giu9ZUc_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KRKX_UtYV9c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KRKX_UtYV9c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KrmG43H1u70_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KrmG43H1u70_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kSdH9z8snac_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kSdH9z8snac_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ksImihlU3qM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ksImihlU3qM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kSKXtXXAD70_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kSKXtXXAD70_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KSye2ifWZ_Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KSye2ifWZ_Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ksYM8YzzWXo_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ksYM8YzzWXo_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kT0KMsfD4d8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kT0KMsfD4d8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kTBlMy4dtC0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kTBlMy4dtC0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KTqf_FXZygM_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KTqf_FXZygM_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ktTrTDQidsE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ktTrTDQidsE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ktw_J6ZW0MM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ktw_J6ZW0MM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kTyI2unrdv0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kTyI2unrdv0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KU2bOYiBX28_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KU2bOYiBX28_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KubrAnJ0o0o_360-370.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KubrAnJ0o0o_360-370.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KUE_I30--AY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KUE_I30--AY_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kuj0Oi2_7yU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kuj0Oi2_7yU_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kUQ1xfK82Q0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kUQ1xfK82Q0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KurvLmoKCog_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KurvLmoKCog_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KV4noVyGHa4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KV4noVyGHa4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KV99GJg0tvA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KV99GJg0tvA_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kVaQA3PhSio_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kVaQA3PhSio_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kvIt_9P79Ro_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kvIt_9P79Ro_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kVuG_F3qCuY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kVuG_F3qCuY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kVYXcbvw9u4_580-590.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kVYXcbvw9u4_580-590.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kw2wPVxUgQY_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kw2wPVxUgQY_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KWpsFxRTGkI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KWpsFxRTGkI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kX5bTiq5eBo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kX5bTiq5eBo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KxjiEi2Eywk_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KxjiEi2Eywk_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KXRngbBe0bg_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KXRngbBe0bg_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KXuB62SMFvA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KXuB62SMFvA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KxVbdGPAfjE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KxVbdGPAfjE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KxZ0yDfyaJw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KxZ0yDfyaJw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KY5TY6ovKQg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KY5TY6ovKQg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KyjeM7J-Pz4_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KyjeM7J-Pz4_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kYrJadZmjm0_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kYrJadZmjm0_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KyRJP_fDrbk_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KyRJP_fDrbk_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KZ8gBHLNmH0_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KZ8gBHLNmH0_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kZBFQAQI7Pg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kZBFQAQI7Pg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KzvdKLdBw3s_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KzvdKLdBw3s_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\kZYBpOwNGZU_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\kZYBpOwNGZU_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KzydTOkZty8_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KzydTOkZty8_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\KzzKguqINa8_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\KzzKguqINa8_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\k_ET0i2y0Ow_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\k_ET0i2y0Ow_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K_G_k1WTdoc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K_G_k1WTdoc_30-40.mid\n","19/31 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\K_ZuxYxxT60_21-31.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\K_ZuxYxxT60_21-31.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l-RdHtsYWBY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l-RdHtsYWBY_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L0-l1LIa22g_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L0-l1LIa22g_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l0fCHZhKEDA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l0fCHZhKEDA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L0oun9F67tg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L0oun9F67tg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l1coM570kVw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l1coM570kVw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L1fxVVl_1bM_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L1fxVVl_1bM_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L1s-oPHsOac_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L1s-oPHsOac_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L1s7KZgWXGc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L1s7KZgWXGc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L2-EGNKzUAQ_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L2-EGNKzUAQ_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l21xSYRR_Xc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l21xSYRR_Xc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L3d4ajg0bhk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L3d4ajg0bhk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l3pK8prEnrQ_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l3pK8prEnrQ_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l3YrliBpOdM_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l3YrliBpOdM_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L3ZtE3rD2nc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L3ZtE3rD2nc_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L47F51OmZXo_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L47F51OmZXo_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L5CgdTtGv8o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L5CgdTtGv8o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l5QPXVIxxwk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l5QPXVIxxwk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L5UDz2PJ9sk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L5UDz2PJ9sk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l6LUPlmua6I_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l6LUPlmua6I_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l8P2wU-JyI8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l8P2wU-JyI8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L8zjEoQFws8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L8zjEoQFws8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L9GXrmmlYhE_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L9GXrmmlYhE_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L9j9fCHHPeg_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L9j9fCHHPeg_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\l9vYSBR9nio_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\l9vYSBR9nio_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LaaC_q3QDUE_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LaaC_q3QDUE_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LadgIxZu8Oc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LadgIxZu8Oc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LaeRCg-NdeY_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LaeRCg-NdeY_240-250.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LAeWwMC2EaI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LAeWwMC2EaI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LAHWV6fZwUk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LAHWV6fZwUk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lAMiOhScSPg_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lAMiOhScSPg_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LaoUSBEVHVQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LaoUSBEVHVQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\laVgKAcv8XA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\laVgKAcv8XA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LAxCq-s84F8_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LAxCq-s84F8_380-390.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LB0u0PrlDHU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LB0u0PrlDHU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lbB2VQYIMo0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lbB2VQYIMo0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LbPRGDwlfqs_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LbPRGDwlfqs_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LbQ4zHxhoSI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LbQ4zHxhoSI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lBtAULJAFp0_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lBtAULJAFp0_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LByEH80c6Eg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LByEH80c6Eg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Lc6OfmzV7Pk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Lc6OfmzV7Pk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LClTjcyNJSI_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LClTjcyNJSI_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LCMQXFKMLIM_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LCMQXFKMLIM_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LCzldLY3E4g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LCzldLY3E4g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ld5G00HlbQs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ld5G00HlbQs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lDABsoatahM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lDABsoatahM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lDCDayKyOQA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lDCDayKyOQA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lDGQu122JdU_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lDGQu122JdU_190-200.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lDnYXLGEEFQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lDnYXLGEEFQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lDsQWSf1h3I_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lDsQWSf1h3I_70-80.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Le4aGNS8e0c_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Le4aGNS8e0c_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LEG7xkYOsWA_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LEG7xkYOsWA_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\leiPemYDg-8_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\leiPemYDg-8_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lePP2BaZhJU_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lePP2BaZhJU_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LF-5BAUGvWI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LF-5BAUGvWI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LfbGHMumxIQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LfbGHMumxIQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lfCWGQ6URds_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lfCWGQ6URds_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lFv1MJSSWNs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lFv1MJSSWNs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LfvdxSBCtFE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LfvdxSBCtFE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LFW4yPH1z3M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LFW4yPH1z3M_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LFYRuK8YstI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LFYRuK8YstI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lGaA1dJQ0AQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lGaA1dJQ0AQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LGi38MqlPFA_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LGi38MqlPFA_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LgKOnHwaCmg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LgKOnHwaCmg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LGrAwQnZ6Bs_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LGrAwQnZ6Bs_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LGW99kSaf6M_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LGW99kSaf6M_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LH3mAtCou6g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LH3mAtCou6g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lh6ACdwNlyk_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lh6ACdwNlyk_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lhizlCmlbYY_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lhizlCmlbYY_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lHlOSsnP48c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lHlOSsnP48c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LHTA8VZGoMs_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LHTA8VZGoMs_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Lhw0H3P4zUE_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Lhw0H3P4zUE_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lI8aGjIb8Jg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lI8aGjIb8Jg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\liagR7x12O4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\liagR7x12O4_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lIBsL97sUmY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lIBsL97sUmY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lIEnbqr3O34_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lIEnbqr3O34_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\liuCTk2nPG8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\liuCTk2nPG8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LjihfG0fit0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LjihfG0fit0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LJsYl38zPOQ_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LJsYl38zPOQ_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LjxhswBV1UA_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LjxhswBV1UA_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LK6zk03lPlM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LK6zk03lPlM_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LktT1OQrPdo_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LktT1OQrPdo_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LKurVRvkmKc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LKurVRvkmKc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LKUYtvUHn0Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LKUYtvUHn0Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LKVSEQCLCLo_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LKVSEQCLCLo_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LkzyG2F8mTM_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LkzyG2F8mTM_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LM2C1eIUX9M_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LM2C1eIUX9M_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LMGpKPavV4Q_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LMGpKPavV4Q_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lmrzR9cSMRY_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lmrzR9cSMRY_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LnczSOwV9Ds_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LnczSOwV9Ds_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LNFAeJ06KVs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LNFAeJ06KVs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lNg2y6SRZPo_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lNg2y6SRZPo_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lnJdWXRgjKo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lnJdWXRgjKo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lnnlghshsVo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lnnlghshsVo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lnYOC9tKUBs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lnYOC9tKUBs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LoTRWc9WK9Q_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LoTRWc9WK9Q_460-470.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LP1yZRsRllQ_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LP1yZRsRllQ_70-80.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LPA8RDzl-Ss_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LPA8RDzl-Ss_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LpcvkXs49Zo_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LpcvkXs49Zo_300-310.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lPFsijo8xYs_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lPFsijo8xYs_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Lq0LMMZfHCU_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Lq0LMMZfHCU_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lqCx0HgF1ZM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lqCx0HgF1ZM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lqeAf-DqE3I_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lqeAf-DqE3I_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LqP4F4a-HOc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LqP4F4a-HOc_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LQYd-dsz62M_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LQYd-dsz62M_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LR3U4b_fVBc_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LR3U4b_fVBc_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lRC2lurjPBw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lRC2lurjPBw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Lrhy2auO6hY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Lrhy2auO6hY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LRUdmYcXFuM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LRUdmYcXFuM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ls6qMcgpdlM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ls6qMcgpdlM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LSaLPObrnZw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LSaLPObrnZw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lSb7Y-_3to8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lSb7Y-_3to8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lSbCqHZy_l4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lSbCqHZy_l4_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lTAfSpsyTSI_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lTAfSpsyTSI_70-80.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LTDle_h2YD8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LTDle_h2YD8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LTG-uVV_6q0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LTG-uVV_6q0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lTOzGIOIfq0_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lTOzGIOIfq0_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lTuEsrVV6Uw_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lTuEsrVV6Uw_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ltysCJWnvsI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ltysCJWnvsI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lUp9WnLYetg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lUp9WnLYetg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LUtBqNS27AQ_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LUtBqNS27AQ_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lV0-LMVpZLg_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lV0-LMVpZLg_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lvktro0asjs_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lvktro0asjs_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LvpImXJMryI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LvpImXJMryI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lwdDm3UO5WM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lwdDm3UO5WM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LWHUat2fo9w_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LWHUat2fo9w_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LWIHz5kao3g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LWIHz5kao3g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LWLLN9INTII_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LWLLN9INTII_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LwmwCpAVPWU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LwmwCpAVPWU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lXrypwLQO3U_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lXrypwLQO3U_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LybSS4amIS0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LybSS4amIS0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lYJAqOpp6RM_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lYJAqOpp6RM_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lymmNwQA0WA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lymmNwQA0WA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LYO7_GxyaZc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LYO7_GxyaZc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lYtoy8sa-Q0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lYtoy8sa-Q0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LyTwxJiSt7A_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LyTwxJiSt7A_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\lZavPVn7O4Q_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\lZavPVn7O4Q_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\LzSWdj4izHM_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\LzSWdj4izHM_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L_fWnna7Np0_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L_fWnna7Np0_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L_ghM-NrH58_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L_ghM-NrH58_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L_KkjB0Wt_Q_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L_KkjB0Wt_Q_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\L_nC2BvhRdQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\L_nC2BvhRdQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m--xEFqqrLc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m--xEFqqrLc_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m-eyGzf9Ux4_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m-eyGzf9Ux4_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m-NM_tIWjxs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m-NM_tIWjxs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M-RX7LqL50A_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M-RX7LqL50A_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m-S-yqzlOj4_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m-S-yqzlOj4_170-180.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m-xxD1fGPnU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m-xxD1fGPnU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m0FhT3UnXjA_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m0FhT3UnXjA_380-390.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M0ygCD6WyXw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M0ygCD6WyXw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M1ds6tRFxhs_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M1ds6tRFxhs_170-180.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m1ov6te6jK8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m1ov6te6jK8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M27mIdPCZEY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M27mIdPCZEY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M2iOUwFHv9Q_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M2iOUwFHv9Q_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m3uiITzeM70_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m3uiITzeM70_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m4bBsvuS4EU_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m4bBsvuS4EU_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m4Dj_vTsAt0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m4Dj_vTsAt0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M4rXhyyvERM_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M4rXhyyvERM_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M4SIUPA05yc_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M4SIUPA05yc_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M4yst1q1nlU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M4yst1q1nlU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M61BBJpvvx8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M61BBJpvvx8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M7GSBDc6s_w_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M7GSBDc6s_w_340-350.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m7i4g_o-znQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m7i4g_o-znQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m8-aK8egg84_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m8-aK8egg84_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m8poFnEbvW8_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m8poFnEbvW8_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M9mc3HYL_GM_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M9mc3HYL_GM_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M9MgZXkYRBs_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M9MgZXkYRBs_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m9MQdg0k1t0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m9MQdg0k1t0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\m9tnNkon_iw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\m9tnNkon_iw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\macnXLRXbHU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\macnXLRXbHU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\maeSHVZX8xc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\maeSHVZX8xc_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mAmaUI7_uZ0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mAmaUI7_uZ0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\maZ3b5w6xVI_440-450.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\maZ3b5w6xVI_440-450.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mB2FAS0DNkk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mB2FAS0DNkk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mBRr_TqLDf4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mBRr_TqLDf4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MC0Aeu7RLSI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MC0Aeu7RLSI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mcAsO331Z9s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mcAsO331Z9s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mCjsuxzcl2k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mCjsuxzcl2k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mdOZIOc8SA4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mdOZIOc8SA4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MeA8CSKAuvw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MeA8CSKAuvw_30-40.mid\n","1/1 [==============================] - 0s 13ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MEew7OQ17HY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MEew7OQ17HY_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\merGvga39Yo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\merGvga39Yo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Mf6Ql55o7Es_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Mf6Ql55o7Es_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mFcHGbnNtSQ_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mFcHGbnNtSQ_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mFp1nrnlGx4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mFp1nrnlGx4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MfX7Q0ucts8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MfX7Q0ucts8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MFxMPOAbUPA_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MFxMPOAbUPA_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mfZMcNmLxWM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mfZMcNmLxWM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mGU4ZRstxpY_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mGU4ZRstxpY_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MHHshnnqyco_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MHHshnnqyco_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MHkfPjW0aRg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MHkfPjW0aRg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mhqHHQ1gSvM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mhqHHQ1gSvM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mhru3GXbkHY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mhru3GXbkHY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Mhvgz5AjV3U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Mhvgz5AjV3U_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MIexFfOsuJs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MIexFfOsuJs_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Mir959i7F2M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Mir959i7F2M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MiWskwqOMrg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MiWskwqOMrg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mixc4NV5IBE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mixc4NV5IBE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MJtDDmS6xSY_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MJtDDmS6xSY_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mJuJfKbcJcw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mJuJfKbcJcw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mjZylz3nCwQ_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mjZylz3nCwQ_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mKIapkfnAGY_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mKIapkfnAGY_130-140.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MKikHxKeodA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MKikHxKeodA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MkPhe7TLLZ0_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MkPhe7TLLZ0_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MkTQQ0m8Ys8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MkTQQ0m8Ys8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MKXeCiPtZwo_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MKXeCiPtZwo_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mLaon9oK1OA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mLaon9oK1OA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mLm8upEhc_s_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mLm8upEhc_s_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MlnK2sa7mm4_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MlnK2sa7mm4_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mlpTCec4igo_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mlpTCec4igo_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mlrarQ5nVlU_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mlrarQ5nVlU_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MM0seezR2F4_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MM0seezR2F4_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mMf4vJFT8Fw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mMf4vJFT8Fw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MmqRlHntd0Q_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MmqRlHntd0Q_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mMT1kEejAG8_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mMT1kEejAG8_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MNd8CRa48Uk_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MNd8CRa48Uk_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Mnk6590abfY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Mnk6590abfY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MNlzpCwdh4g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MNlzpCwdh4g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mnSP_ONVS7k_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mnSP_ONVS7k_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MocXmVbat3s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MocXmVbat3s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mOFyRCMlXIo_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mOFyRCMlXIo_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mOmYcOBqhwo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mOmYcOBqhwo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mOn13E68Td0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mOn13E68Td0_30-40.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Mp1MHSeHa0o_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Mp1MHSeHa0o_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MP7KPlqoQW0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MP7KPlqoQW0_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mPaRs96jtFY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mPaRs96jtFY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MPe6ztPtF0Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MPe6ztPtF0Y_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mpikDeSk-mM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mpikDeSk-mM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MpS2SSIhe2g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MpS2SSIhe2g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MpWGx5odhh8_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MpWGx5odhh8_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MPxwPOOIskc_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MPxwPOOIskc_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mpymEs4Mcw8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mpymEs4Mcw8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mQ1E8rx2dnI_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mQ1E8rx2dnI_220-230.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MQ1Q7xydJPU_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MQ1Q7xydJPU_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mQM3Fd3eN9E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mQM3Fd3eN9E_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MQrOnSzVlJg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MQrOnSzVlJg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mQWht9mv7sE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mQWht9mv7sE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mqyeBqaUeN8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mqyeBqaUeN8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mq_b6QKVsuc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mq_b6QKVsuc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mRKud6yP4iU_440-450.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mRKud6yP4iU_440-450.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MrMXYO2fzJ4_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MrMXYO2fzJ4_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MROotmz8a-U_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MROotmz8a-U_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MS8VU468rKk_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MS8VU468rKk_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MsEoUVWS59M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MsEoUVWS59M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MSHbLrVlrQc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MSHbLrVlrQc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MsjeOXuUYG4_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MsjeOXuUYG4_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\msnm_tYXcYw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\msnm_tYXcYw_40-50.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MSqQKf3O3vY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MSqQKf3O3vY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mtapmFDmImA_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mtapmFDmImA_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MtVLmOvQopM_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MtVLmOvQopM_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mu0dlj8ibA4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mu0dlj8ibA4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mU6cfEWw5Og_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mU6cfEWw5Og_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\muwIU0BHXE0_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\muwIU0BHXE0_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MV4tgzc9X6s_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MV4tgzc9X6s_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Mv90uA0tmgc_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Mv90uA0tmgc_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MVAXHT67Na4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MVAXHT67Na4_10-20.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MVBQrBAXgw4_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MVBQrBAXgw4_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MvnC1TfNiPY_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MvnC1TfNiPY_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MVq9PYtypy0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MVq9PYtypy0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MVYSWTF11Nc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MVYSWTF11Nc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mvZLlJpyDyc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mvZLlJpyDyc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mW0B1sipLBI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mW0B1sipLBI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mW5_chAgg8c_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mW5_chAgg8c_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MwE7REVj8JQ_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MwE7REVj8JQ_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MwK9HYjeeN0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MwK9HYjeeN0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mWL9_WIbykw_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mWL9_WIbykw_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mwLrABPxvgA_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mwLrABPxvgA_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mwqluX7sXXU_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mwqluX7sXXU_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MWS-Uxf1MRw_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MWS-Uxf1MRw_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mwwnfWgV_5U_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mwwnfWgV_5U_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Mwy5Y0S5jfM_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Mwy5Y0S5jfM_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MX0wS7MX3Zo_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MX0wS7MX3Zo_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mx7kjFY7ALs_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mx7kjFY7ALs_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MXdVnDVjSL8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MXdVnDVjSL8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MY0PsDE3xHs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MY0PsDE3xHs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\myGef3nriL8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\myGef3nriL8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\myGffB4WcF8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\myGffB4WcF8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MyH8zQw9csc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MyH8zQw9csc_30-40.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MyjxrBI9k4o_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MyjxrBI9k4o_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mzDq-abtAKs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mzDq-abtAKs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MZhaDGgULtc_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MZhaDGgULtc_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\mZNNWTrvGoA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\mZNNWTrvGoA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\MzUgHy7SyS8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\MzUgHy7SyS8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\M_s-49rNCdw_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\M_s-49rNCdw_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N-dzfI3L5ic_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N-dzfI3L5ic_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N0i99VyZCg8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N0i99VyZCg8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N0q5vPAsHLI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N0q5vPAsHLI_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n16ZUTfZtDM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n16ZUTfZtDM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n179cK8EubU_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n179cK8EubU_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n1fY-23ffl0_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n1fY-23ffl0_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n1HBKct6rto_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n1HBKct6rto_30-40.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N1Mxns_JJTk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N1Mxns_JJTk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n1PTn_NH_K0_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n1PTn_NH_K0_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n3EeS2mVU5w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n3EeS2mVU5w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n3QsFeGadEE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n3QsFeGadEE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n3X8RGZsGg4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n3X8RGZsGg4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n4PBoAedWVA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n4PBoAedWVA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n4QSYx4wVQg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n4QSYx4wVQg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N4tTZn8WlDM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N4tTZn8WlDM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N5BAnG2zoUY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N5BAnG2zoUY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n615BjoN7fI_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n615BjoN7fI_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N6YT8_jlt0E_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N6YT8_jlt0E_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n7yLkcSfiuM_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n7yLkcSfiuM_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n87PCgYm6mE_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n87PCgYm6mE_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N8Fg3L1Cc5E_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N8Fg3L1Cc5E_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nAKUDXMeWeQ_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nAKUDXMeWeQ_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\navn7jCBp_o_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\navn7jCBp_o_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nB2Lf5TTmBs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nB2Lf5TTmBs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nbb8vmfjHJs_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nbb8vmfjHJs_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nBiHncFD0dM_430-440.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nBiHncFD0dM_430-440.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nbIwdOQ7D8A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nbIwdOQ7D8A_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NBnz0xV9nb4_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NBnz0xV9nb4_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nBSMh7pgn2o_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nBSMh7pgn2o_170-180.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nbYdiazwUQo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nbYdiazwUQo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nb_7c2xPKYA_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nb_7c2xPKYA_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NC5tIv4-8fg_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NC5tIv4-8fg_130-140.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nc6h6rC3wdk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nc6h6rC3wdk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NcsYdCbKgcc_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NcsYdCbKgcc_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NdiSW-p2I0c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NdiSW-p2I0c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NDJEKij2qOg_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NDJEKij2qOg_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ndjLkbP6Y9Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ndjLkbP6Y9Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\negr4U79PUE_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\negr4U79PUE_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Nep_3Y81E_w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Nep_3Y81E_w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nf3LGAL1LZc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nf3LGAL1LZc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nFkmTa4oY84_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nFkmTa4oY84_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nFoktpUVeVw_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nFoktpUVeVw_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NgniX3tg_Mo_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NgniX3tg_Mo_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NHA1l_Czm38_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NHA1l_Czm38_180-190.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NhVkzcCL0SA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NhVkzcCL0SA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nH_lVl3a3Uw_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nH_lVl3a3Uw_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nIL_xrqjo1g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nIL_xrqjo1g_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nJ3tuDmcdTs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nJ3tuDmcdTs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nJaezskegdc_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nJaezskegdc_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\njFM8DvmPVU_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\njFM8DvmPVU_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NJGo2fmUAII_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NJGo2fmUAII_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\njybD3PNrlc_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\njybD3PNrlc_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NJ_Ha89QjiI_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NJ_Ha89QjiI_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NKDBwJIwWoU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NKDBwJIwWoU_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nkSRzaqpOCQ_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nkSRzaqpOCQ_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nL4zx0-mi14_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nL4zx0-mi14_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NlCfScKw_Mk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NlCfScKw_Mk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Nlg8AbWRV_c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Nlg8AbWRV_c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NLQts9t7d8k_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NLQts9t7d8k_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NlUf1ppoSG4_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NlUf1ppoSG4_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nlWXsfjHeA8_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nlWXsfjHeA8_120-130.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NmMJgUo19Gk_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NmMJgUo19Gk_460-470.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Nms2A0wi0vU_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Nms2A0wi0vU_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NmwmOY6iBFg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NmwmOY6iBFg_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nnc6m1pBJ4c_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nnc6m1pBJ4c_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NNeEzTVATHg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NNeEzTVATHg_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NnmJ1UHWlas_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NnmJ1UHWlas_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nnUva-yCR08_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nnUva-yCR08_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NnYfF7E12dk_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NnYfF7E12dk_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NoB_4XaZYVs_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NoB_4XaZYVs_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\noLrCDzAp5M_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\noLrCDzAp5M_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nP05Sf4Fgac_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nP05Sf4Fgac_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NP5iO_HB-f0_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NP5iO_HB-f0_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Npbs_4DZgEQ_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Npbs_4DZgEQ_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nPlDt1R8Qfc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nPlDt1R8Qfc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Nqb7nw58q08_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Nqb7nw58q08_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nqcVA89BD6I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nqcVA89BD6I_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NqDxpJ2uR_8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NqDxpJ2uR_8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NQXQsVawPhU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NQXQsVawPhU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nr9oLIsbDyQ_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nr9oLIsbDyQ_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nrj2zTr7U0o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nrj2zTr7U0o_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NRWlHRvaDcQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NRWlHRvaDcQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ns-iXXKmzzU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ns-iXXKmzzU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nSBDyxxscks_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nSBDyxxscks_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nSinUcyFFqg_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nSinUcyFFqg_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nSLxQLYYoNE_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nSLxQLYYoNE_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NsR60ehkHGA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NsR60ehkHGA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NSS9_2FFVeo_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NSS9_2FFVeo_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nsxaoH9DjDo_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nsxaoH9DjDo_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NSyqj1DXZKg_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NSyqj1DXZKg_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NsYVaRI6rXg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NsYVaRI6rXg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nT1YAP4Vy9s_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nT1YAP4Vy9s_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nt2rvdC75uY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nt2rvdC75uY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ntfyeC178Tg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ntfyeC178Tg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NtM3gudMBCQ_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NtM3gudMBCQ_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nT_R3O0OK6U_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nT_R3O0OK6U_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nU7x170OvJ4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nU7x170OvJ4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Nuks8XFdGMk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Nuks8XFdGMk_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NuN-ug3dIkw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NuN-ug3dIkw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nUs5SJyQPnM_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nUs5SJyQPnM_350-360.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NUTaOnEhvzE_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NUTaOnEhvzE_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nu_Bl8Pz6PE_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nu_Bl8Pz6PE_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nv1hWkBbG0g_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nv1hWkBbG0g_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NVo-stvk_QE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NVo-stvk_QE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nvoGwmKh6NI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nvoGwmKh6NI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nvRd4xgEWbw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nvRd4xgEWbw_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nVsAyArtEh0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nVsAyArtEh0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nVSDv46ARvY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nVSDv46ARvY_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nvuxMnSHHtg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nvuxMnSHHtg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nvvXOfLs-ng_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nvvXOfLs-ng_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nW6Naj6eeI4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nW6Naj6eeI4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NwA9JSlK_lM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NwA9JSlK_lM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NwfEO8cjSK0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NwfEO8cjSK0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NWL-P08eM-U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NWL-P08eM-U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NwUJe24OxC8_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NwUJe24OxC8_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NxdQtpceXaI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NxdQtpceXaI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nXfqAzdu8IY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nXfqAzdu8IY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NxpnW_IdkSY_480-490.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NxpnW_IdkSY_480-490.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NXuB3ZEpM5U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NXuB3ZEpM5U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nY4tpb8O_Rg_430-440.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nY4tpb8O_Rg_430-440.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ny4wnDN4K1U_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ny4wnDN4K1U_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nyjXFx0GSX8_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nyjXFx0GSX8_150-160.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nyLpME6YH20_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nyLpME6YH20_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Nymjfq2kXnI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Nymjfq2kXnI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nYO8n62Piys_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nYO8n62Piys_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nZ19mW-TMRk_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nZ19mW-TMRk_200-210.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NZ2kFIaW05k_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NZ2kFIaW05k_450-460.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Nz4iLzJBTBo_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Nz4iLzJBTBo_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nZ5_UUUS8X8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nZ5_UUUS8X8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nzdlPYd8XUs_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nzdlPYd8XUs_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nZmhIHZINL8_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nZmhIHZINL8_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NZn4-gP2GiI_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NZn4-gP2GiI_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nZOgoVEud_w_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nZOgoVEud_w_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nzpnWuk3RjU_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nzpnWuk3RjU_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\nZQZ7CpXqAU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\nZQZ7CpXqAU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NzvkMWY4EjA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NzvkMWY4EjA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\NZYDLDIyZr8_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\NZYDLDIyZr8_260-270.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N_41Y2vH6eA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N_41Y2vH6eA_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n_boIyhZqWc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n_boIyhZqWc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N_LKZjw9DLk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N_LKZjw9DLk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\n_REM0fSVrA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\n_REM0fSVrA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\N_Wx35sNqdM_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\N_Wx35sNqdM_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\o-ISARPUGlo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\o-ISARPUGlo_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\o-ZTQP5CFCg_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\o-ZTQP5CFCg_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O0sDg-yLvlE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O0sDg-yLvlE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O0y-m0pCi5E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O0y-m0pCi5E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O1EmHJyz5ds_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O1EmHJyz5ds_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O1RmrE_HfpE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O1RmrE_HfpE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O25IKwo2HkE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O25IKwo2HkE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O28kY0aN8VI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O28kY0aN8VI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\o2bqT0ZTz7E_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\o2bqT0ZTz7E_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O2HttJtcec4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O2HttJtcec4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O3Cvn4yXrao_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O3Cvn4yXrao_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O40E8bpmONQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O40E8bpmONQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O5IulN0n6d0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O5IulN0n6d0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O6QyYC7Tt2A_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O6QyYC7Tt2A_160-170.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O6xMQnKJROc_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O6xMQnKJROc_140-150.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\o6ZQNr0Tpz4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\o6ZQNr0Tpz4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O73wigUotGo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O73wigUotGo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O84YjlJ_Qw4_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O84YjlJ_Qw4_40-50.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O8EMm4QJjeo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O8EMm4QJjeo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\o8FsD7l5er4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\o8FsD7l5er4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O8rHjrG3HM4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O8rHjrG3HM4_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O9Ag-dE-yfQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O9Ag-dE-yfQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\O9_avJFKIQk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\O9_avJFKIQk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OA63sRxGk6o_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OA63sRxGk6o_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oag3I4VRXyM_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oag3I4VRXyM_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ob9iaGon5ak_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ob9iaGon5ak_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oBBTqXQFTiA_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oBBTqXQFTiA_80-90.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OBJM1TqPvu4_470-480.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OBJM1TqPvu4_470-480.mid\n","1/1 [==============================] - 0s 16ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Obtx-A9Lt5c_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Obtx-A9Lt5c_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oBwt8T8P8Zs_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oBwt8T8P8Zs_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oC0e8GXYy_4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oC0e8GXYy_4_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Occ4uW0lw0k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Occ4uW0lw0k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ocCIB2bPq_Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ocCIB2bPq_Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OcdrbkDm2LQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OcdrbkDm2LQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oczJZV87k9A_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oczJZV87k9A_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oD0Xp--xxjE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oD0Xp--xxjE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OdLCoLVRCmk_570-580.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OdLCoLVRCmk_570-580.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ODOrls3MuZI_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ODOrls3MuZI_190-200.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ODRAYQE9GXs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ODRAYQE9GXs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\odzi_VK8m3k_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\odzi_VK8m3k_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OECgm1obaFs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OECgm1obaFs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OEIj1UX5ZRg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OEIj1UX5ZRg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oEJ5bh-OIuU_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oEJ5bh-OIuU_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OEjgIDubFbg_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OEjgIDubFbg_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OeNTAUKZgKs_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OeNTAUKZgKs_400-410.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OEpMpYMjO9Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OEpMpYMjO9Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OEuBITrf-kE_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OEuBITrf-kE_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Oe_xSG_ic-c_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Oe_xSG_ic-c_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oFCzd9bJo9A_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oFCzd9bJo9A_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OFJG5Wo_knI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OFJG5Wo_knI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OFP5MYVDa4g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OFP5MYVDa4g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ofry7lyQZDA_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ofry7lyQZDA_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oGbNzR_lpSk_480-490.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oGbNzR_lpSk_480-490.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ogOTksL2Vas_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ogOTksL2Vas_420-430.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OgqDO1wxQ8E_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OgqDO1wxQ8E_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oh0EWEvJI90_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oh0EWEvJI90_30-40.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OH2SQhJqZDg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OH2SQhJqZDg_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oh5XmtSAOuM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oh5XmtSAOuM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OH8urnIthoQ_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OH8urnIthoQ_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ohBNHUUGD3Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ohBNHUUGD3Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OheHnFixwVk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OheHnFixwVk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ohikUtjUN7c_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ohikUtjUN7c_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OhZmxS5DUKU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OhZmxS5DUKU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OHZZuO2vY50_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OHZZuO2vY50_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OI7S7vaBT4I_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OI7S7vaBT4I_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OiAJB9uydS8_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OiAJB9uydS8_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OII3VJoE0WA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OII3VJoE0WA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OiNlYrlJE4g_430-440.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OiNlYrlJE4g_430-440.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oJ0rdNlghn4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oJ0rdNlghn4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ojdqgnmcgYM_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ojdqgnmcgYM_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OjEG808MfF4_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OjEG808MfF4_330-340.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OjoDuBkPDM8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OjoDuBkPDM8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OJuVsBojdvo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OJuVsBojdvo_30-40.mid\n","31/31 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OjvWDzPGeic_5-15.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OjvWDzPGeic_5-15.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ojwVhlh-P1U_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ojwVhlh-P1U_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oJyyNWuyig4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oJyyNWuyig4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ok-ia7ziJy0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ok-ia7ziJy0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oKab6-syQD4_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oKab6-syQD4_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\okAn7kjxmes_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\okAn7kjxmes_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OkcBJawiIHA_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OkcBJawiIHA_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OKquGBKOgME_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OKquGBKOgME_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OKZF0oG1E14_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OKZF0oG1E14_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OLy3C8YpMsY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OLy3C8YpMsY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OMApGp219Zc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OMApGp219Zc_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OMcoFfaCaGM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OMcoFfaCaGM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oMgSuyPBINs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oMgSuyPBINs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OmjfHQB_lcs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OmjfHQB_lcs_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oMZcsGUi8ZE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oMZcsGUi8ZE_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\on18CWdmxn8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\on18CWdmxn8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\On9epzZ_ceI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\On9epzZ_ceI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oN9_GYDkNcM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oN9_GYDkNcM_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oNggxSyyyq8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oNggxSyyyq8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OnL-e9X0oEc_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OnL-e9X0oEc_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oNqBsQiNoAU_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oNqBsQiNoAU_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oNryELagQUM_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oNryELagQUM_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OO1Q-3kXCtM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OO1Q-3kXCtM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OOik9i9wrU8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OOik9i9wrU8_0-10.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oOiwmRV1PBk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oOiwmRV1PBk_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OoJGMj5H7Wk_440-450.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OoJGMj5H7Wk_440-450.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oOlMzQpK690_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oOlMzQpK690_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OoRUo92emGo_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OoRUo92emGo_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OoyxPPoPmt0_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OoyxPPoPmt0_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OPimGlHcSRQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OPimGlHcSRQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OpWCljke4oQ_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OpWCljke4oQ_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OPX9ukYun3o_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OPX9ukYun3o_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oqMlq2zWr0c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oqMlq2zWr0c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OQz8reoVQEI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OQz8reoVQEI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Or4CALipjig_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Or4CALipjig_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Orge4_UlvNI_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Orge4_UlvNI_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oRHKVmQ138Q_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oRHKVmQ138Q_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ORikRIu7s1o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ORikRIu7s1o_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OrsfEkAhie4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OrsfEkAhie4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ORt8LSgn-uA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ORt8LSgn-uA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oRUdvu3Qo-E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oRUdvu3Qo-E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oRVivXC83hA_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oRVivXC83hA_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OR_YbeqV5tA_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OR_YbeqV5tA_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oSDZZHN77PI_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oSDZZHN77PI_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OseeYF_ud7g_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OseeYF_ud7g_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oSg1VJHiPOE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oSg1VJHiPOE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OSlotCnSFow_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OSlotCnSFow_140-150.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oSoP9Is0UH4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oSoP9Is0UH4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oswsd_r-GI8_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oswsd_r-GI8_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ot6SpwD1hzk_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ot6SpwD1hzk_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oT6ud0OdR_E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oT6ud0OdR_E_30-40.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OTu_vWZV4QA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OTu_vWZV4QA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\otVPTo72q4w_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\otVPTo72q4w_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oTXKGrB3bCA_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oTXKGrB3bCA_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oTzTZqDOIt0_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oTzTZqDOIt0_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ou2rEaq28PM_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ou2rEaq28PM_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ou3LJpAM4mk_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ou3LJpAM4mk_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ou7vteWmqfw_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ou7vteWmqfw_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oUp-acoLyvU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oUp-acoLyvU_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ouVuF-y8bog_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ouVuF-y8bog_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oVhhEku6ECA_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oVhhEku6ECA_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OvjmfGU4y_M_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OvjmfGU4y_M_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ovk5EfFj7Ws_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ovk5EfFj7Ws_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OVNVaXZ9D0E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OVNVaXZ9D0E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OvX68hqDjeA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OvX68hqDjeA_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ow12iGt8z5Q_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ow12iGt8z5Q_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ow7xqVk8Wjs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ow7xqVk8Wjs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OwukabRF7I4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OwukabRF7I4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OwUzGq0ceT8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OwUzGq0ceT8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oXBGZoBYaLY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oXBGZoBYaLY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oxhFIoExrMk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oxhFIoExrMk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OxxRnDpN9cc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OxxRnDpN9cc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oxZjkE984Uo_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oxZjkE984Uo_60-70.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oyAAhjGTNvQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oyAAhjGTNvQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oYECB7KFJgU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oYECB7KFJgU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oYEzy8gH6q8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oYEzy8gH6q8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oynXCFZWxnI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oynXCFZWxnI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OyouRYAq-tE_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OyouRYAq-tE_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oypg41SWGDc_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oypg41SWGDc_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OyRtTtTSXuM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OyRtTtTSXuM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OzaVvthCvtk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OzaVvthCvtk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oZF73R89bk0_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oZF73R89bk0_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OZjpYGdvMX0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OZjpYGdvMX0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ozjs2d_xlSI_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ozjs2d_xlSI_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oZoJ26C6LrU_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oZoJ26C6LrU_100-110.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oZrMoZeJ8Ng_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oZrMoZeJ8Ng_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\oZScu7DU5qk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\oZScu7DU5qk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\OZv8mtQEgA0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\OZv8mtQEgA0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P-eIhvCaK-s_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P-eIhvCaK-s_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P007re8_iyY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P007re8_iyY_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p0oRrGDrQQw_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p0oRrGDrQQw_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p1-07VdP__Q_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p1-07VdP__Q_10-20.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P14zjckYFK0_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P14zjckYFK0_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p1DNl8BF49U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p1DNl8BF49U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p20KE0LhL68_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p20KE0LhL68_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P240GHf9Eq4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P240GHf9Eq4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P25JeM4lPGw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P25JeM4lPGw_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p28jmA01BHo_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p28jmA01BHo_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P2F4iNqJmNU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P2F4iNqJmNU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p2jnUySmuvA_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p2jnUySmuvA_220-230.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p2NPfU5QARc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p2NPfU5QARc_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P2UqnWU8d8o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P2UqnWU8d8o_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p2yedR_jMTU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p2yedR_jMTU_0-10.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P39x5dOsJ40_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P39x5dOsJ40_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p3DLHNuCYhU_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p3DLHNuCYhU_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P3ZPbGjHFXE_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P3ZPbGjHFXE_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P4aTFrJws40_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P4aTFrJws40_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p4T1pddBia0_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p4T1pddBia0_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P4zWSoib5BU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P4zWSoib5BU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P54hbuQLkc4_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P54hbuQLkc4_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P5AgEqouchI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P5AgEqouchI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P5IxlG4-CY8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P5IxlG4-CY8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P5tsRM1iokA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P5tsRM1iokA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P5uIpVLEpm4_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P5uIpVLEpm4_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P65yE_EXLd8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P65yE_EXLd8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P8nK4i8XscM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P8nK4i8XscM_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p8xxC2um9xQ_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p8xxC2um9xQ_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P90rFZQFqWk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P90rFZQFqWk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P97w3AdePgQ_570-580.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P97w3AdePgQ_570-580.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\P9fh7rOIKcM_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\P9fh7rOIKcM_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p9nbp0Oo1U0_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p9nbp0Oo1U0_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\paeNnR33i5Q_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\paeNnR33i5Q_300-310.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PaQGXIh94uc_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PaQGXIh94uc_150-160.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PAX2PMha2dU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PAX2PMha2dU_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PB3i02Cjf1k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PB3i02Cjf1k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PBMfPDei93s_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PBMfPDei93s_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PBqNpMpD76k_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PBqNpMpD76k_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PbUyPbafFh0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PbUyPbafFh0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PcdpjUIa8l0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PcdpjUIa8l0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pcOPueObfWs_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pcOPueObfWs_130-140.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pCW5ab3SNcQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pCW5ab3SNcQ_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pd4WnsXwdqw_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pd4WnsXwdqw_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PdgswSjYhMw_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PdgswSjYhMw_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pDgWT99uaJ0_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pDgWT99uaJ0_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pdIAN6lMXSU_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pdIAN6lMXSU_230-240.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pdOskdFwRPg_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pdOskdFwRPg_40-50.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PduP4CpaDtY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PduP4CpaDtY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PE1ges9nn6A_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PE1ges9nn6A_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pejDm3j4Y-I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pejDm3j4Y-I_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pELIBvAnbkY_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pELIBvAnbkY_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PeQ8L_svYcU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PeQ8L_svYcU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PeWXdkEUPbo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PeWXdkEUPbo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PF5LgwJjYuA_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PF5LgwJjYuA_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PF6Mn51Nkvs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PF6Mn51Nkvs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pf9AaTV4-yw_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pf9AaTV4-yw_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PFa1XVCgPgM_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PFa1XVCgPgM_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PfO7ZVdzfZ4_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PfO7ZVdzfZ4_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PfpP3WjY118_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PfpP3WjY118_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PFtcnQqLdEc_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PFtcnQqLdEc_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PFX2OO75sRQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PFX2OO75sRQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pG6yeC3yUY4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pG6yeC3yUY4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pgpd1yxLcLI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pgpd1yxLcLI_30-40.mid\n","22/32 [===================>..........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pHC25Ia8Dxo_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pHC25Ia8Dxo_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pHj8U-3RHc4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pHj8U-3RHc4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Phy-_ko0zWU_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Phy-_ko0zWU_160-170.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pHzjKCj9INw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pHzjKCj9INw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PIIAyM4H1UE_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PIIAyM4H1UE_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pIwn0udLJXI_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pIwn0udLJXI_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\piY4mt4F9xg_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\piY4mt4F9xg_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\piyYJ2l_h8Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\piyYJ2l_h8Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PJRG2bwphUc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PJRG2bwphUc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PJUffXn-LIk_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PJUffXn-LIk_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pk5NZe-ah4U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pk5NZe-ah4U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pKDnn0CBIe0_35-45.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pKDnn0CBIe0_35-45.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pKFXFu8st9I_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pKFXFu8st9I_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PKJMsnUJ994_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PKJMsnUJ994_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PkkhCW04O9k_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PkkhCW04O9k_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PKsdjH0RmsU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PKsdjH0RmsU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pL71P2hVjMc_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pL71P2hVjMc_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pln4GLIMqKY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pln4GLIMqKY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PlQibWaPAcM_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PlQibWaPAcM_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pm6vRblouxc_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pm6vRblouxc_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pmdoDcNBt0E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pmdoDcNBt0E_30-40.mid\n","1/1 [==============================] - 0s 6ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PmiH7RnCkhI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PmiH7RnCkhI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PN3Lx8RutmI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PN3Lx8RutmI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pn8HqUbNQAc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pn8HqUbNQAc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pnh_C1w4yGc_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pnh_C1w4yGc_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PnJx0uLJ_oE_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PnJx0uLJ_oE_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pNlrM-GhFZU_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pNlrM-GhFZU_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PNT3hW4qFpQ_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PNT3hW4qFpQ_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\POOu05eUvqE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\POOu05eUvqE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\poxsF3-HeP0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\poxsF3-HeP0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pOZWVSiRwv4_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pOZWVSiRwv4_390-400.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PP3kNqPM434_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PP3kNqPM434_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pp6eSGANq0Y_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pp6eSGANq0Y_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PpamaOkNqoI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PpamaOkNqoI_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ppAT0f2YCyM_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ppAT0f2YCyM_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PpJKo-JPVU0_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PpJKo-JPVU0_60-70.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pPOUg26EXiU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pPOUg26EXiU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pq1jBX0RW2k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pq1jBX0RW2k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PQ7cX2Cnusg_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PQ7cX2Cnusg_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PqN7aT4dVN4_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PqN7aT4dVN4_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PQrYV7hJWDg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PQrYV7hJWDg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pqsU95TNNP8_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pqsU95TNNP8_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PqTPbZf44E0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PqTPbZf44E0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PqTTIfja0y8_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PqTTIfja0y8_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pQWpa484HQM_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pQWpa484HQM_40-50.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PQXYWc3JHhU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PQXYWc3JHhU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pR87Ts3a0e8_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pR87Ts3a0e8_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PrMKUjFxrvQ_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PrMKUjFxrvQ_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PRRcVdXsBQg_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PRRcVdXsBQg_90-100.mid\n","18/31 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["31/31 [==============================] - 1s 19ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PRzBkZSSyY0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PRzBkZSSyY0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pS1X6Au1EAU_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pS1X6Au1EAU_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pSt8NwXyDlg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pSt8NwXyDlg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pSzTPGlNa5U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pSzTPGlNa5U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PTCsH-ffeq4_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PTCsH-ffeq4_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PTl5ixI1Ogc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PTl5ixI1Ogc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PTLOLz9YzmM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PTLOLz9YzmM_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pTzINk_nVHg_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pTzINk_nVHg_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PufDOSkxwzQ_550-560.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PufDOSkxwzQ_550-560.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PuJxL6tLxm4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PuJxL6tLxm4_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Puu8SEqYN0k_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Puu8SEqYN0k_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PUy3cnNk4ys_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PUy3cnNk4ys_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pv8ZWvM8bhw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pv8ZWvM8bhw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pVfV09CDmus_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pVfV09CDmus_0-10.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PvHKu1XRSJ0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PvHKu1XRSJ0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pvxx3aokwCU_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pvxx3aokwCU_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pWHkmo9Kn8g_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pWHkmo9Kn8g_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PwmXO0J-PAA_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PwmXO0J-PAA_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PWVr9weg00U_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PWVr9weg00U_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pwX5SArqGKU_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pwX5SArqGKU_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pWZqzEpygE0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pWZqzEpygE0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PXd0NCqZLzU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PXd0NCqZLzU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pxEmmUYLHrE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pxEmmUYLHrE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PxXR74Uohfg_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PxXR74Uohfg_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PxxyplPsqBY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PxxyplPsqBY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pXz67syyse0_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pXz67syyse0_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Py8Vd0-qxYU_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Py8Vd0-qxYU_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pYaegEQ_wtI_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pYaegEQ_wtI_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pyumNmhV4_s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pyumNmhV4_s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PyVuHAskeUg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PyVuHAskeUg_10-20.mid\n","32/32 [==============================] - 0s 15ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pYXx0xXZiXk_14-24.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pYXx0xXZiXk_14-24.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pz8P96myUZk_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pz8P96myUZk_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pzm90xLX9HM_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pzm90xLX9HM_450-460.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\pzpg2-jYu6k_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\pzpg2-jYu6k_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Pzp_oTEn0Yk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Pzp_oTEn0Yk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\PZZxVIIOQPo_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\PZZxVIIOQPo_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p_-lKpxLK3g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p_-lKpxLK3g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p_dE26TA8ig_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p_dE26TA8ig_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\p_o6NQX7lmE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\p_o6NQX7lmE_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q-86OQ3HZ4o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q-86OQ3HZ4o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q-ATDBgDbLE_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q-ATDBgDbLE_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q-sJu8CoZts_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q-sJu8CoZts_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q0KwG3ynscI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q0KwG3ynscI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q0VVfneN8MI_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q0VVfneN8MI_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q1LJotkUbUY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q1LJotkUbUY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q1pjymZOm6Q_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q1pjymZOm6Q_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q2Omtt4A8ls_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q2Omtt4A8ls_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q4PfLl3JVfg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q4PfLl3JVfg_30-40.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q6dVti1YVwM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q6dVti1YVwM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q6GBCmLxNIk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q6GBCmLxNIk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q6SgmlYMYLA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q6SgmlYMYLA_30-40.mid\n","22/32 [===================>..........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q75y0TIp7Ds_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q75y0TIp7Ds_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q7oWXOByo28_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q7oWXOByo28_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q7s7C4oNlFo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q7s7C4oNlFo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q7sK_xrJz-k_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q7sK_xrJz-k_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q7U8p-m8J3s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q7U8p-m8J3s_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q87TmUmVg0Y_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q87TmUmVg0Y_130-140.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q8QXzYpl6Tw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q8QXzYpl6Tw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q8X6geEBR2o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q8X6geEBR2o_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q9DzO_I4dXg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q9DzO_I4dXg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q9Gh-zh-5Ig_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q9Gh-zh-5Ig_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\q9zAlMM-A9I_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\q9zAlMM-A9I_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qa-Qs9CtOOw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qa-Qs9CtOOw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qaQjG9SwORU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qaQjG9SwORU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qAr3mFkEvco_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qAr3mFkEvco_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qbexOeoH5hg_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qbexOeoH5hg_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qBe_D8Gg5lA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qBe_D8Gg5lA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QBhhtVMiQBQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QBhhtVMiQBQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qbIPQGY8RRA_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qbIPQGY8RRA_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QBMM1ocXkhY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QBMM1ocXkhY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QCbUlDMu7Hk_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QCbUlDMu7Hk_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qcjzfHmQvxg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qcjzfHmQvxg_20-30.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qCUJ-8AlecY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qCUJ-8AlecY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qDiTICmdUQg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qDiTICmdUQg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qDjeY72KaSo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qDjeY72KaSo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QdoTdG_VNV4_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QdoTdG_VNV4_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qDSvHlHbAqM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qDSvHlHbAqM_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QDTCAxyXt80_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QDTCAxyXt80_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qdWTfyysMN8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qdWTfyysMN8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qe71m678qEU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qe71m678qEU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qEGNzCWQdqo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qEGNzCWQdqo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qeoYWM1uYPI_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qeoYWM1uYPI_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qET3h3w35EA_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qET3h3w35EA_110-120.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qe_KwKVDgoE_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qe_KwKVDgoE_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qf87MJcWZQI_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qf87MJcWZQI_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QFhmzRkUx0I_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QFhmzRkUx0I_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QfM5-WqvquQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QfM5-WqvquQ_30-40.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qFo_gRhW6dQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qFo_gRhW6dQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qFTMEVccUMg_450-460.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qFTMEVccUMg_450-460.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qfVIeq7s6tw_460-470.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qfVIeq7s6tw_460-470.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qfwTbBprDVU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qfwTbBprDVU_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qh-4EDX4agQ_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qh-4EDX4agQ_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QHCHK-NPO_U_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QHCHK-NPO_U_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QhF0CFyzzAc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QhF0CFyzzAc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QHmGUrpOgAU_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QHmGUrpOgAU_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QHNREJJRTS4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QHNREJJRTS4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qHRRWdWvjxI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qHRRWdWvjxI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qI-Ji4gtBPM_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qI-Ji4gtBPM_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QiD3AkQz17E_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QiD3AkQz17E_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qie2k2gZ7wA_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qie2k2gZ7wA_490-500.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QIjShFhrp6w_113-123.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QIjShFhrp6w_113-123.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qj4r_MCC0mc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qj4r_MCC0mc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qjH068GOmQ4_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qjH068GOmQ4_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qjJ41iwU9LY_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qjJ41iwU9LY_130-140.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QJzveo6IBsU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QJzveo6IBsU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QK-mjNg8cPo_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QK-mjNg8cPo_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QKkhwAAGLIE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QKkhwAAGLIE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qknDM3pcoD0_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qknDM3pcoD0_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qKOsbyT8GCU_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qKOsbyT8GCU_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qKXhSGaudtk_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qKXhSGaudtk_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ql7aH8wF6JM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ql7aH8wF6JM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qlklggFvAZs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qlklggFvAZs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qlqJF5yPmUc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qlqJF5yPmUc_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qlWEAm4AUTU_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qlWEAm4AUTU_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qLWWDHLJBBQ_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qLWWDHLJBBQ_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qM8F6ECriRc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qM8F6ECriRc_50-60.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qm8sJxsZ5VY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qm8sJxsZ5VY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qMbGFWz9who_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qMbGFWz9who_20-30.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qMd2DTyF9EE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qMd2DTyF9EE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QmIhKF1BqCg_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QmIhKF1BqCg_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QMoRiBjRLKc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QMoRiBjRLKc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qmR9O2oZCWc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qmR9O2oZCWc_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qni67aUJbw4_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qni67aUJbw4_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QNQ3sAMxZPY_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QNQ3sAMxZPY_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qoBC2wimalI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qoBC2wimalI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qOSdHmfwLF4_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qOSdHmfwLF4_40-50.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qp4Ubx7WOAQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qp4Ubx7WOAQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qpN3Aqrr8mg_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qpN3Aqrr8mg_140-150.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qpt3umHYfmY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qpt3umHYfmY_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qpwjSTEaswI_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qpwjSTEaswI_90-100.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QpX9dSCFxRI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QpX9dSCFxRI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QqRrZzOY2xw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QqRrZzOY2xw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QQTWFTNy-WA_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QQTWFTNy-WA_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qRgefptkDeo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qRgefptkDeo_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QrJVAHIkpCo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QrJVAHIkpCo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QRKc90kuAaE_560-570.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QRKc90kuAaE_560-570.mid\n","1/1 [==============================] - 0s 16ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QrKJs6lBfmM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QrKJs6lBfmM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qrP_H87vFpo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qrP_H87vFpo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qrY7PW5guxk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qrY7PW5guxk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qrzNABqN420_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qrzNABqN420_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QS3DabGF41Y_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QS3DabGF41Y_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qsFfUzErXqw_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qsFfUzErXqw_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qsRPTMXFGsA_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qsRPTMXFGsA_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QT1SjY9mQxc_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QT1SjY9mQxc_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qt8Ze-k2h2o_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qt8Ze-k2h2o_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QtfIj5cJzYw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QtfIj5cJzYw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QtjMlA_7dds_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QtjMlA_7dds_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qtnE1hnCD0M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qtnE1hnCD0M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qtNTHnXOQew_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qtNTHnXOQew_40-50.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qu76GhRO9Yk_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qu76GhRO9Yk_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QUB_vpjogmo_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QUB_vpjogmo_170-180.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QutCXtWmzIs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QutCXtWmzIs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qutPvh6TFd8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qutPvh6TFd8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QUtyeIooCy4_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QUtyeIooCy4_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qUWYzx7pBSw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qUWYzx7pBSw_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qVdBBOpSoN4_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qVdBBOpSoN4_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qVgnzJuGDBE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qVgnzJuGDBE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qVgVh9t_7ac_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qVgVh9t_7ac_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qVT6GX1KHUY_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qVT6GX1KHUY_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qVuxCN3JpiM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qVuxCN3JpiM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QvwD7NEg3Mw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QvwD7NEg3Mw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qV_VxEAXXDU_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qV_VxEAXXDU_220-230.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qw468qlDaAE_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qw468qlDaAE_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qwGT6wvYdLo_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qwGT6wvYdLo_60-70.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qwI32Si0ipE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qwI32Si0ipE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qwOLhVbuhpM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qwOLhVbuhpM_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qwz7oLASJqg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qwz7oLASJqg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QXe9BpTENCc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QXe9BpTENCc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qXgSlhWbWLU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qXgSlhWbWLU_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qxOPhByaK_M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qxOPhByaK_M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qXSG2uq2tNw_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qXSG2uq2tNw_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qy77eJc72UQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qy77eJc72UQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QyMcSnNsAPw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QyMcSnNsAPw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QYxFWV85-pg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QYxFWV85-pg_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Qz2PIXM60iE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Qz2PIXM60iE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qZkM3QaeaUM_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qZkM3QaeaUM_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QzMsoz4XIkM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QzMsoz4XIkM_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QZNrK337wow_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QZNrK337wow_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QzO6ylLrTGg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QzO6ylLrTGg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\QZoclbefgak_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\QZoclbefgak_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\qZ_-5JplSVg_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\qZ_-5JplSVg_370-380.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Q_3GACs__Xs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Q_3GACs__Xs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R-aMYx9f0Ho_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R-aMYx9f0Ho_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r-PBeJiE5sc_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r-PBeJiE5sc_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R0b3pU4AKNc_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R0b3pU4AKNc_380-390.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R0ws0tATJLg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R0ws0tATJLg_0-10.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r0Xvr8maR34_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r0Xvr8maR34_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R1RGIgC-xKw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R1RGIgC-xKw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r1W1z_31Obw_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r1W1z_31Obw_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r2gYE6-cGx8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r2gYE6-cGx8_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R3urUtvSgkU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R3urUtvSgkU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r43WrKA6ppI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r43WrKA6ppI_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r4G71I1dFpA_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r4G71I1dFpA_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R4jlQEweREY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R4jlQEweREY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r4JRDHYukZ4_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r4JRDHYukZ4_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r4nPBNL3D0E_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r4nPBNL3D0E_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R4ulZgTCw-k_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R4ulZgTCw-k_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R5JRh08zgMo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R5JRh08zgMo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R5KBk76b9HE_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R5KBk76b9HE_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r5xTmK2Fq1w_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r5xTmK2Fq1w_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R60qQ3ag8y8_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R60qQ3ag8y8_100-110.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R6lRMU-zBLA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R6lRMU-zBLA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R6mhBqTU0Tc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R6mhBqTU0Tc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r6QD2E-YesI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r6QD2E-YesI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R6V85er9VXc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R6V85er9VXc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r6yGS_yQmj4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r6yGS_yQmj4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R77XPtKgvy4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R77XPtKgvy4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R7gHB-YuUZM_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R7gHB-YuUZM_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r7Ve8ExE8YY_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r7Ve8ExE8YY_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r9AxQfXYLEs_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r9AxQfXYLEs_160-170.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\raM8Lp0aGCk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\raM8Lp0aGCk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RBniJk6GKK0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RBniJk6GKK0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rC4PNZ1XOmU_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rC4PNZ1XOmU_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rccs9c1gteQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rccs9c1gteQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RcfaWoTywcA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RcfaWoTywcA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RczzNAr1T_Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RczzNAr1T_Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RD8kf4453cY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RD8kf4453cY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RDCXvJPzT5k_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RDCXvJPzT5k_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RdKQGIzKZ_c_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RdKQGIzKZ_c_420-430.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RDNatVYvpeA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RDNatVYvpeA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rDusaHYR69g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rDusaHYR69g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Rdwtr2IX8ek_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Rdwtr2IX8ek_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RDW_kz4SXo0_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RDW_kz4SXo0_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rE7S4nLrThs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rE7S4nLrThs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\REpuZwvyThM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\REpuZwvyThM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rez5KDmIZoc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rez5KDmIZoc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RF3rog2YjYw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RF3rog2YjYw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Rf7vygfb7w4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Rf7vygfb7w4_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rfa-iUp5UQc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rfa-iUp5UQc_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RFbWkL818XQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RFbWkL818XQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rFE_bKOr1W0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rFE_bKOr1W0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RFKTlhbnfXA_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RFKTlhbnfXA_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RFNRR78dh-8_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RFNRR78dh-8_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rfQ94EXIpTc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rfQ94EXIpTc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rFwJ2L-geWw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rFwJ2L-geWw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rGEJVUcFA2U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rGEJVUcFA2U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rGgvqyHKI4Y_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rGgvqyHKI4Y_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RGTWqZoswAo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RGTWqZoswAo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rgWm0-a0kAo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rgWm0-a0kAo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rG_6MS6_K6g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rG_6MS6_K6g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rh0vBy1JD8A_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rh0vBy1JD8A_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rh2D2OSxyw0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rh2D2OSxyw0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Rhn6K9HCbC8_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Rhn6K9HCbC8_340-350.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RI126_DmGLQ_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RI126_DmGLQ_220-230.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RI71ebbU0PQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RI71ebbU0PQ_0-10.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RIe1omxr7nc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RIe1omxr7nc_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RIiN9Ed1fqU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RIiN9Ed1fqU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RIpfb9LSFe8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RIpfb9LSFe8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RiqtelZs_2I_510-520.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RiqtelZs_2I_510-520.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rizanOQM61k_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rizanOQM61k_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RJViDdqUYyo_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RJViDdqUYyo_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rJZgUpzqAyY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rJZgUpzqAyY_70-80.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rKfpCiJf9do_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rKfpCiJf9do_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rkQPSAHNoeI_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rkQPSAHNoeI_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rKRI5UcIICI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rKRI5UcIICI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rLBGxAj9D14_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rLBGxAj9D14_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RlcIJsgtU58_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RlcIJsgtU58_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rLQ93N6RJC0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rLQ93N6RJC0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RlrNPBfOowg_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RlrNPBfOowg_160-170.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rLtXML8Y5wo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rLtXML8Y5wo_0-10.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RM0RELBtdfc_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RM0RELBtdfc_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RmDfwz0OG8E_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RmDfwz0OG8E_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rmKh9uaikTU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rmKh9uaikTU_30-40.mid\n","1/1 [==============================] - 0s 16ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RmyyW-TMkVc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RmyyW-TMkVc_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RneRJ5ZnHlE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RneRJ5ZnHlE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rNJ0C44bOac_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rNJ0C44bOac_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rNKJXwMz9XQ_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rNKJXwMz9XQ_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rnOIXOGfSUE_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rnOIXOGfSUE_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rnuGOQ-aSjs_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rnuGOQ-aSjs_80-90.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rNUtYf6EdW8_470-480.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rNUtYf6EdW8_470-480.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RNwiEsjrhiQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RNwiEsjrhiQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rn_v88OiRks_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rn_v88OiRks_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ROA6DMBPlNM_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ROA6DMBPlNM_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RoDS0k7qrIo_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RoDS0k7qrIo_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ROM--1yVra8_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ROM--1yVra8_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rOOBAGxxjBk_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rOOBAGxxjBk_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rPAB0ymJGco_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rPAB0ymJGco_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RPqz3vJYMLQ_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RPqz3vJYMLQ_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RQbNC1J4Jfk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RQbNC1J4Jfk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rQcecqZtGvE_590-600.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rQcecqZtGvE_590-600.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RQMUz0NFx6o_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RQMUz0NFx6o_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rrAIuGMTqtA_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rrAIuGMTqtA_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rrWQd5SZK74_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rrWQd5SZK74_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RS43EP1EXz4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RS43EP1EXz4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rs5ecH8Lh3s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rs5ecH8Lh3s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rS8oECcQBCk_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rS8oECcQBCk_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rsCQ1PIGcm0_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rsCQ1PIGcm0_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rsvHQCTgHvg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rsvHQCTgHvg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rTBQmP6Vt0g_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rTBQmP6Vt0g_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RtgHU1UMo5o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RtgHU1UMo5o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RtXe5T7NFrE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RtXe5T7NFrE_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rUIGOcQMaSE_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rUIGOcQMaSE_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RUUZzoeVrK4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RUUZzoeVrK4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RV05BW-2WIc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RV05BW-2WIc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rVdI-aD9pq8_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rVdI-aD9pq8_40-50.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rVDojJcQdE0_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rVDojJcQdE0_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RVevnXD4Fig_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RVevnXD4Fig_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RVlXLa80vcE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RVlXLa80vcE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rVymW4Nb4NU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rVymW4Nb4NU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rW5YKFsiWM8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rW5YKFsiWM8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rWitVrXe5tg_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rWitVrXe5tg_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Rwt8j_USbWI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Rwt8j_USbWI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RXGDlFry3Vo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RXGDlFry3Vo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RXk0lQJ7ttc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RXk0lQJ7ttc_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\RxmGtt0YzYY_580-590.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\RxmGtt0YzYY_580-590.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\rY9zjr9T_WI_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\rY9zjr9T_WI_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\R_HAtyDbw1M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\R_HAtyDbw1M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r_KdRKquXsM_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r_KdRKquXsM_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\r_TgaHCsYB0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\r_TgaHCsYB0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S0W_zIUYwrE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S0W_zIUYwrE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s1c8RF7lKv0_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s1c8RF7lKv0_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s1JHUf3Q_F0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s1JHUf3Q_F0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s1l4Zjqoqdg_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s1l4Zjqoqdg_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s1QeDT7jqHQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s1QeDT7jqHQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S29WiN-bTWo_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S29WiN-bTWo_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s2GctT6NuyQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s2GctT6NuyQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s2iIZ2WNuKY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s2iIZ2WNuKY_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s2O2xaRfje0_360-370.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s2O2xaRfje0_360-370.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S2u5IE0n1ws_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S2u5IE0n1ws_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S2yXmXUJ5xU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S2yXmXUJ5xU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s3Q8pVDY7ZI_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s3Q8pVDY7ZI_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S48GsFznk50_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S48GsFznk50_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s4PN7iTLdVM_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s4PN7iTLdVM_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s59pQGs7Q3E_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s59pQGs7Q3E_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s5kz8qg4B2Y_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s5kz8qg4B2Y_210-220.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s5wdG7xbTNg_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s5wdG7xbTNg_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s6U8DtBK3Us_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s6U8DtBK3Us_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s72505MIhz8_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s72505MIhz8_80-90.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S7igso5_MBE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S7igso5_MBE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S7R3NMq3MKk_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S7R3NMq3MKk_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S7rP6coeLTY_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S7rP6coeLTY_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S7TYAcOEPt4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S7TYAcOEPt4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s7VkXHiULz8_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s7VkXHiULz8_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S8fE5jNVchg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S8fE5jNVchg_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S8WTaKLpmmg_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S8WTaKLpmmg_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S9-i_pqoUCw_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S9-i_pqoUCw_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Sa3Ky5sJshU_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Sa3Ky5sJshU_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\saEDf6EV9wg_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\saEDf6EV9wg_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SBeC9TISHz8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SBeC9TISHz8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sbOBTkrivXM_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sbOBTkrivXM_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SbUwQctvbHg_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SbUwQctvbHg_240-250.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sc7KNFUEdfY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sc7KNFUEdfY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sC7T0sEG6ek_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sC7T0sEG6ek_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ScAlKYCgHV0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ScAlKYCgHV0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SCcryBmDGPw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SCcryBmDGPw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sd1gAgsXMsc_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sd1gAgsXMsc_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Sdnv8043mdk_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Sdnv8043mdk_70-80.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sDoV3sMgDhE_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sDoV3sMgDhE_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SDTsifbpGMM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SDTsifbpGMM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sDX_95H0f9Q_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sDX_95H0f9Q_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SEDfsU63w8I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SEDfsU63w8I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SEHE3WGui30_580-590.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SEHE3WGui30_580-590.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sEIn8YYD9jw_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sEIn8YYD9jw_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sETUDPPoDuo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sETUDPPoDuo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SFHoTmcgw8E_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SFHoTmcgw8E_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sfmAeijj5cM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sfmAeijj5cM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SG24NL2Xi3A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SG24NL2Xi3A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sGAYO93RR5Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sGAYO93RR5Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SGcjdZ19R1k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SGcjdZ19R1k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SGF4N3JHF7Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SGF4N3JHF7Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SGFYFPs3Fic_550-560.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SGFYFPs3Fic_550-560.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sgJT5lIFttM_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sgJT5lIFttM_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sGM6xX5laFU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sGM6xX5laFU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sgTZHSTnU40_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sgTZHSTnU40_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sgVqMKtUMsA_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sgVqMKtUMsA_200-210.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sGVzzQLcT0U_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sGVzzQLcT0U_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sgwvhvkNELc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sgwvhvkNELc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sHbGsZUsisE_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sHbGsZUsisE_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SHYGoXwgKtk_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SHYGoXwgKtk_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sIA-IuTI7AY_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sIA-IuTI7AY_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sIItIq_W3eE_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sIItIq_W3eE_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SijRZIQUa08_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SijRZIQUa08_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Simd4JoehW8_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Simd4JoehW8_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\si_IAMPOXlQ_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\si_IAMPOXlQ_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Sj5MQtqDw8Y_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Sj5MQtqDw8Y_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SJ9TY-iqD9Q_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SJ9TY-iqD9Q_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sjiE5CfyuHU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sjiE5CfyuHU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sJzb2AhqkSg_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sJzb2AhqkSg_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sK6ltq0-zgY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sK6ltq0-zgY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SkFG5SoXsVk_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SkFG5SoXsVk_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SkIDF7iNJQE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SkIDF7iNJQE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SKQbQXPjmvE_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SKQbQXPjmvE_70-80.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SKt_3Nv2DHo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SKt_3Nv2DHo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SkZ7mGbs3SI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SkZ7mGbs3SI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sL01xTmV_Fc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sL01xTmV_Fc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sl37XQfkJCQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sl37XQfkJCQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Sl9ZkYViEIs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Sl9ZkYViEIs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SLcIv8CNk20_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SLcIv8CNk20_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SlnjJv305Vg_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SlnjJv305Vg_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sm7eBFHtdeA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sm7eBFHtdeA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SMjYheNdAzg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SMjYheNdAzg_30-40.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sMNuJy4f4A0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sMNuJy4f4A0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\smU92Nu0FmY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\smU92Nu0FmY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SNhfvhWPXNc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SNhfvhWPXNc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\snJDZAnTMwQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\snJDZAnTMwQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sOJSjVp6UTc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sOJSjVp6UTc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sOyHkcK_lOA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sOyHkcK_lOA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SOzuJU25uGc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SOzuJU25uGc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Sp1YBy4h9OY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Sp1YBy4h9OY_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Sp3T_x3SGzQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Sp3T_x3SGzQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sp77ueBkqS0_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sp77ueBkqS0_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\spyBrs3relU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\spyBrs3relU_60-70.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sQMzHk9MRAI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sQMzHk9MRAI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Sr2Grfi3lFg_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Sr2Grfi3lFg_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sR8rlTIU8_Y_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sR8rlTIU8_Y_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\srEOZzpdhs8_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\srEOZzpdhs8_80-90.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SrLhnoBMyWM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SrLhnoBMyWM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sRxUm-ziCBo_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sRxUm-ziCBo_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ss1bubMNPQE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ss1bubMNPQE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sSavMIH-e-w_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sSavMIH-e-w_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SSO7F_Ex0s4_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SSO7F_Ex0s4_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SsVc1TAVsSc_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SsVc1TAVsSc_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SSVlD_ZDb70_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SSVlD_ZDb70_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\st92BzeUzFU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\st92BzeUzFU_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\stobfk1Mfjk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\stobfk1Mfjk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SU9ZP2pbqyU_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SU9ZP2pbqyU_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SUclDZHax0w_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SUclDZHax0w_120-130.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sUh43prJYMM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sUh43prJYMM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sUjAb0SfppQ_430-440.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sUjAb0SfppQ_430-440.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\suX7Cri4kAo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\suX7Cri4kAo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sVF7NNvdoJc_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sVF7NNvdoJc_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\svNayU6q3Dg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\svNayU6q3Dg_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SW4cW2oU07U_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SW4cW2oU07U_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SwaqANBpZGY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SwaqANBpZGY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SWcEG8RLKsw_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SWcEG8RLKsw_150-160.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SwdhfGXkMCo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SwdhfGXkMCo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Swien0oGl7o_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Swien0oGl7o_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\swIXVQtP_TI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\swIXVQtP_TI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SwRjY1-ojAU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SwRjY1-ojAU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SWyF5TSxWso_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SWyF5TSxWso_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sxgMEmp5aGE_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sxgMEmp5aGE_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sxMYFYDNF_g_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sxMYFYDNF_g_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sXwa1Akj1t0_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sXwa1Akj1t0_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SxYnb9_qDtk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SxYnb9_qDtk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SY6uwVbC944_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SY6uwVbC944_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sYIymaJi6tc_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sYIymaJi6tc_90-100.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sYJiHxmQWjo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sYJiHxmQWjo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\SYVcaQ1Bzu8_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\SYVcaQ1Bzu8_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sZQ4TeLueSs_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sZQ4TeLueSs_210-220.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\szWQPoOH2Rw_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\szWQPoOH2Rw_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\sZwZ2fOWWSg_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\sZwZ2fOWWSg_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s_BKo_1LzJM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s_BKo_1LzJM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\s_LMd1_XN1w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\s_LMd1_XN1w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\S_Z7o4OmU30_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\S_Z7o4OmU30_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t-CjLfu9zCk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t-CjLfu9zCk_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t-CMJ6RsZzY_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t-CMJ6RsZzY_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t-L_PuzR67U_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t-L_PuzR67U_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t-yy7v7P0IE_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t-yy7v7P0IE_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T0oF8MyYhBM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T0oF8MyYhBM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T0OFKHj6878_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T0OFKHj6878_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T0tyLNN7SKA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T0tyLNN7SKA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T0uoYE12cnI_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T0uoYE12cnI_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t12O05LVSBA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t12O05LVSBA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t1ULMDpL35I_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t1ULMDpL35I_70-80.mid\n","1/1 [==============================] - 0s 13ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T2pIUdaDMuA_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T2pIUdaDMuA_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T2zoWLYzEpo_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T2zoWLYzEpo_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t3-xANiQrho_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t3-xANiQrho_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t3758pixHZY_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t3758pixHZY_340-350.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t3Y9Za9roJM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t3Y9Za9roJM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t5P_HJrrD64_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t5P_HJrrD64_90-100.mid\n","18/32 [===============>..............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t5RqDGLiDvo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t5RqDGLiDvo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T5YZwhC7Br8_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T5YZwhC7Br8_220-230.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t637ILYjH_A_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t637ILYjH_A_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t6jlx6jAb-Q_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t6jlx6jAb-Q_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t6XtW3SHQNE_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t6XtW3SHQNE_380-390.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T78nMdsJMmk_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T78nMdsJMmk_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T7A0RejsZIo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T7A0RejsZIo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T7bG4kIEw-M_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T7bG4kIEw-M_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T7khbuOBHbo_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T7khbuOBHbo_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t7oAteGa55g_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t7oAteGa55g_90-100.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 1s 16ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T7ZSZhcsfjA_9-19.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T7ZSZhcsfjA_9-19.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t8os583-_JM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t8os583-_JM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t8SLY7xn7Sc_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t8SLY7xn7Sc_80-90.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T8U3ihbHh9A_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T8U3ihbHh9A_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t8uF3PZ3KGQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t8uF3PZ3KGQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\t9aSL2MwEDM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\t9aSL2MwEDM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T9dKp1EN4p8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T9dKp1EN4p8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T9fk99yqwN4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T9fk99yqwN4_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TA-O_bVnvLY_540-550.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TA-O_bVnvLY_540-550.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TabaOeYq2ek_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TabaOeYq2ek_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tAdNaRRFFXg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tAdNaRRFFXg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TArWNq2retM_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TArWNq2retM_200-210.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TbA_TZn35LA_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TbA_TZn35LA_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tBKOvAiNOQE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tBKOvAiNOQE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tbovKStEnME_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tbovKStEnME_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TbYahEEj_B4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TbYahEEj_B4_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TC4mH6nACm8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TC4mH6nACm8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tc7crRl2JqA_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tc7crRl2JqA_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TcJ7rdYMHiQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TcJ7rdYMHiQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tcOHcop3sCQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tcOHcop3sCQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TcoRmHHHNgI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TcoRmHHHNgI_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TCRxCAYyduo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TCRxCAYyduo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TdHdD1wxu_0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TdHdD1wxu_0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tdrz4EkIsow_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tdrz4EkIsow_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tdTT6rmkk9M_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tdTT6rmkk9M_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tDVOUsG52Jw_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tDVOUsG52Jw_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TdvwUwpYYos_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TdvwUwpYYos_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tDZPGf8WYmI_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tDZPGf8WYmI_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tEdeb9eSKDI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tEdeb9eSKDI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TEoDtxjlctA_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TEoDtxjlctA_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TEWYFkjH2jc_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TEWYFkjH2jc_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\teyDfFbVMSY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\teyDfFbVMSY_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TFLt7mn57ZI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TFLt7mn57ZI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tG5C-Smp-eY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tG5C-Smp-eY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TgCv5a22YUU_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TgCv5a22YUU_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tGic59TlrVg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tGic59TlrVg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TgOr_C6xP6U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TgOr_C6xP6U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tGUWSgewh0A_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tGUWSgewh0A_270-280.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tGv_L09pf6E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tGv_L09pf6E_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Th6Tf6kA8RU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Th6Tf6kA8RU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\THfTLXBLpJE_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\THfTLXBLpJE_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\THhptTKMr9U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\THhptTKMr9U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\thHSYzhoLo4_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\thHSYzhoLo4_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TIAj-fi_R7c_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TIAj-fi_R7c_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TIASpLtI8ks_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TIASpLtI8ks_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TiDdR-6bIcY_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TiDdR-6bIcY_90-100.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TIL8jEw8pSc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TIL8jEw8pSc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TiOBlG-R1Y4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TiOBlG-R1Y4_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tIRHm8VhK_4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tIRHm8VhK_4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tIS1Jaw9dCg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tIS1Jaw9dCg_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tJHFSRTPyew_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tJHFSRTPyew_120-130.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tjQTZM-sqS0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tjQTZM-sqS0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tJWduBZRJkE_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tJWduBZRJkE_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TJyzBaMwXFY_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TJyzBaMwXFY_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tKawN2sxhYc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tKawN2sxhYc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TkHZdMJPwKc_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TkHZdMJPwKc_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TKSFbf-wQ8I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TKSFbf-wQ8I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tlDBOenCGV4_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tlDBOenCGV4_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tllFsEPv7Ls_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tllFsEPv7Ls_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TLMEsc_42Gw_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TLMEsc_42Gw_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tmabzx6yxqs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tmabzx6yxqs_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tMICtalfpSc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tMICtalfpSc_60-70.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tMMjurLqYJQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tMMjurLqYJQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TN53jpjqAGI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TN53jpjqAGI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TnCXmm-v3Ys_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TnCXmm-v3Ys_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tnDUwvxQU3k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tnDUwvxQU3k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tnJb9WyhCUc_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tnJb9WyhCUc_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TnJE6W6Z6mM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TnJE6W6Z6mM_30-40.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tnSM-SnE5Lk_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tnSM-SnE5Lk_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tOb0M2k3deo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tOb0M2k3deo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TObYoD2pGb0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TObYoD2pGb0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TokHdpvX7Es_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TokHdpvX7Es_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tOnjlUzqSC4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tOnjlUzqSC4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\too9MtXBwts_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\too9MtXBwts_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Tp8PG2xae8c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Tp8PG2xae8c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TPdqEmS1Dr0_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TPdqEmS1Dr0_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tPJMr890HeE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tPJMr890HeE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tpnvHb9ZhlU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tpnvHb9ZhlU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tPVsTFGWU5Q_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tPVsTFGWU5Q_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TPYNIc_M1ng_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TPYNIc_M1ng_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tQ1Nl4Dy2aI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tQ1Nl4Dy2aI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TqIptTnXb20_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TqIptTnXb20_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TqWmuwAYmnI_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TqWmuwAYmnI_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tr2iVjsu4xs_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tr2iVjsu4xs_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tRA-5inwlMI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tRA-5inwlMI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TrvI6t4pAP0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TrvI6t4pAP0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ts04bBeY1d4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ts04bBeY1d4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tsdNl72WVs4_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tsdNl72WVs4_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TSl5LrM6LcQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TSl5LrM6LcQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Tsmx6Pb7CnU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Tsmx6Pb7CnU_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TsTdffJ9LHg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TsTdffJ9LHg_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Tt3BnoJw8ds_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Tt3BnoJw8ds_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tt5-i1R78ms_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tt5-i1R78ms_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tu3IrmT_2xk_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tu3IrmT_2xk_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tUBTRs7Avk0_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tUBTRs7Avk0_130-140.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tUJ_ZniLjhc_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tUJ_ZniLjhc_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tuoBmxts5Xo_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tuoBmxts5Xo_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tUppIOzUo2Q_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tUppIOzUo2Q_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tUZB_Xf1m6k_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tUZB_Xf1m6k_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tv14XEQcY0c_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tv14XEQcY0c_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tV2m7HFJprU_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tV2m7HFJprU_230-240.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tV3rvUSlVnY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tV3rvUSlVnY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tvcJENqxr1c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tvcJENqxr1c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tvqvuGywD8U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tvqvuGywD8U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Tvwi_YuLehk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Tvwi_YuLehk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tw0BGErgupk_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tw0BGErgupk_80-90.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tW7478HnmCs_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tW7478HnmCs_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tw8-TlQBcBA_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tw8-TlQBcBA_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tWByqbOvYQE_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tWByqbOvYQE_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tWexzTJPxQs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tWexzTJPxQs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TWm0OilO0uw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TWm0OilO0uw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TWm_2QncYXg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TWm_2QncYXg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TWnrcjA6VTk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TWnrcjA6VTk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tWseBEYhE1M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tWseBEYhE1M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TWV3YLscSaw_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TWV3YLscSaw_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tWwvTUm9RXs_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tWwvTUm9RXs_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TX9PGFdqRak_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TX9PGFdqRak_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tyAXjOihm6g_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tyAXjOihm6g_240-250.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TyMZJqYmrwE_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TyMZJqYmrwE_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tz2TlSMmTp4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tz2TlSMmTp4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\tZgww16UyU8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\tZgww16UyU8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TZlFTbvfKPE_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TZlFTbvfKPE_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\TzPuAqjoL80_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\TzPuAqjoL80_60-70.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\T_d82v2g93w_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\T_d82v2g93w_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U-L9YCIdLbg_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U-L9YCIdLbg_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U-UF93NA3ko_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U-UF93NA3ko_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u0CgRmXMXNc_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u0CgRmXMXNc_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u0lm58cet1g_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u0lm58cet1g_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U0sjbOT6hY4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U0sjbOT6hY4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U0xhbrULfNY_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U0xhbrULfNY_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u1a5eyk-9ig_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u1a5eyk-9ig_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u3pYqyLM0f4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u3pYqyLM0f4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U3TpCc2zHrI_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U3TpCc2zHrI_20-30.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u3yOMK8SuRI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u3yOMK8SuRI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U4MdEIQcZxs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U4MdEIQcZxs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U4UtZeTl2DE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U4UtZeTl2DE_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u68Ghaf_Phs_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u68Ghaf_Phs_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U6aLiMIlqCc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U6aLiMIlqCc_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U6SYfguaJtk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U6SYfguaJtk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u6tgeRXOxnU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u6tgeRXOxnU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u8aB6EALonk_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u8aB6EALonk_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U8XdDv5ERu4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U8XdDv5ERu4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\U8yqYlErUz8_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\U8yqYlErUz8_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u9n4R78UBtA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u9n4R78UBtA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uA-JpZppFsc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uA-JpZppFsc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ua0hgl8fi0I_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ua0hgl8fi0I_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uAgizG1hYw0_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uAgizG1hYw0_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uARzr9CAemI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uARzr9CAemI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uAYPacrJnyQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uAYPacrJnyQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uBENjCPS8LI_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uBENjCPS8LI_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UBfHLeCBBsA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UBfHLeCBBsA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ubj0jlheyvk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ubj0jlheyvk_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UcabTrKowlI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UcabTrKowlI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UCBocxMCdck_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UCBocxMCdck_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uCCdUB7D10U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uCCdUB7D10U_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UcNVLU-cRNg_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UcNVLU-cRNg_340-350.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UcS5U1mpbAE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UcS5U1mpbAE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ucSF9NIxK8A_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ucSF9NIxK8A_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uCXI7dgABHI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uCXI7dgABHI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Uc_1PzGr5xw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Uc_1PzGr5xw_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UC_XpUcIQ_8_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UC_XpUcIQ_8_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UD0pisqyLKA_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UD0pisqyLKA_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UDg9vuBDtVU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UDg9vuBDtVU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UDN11Q90Fa4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UDN11Q90Fa4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\udQQrQB-gr4_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\udQQrQB-gr4_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uDqVzJtaxOc_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uDqVzJtaxOc_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UDS6PrY9ZIM_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UDS6PrY9ZIM_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UDTsCTLkZzc_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UDTsCTLkZzc_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ue1sgGEvkwE_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ue1sgGEvkwE_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uE3BHXXiCFs_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uE3BHXXiCFs_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UEel3wTf0Sk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UEel3wTf0Sk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uegzZWp6Y4w_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uegzZWp6Y4w_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UEOUXjX5R2I_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UEOUXjX5R2I_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UeYmnV-B8so_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UeYmnV-B8so_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uF1KTW5rT-s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uF1KTW5rT-s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UfEGX0rNOvA_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UfEGX0rNOvA_70-80.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UFyOGqmITjM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UFyOGqmITjM_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UfZP677y3Dc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UfZP677y3Dc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UGEqY_NTMpI_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UGEqY_NTMpI_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uGfd3xanwro_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uGfd3xanwro_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uGQ7QnKqeY4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uGQ7QnKqeY4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uHgpDP_4Lsc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uHgpDP_4Lsc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UHvYrO1IGCc_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UHvYrO1IGCc_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UhwJrftWAFg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UhwJrftWAFg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ui6ERk-AySw_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ui6ERk-AySw_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uiHyWdYkBvY_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uiHyWdYkBvY_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UiiYMspxfhU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UiiYMspxfhU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UinQGYfmZhE_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UinQGYfmZhE_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UIOnnpaqBy8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UIOnnpaqBy8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UJA5AWbt6HM_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UJA5AWbt6HM_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UJAk1nNdo1I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UJAk1nNdo1I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uJPW9BEhU6Y_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uJPW9BEhU6Y_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uKGo4phKqLM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uKGo4phKqLM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uknhELOFYmY_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uknhELOFYmY_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UkqayNnk00w_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UkqayNnk00w_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UkTWmyy7ia8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UkTWmyy7ia8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UkZ76EFfLSg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UkZ76EFfLSg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ULHPhjaJ6p0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ULHPhjaJ6p0_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uLp6z37bfVE_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uLp6z37bfVE_230-240.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ULXbXpLcoVA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ULXbXpLcoVA_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\un-OXLWhvDc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\un-OXLWhvDc_10-20.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UnFEqUWTefM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UnFEqUWTefM_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UNJswfXKJ3s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UNJswfXKJ3s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uNUx8rqcy0M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uNUx8rqcy0M_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Uo-Okq1D8Xo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Uo-Okq1D8Xo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UOAv5b6MGxw_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UOAv5b6MGxw_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uoee1ikakWY_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uoee1ikakWY_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UOKWQ2EHJQI_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UOKWQ2EHJQI_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UoSID1KzWuI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UoSID1KzWuI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UoxHwOl2gN0_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UoxHwOl2gN0_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uoZ9Rs4E-6Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uoZ9Rs4E-6Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uPGasFKZSBo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uPGasFKZSBo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UPPHkyd7lwE_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UPPHkyd7lwE_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uqAY4lCUcRY_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uqAY4lCUcRY_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UQKLBsZJsww_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UQKLBsZJsww_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uQTCfT5XDzQ_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uQTCfT5XDzQ_40-50.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uqUNGNZoxrg_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uqUNGNZoxrg_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UR3k09hOxI4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UR3k09hOxI4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ur8O3h8S0K4_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ur8O3h8S0K4_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uRA5Ue30fsY_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uRA5Ue30fsY_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ura8EjHjGC4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ura8EjHjGC4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UrgzGbGVV8I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UrgzGbGVV8I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\URM1QgX5Ar4_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\URM1QgX5Ar4_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uS2kPLvEo6A_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uS2kPLvEo6A_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\US3ZL2zhXgI_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\US3ZL2zhXgI_180-190.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UsdoUjuczY4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UsdoUjuczY4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UsHtZ7Bzi0s_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UsHtZ7Bzi0s_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\usrzF-0GbLY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\usrzF-0GbLY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uSZQGP_i3gs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uSZQGP_i3gs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uT-S_JC_GzU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uT-S_JC_GzU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UtCRBs5p4EQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UtCRBs5p4EQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uTfLf1Y8hhM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uTfLf1Y8hhM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Utl5it7YMUs_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Utl5it7YMUs_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UtZofZjccBs_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UtZofZjccBs_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uuHTPvG-BYI_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uuHTPvG-BYI_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UUJ1DNycpiQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UUJ1DNycpiQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uUNlJ4KZTPE_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uUNlJ4KZTPE_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uUoEB3DBSjo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uUoEB3DBSjo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UvCY9FHpKC8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UvCY9FHpKC8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UVMBRVJTvzg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UVMBRVJTvzg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Uvn7waPvseo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Uvn7waPvseo_30-40.mid\n","13/32 [===========>..................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UVY68vFiApA_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UVY68vFiApA_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UWl99yJsb8M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UWl99yJsb8M_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uwPeQy7ZtGo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uwPeQy7ZtGo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UwxatzcYf9Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UwxatzcYf9Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ux1vBolJf5Q_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ux1vBolJf5Q_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ux3YosKD-9I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ux3YosKD-9I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UXDzDV_f1jw_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UXDzDV_f1jw_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UxlrI-9RtWg_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UxlrI-9RtWg_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uxLY3CBoPo8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uxLY3CBoPo8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uXMMzpgrY2g_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uXMMzpgrY2g_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UxT3KG4AHAI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UxT3KG4AHAI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Uxyu3XwXEV8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Uxyu3XwXEV8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UY2_Q830lqo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UY2_Q830lqo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uy3nQ9VYE-Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uy3nQ9VYE-Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uYCAxX2F6DA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uYCAxX2F6DA_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uYCMVgUAwnM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uYCMVgUAwnM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uYYpqx0rzok_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uYYpqx0rzok_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\UzDVZzIIcy8_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\UzDVZzIIcy8_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uZesGREO0eI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uZesGREO0eI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\uZHE9b1WDuM_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\uZHE9b1WDuM_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\u_TfWvyYY0Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\u_TfWvyYY0Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v0tYHz5mk4I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v0tYHz5mk4I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V0zQHNmz0gU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V0zQHNmz0gU_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V1A4wBgvPgI_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V1A4wBgvPgI_250-260.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v1EDTMRmJlY_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v1EDTMRmJlY_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V1M3HiUz0ZQ_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V1M3HiUz0ZQ_70-80.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v29jCrlSCmE_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v29jCrlSCmE_250-260.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v2Ng8iGwf40_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v2Ng8iGwf40_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V3Jb0Q_e_pQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V3Jb0Q_e_pQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V3Vvp5HS90k_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V3Vvp5HS90k_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v3wR3aIQ23w_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v3wR3aIQ23w_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v4sANJkuwP4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v4sANJkuwP4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V4YUpQKeKD4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V4YUpQKeKD4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v582kPp43Mg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v582kPp43Mg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v592zQpuaJA_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v592zQpuaJA_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V5HMIxuAtv8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V5HMIxuAtv8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v5nB2OJnCko_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v5nB2OJnCko_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v5SsASLy2c8_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v5SsASLy2c8_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V5xL8hLFY58_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V5xL8hLFY58_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v88cAXP03As_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v88cAXP03As_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v8bBrrXUpdo_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v8bBrrXUpdo_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V9EFYFKlYbE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V9EFYFKlYbE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\V9jIsOTC1lY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\V9jIsOTC1lY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\v9TTtjEngjY_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\v9TTtjEngjY_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VAqgpoyD2jc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VAqgpoyD2jc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VAqPLAgn9NI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VAqPLAgn9NI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VB82vMSTYK0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VB82vMSTYK0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vBkDLBO-Aok_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vBkDLBO-Aok_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vBw99ghST1g_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vBw99ghST1g_10-20.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vbx6TFxSPYY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vbx6TFxSPYY_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vByuZEzCZJg_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vByuZEzCZJg_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VCIN1OJkNbg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VCIN1OJkNbg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VCrnnx9jTqs_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VCrnnx9jTqs_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VCusyLPrFCo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VCusyLPrFCo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vd1dgdxlA94_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vd1dgdxlA94_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vDmUlgsDOP4_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vDmUlgsDOP4_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vDrbslhtX8o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vDrbslhtX8o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VdYakZ4Yciw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VdYakZ4Yciw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ve6Zy1BXBbY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ve6Zy1BXBbY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VeAomElRCJc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VeAomElRCJc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vEl7ImwLlrA_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vEl7ImwLlrA_180-190.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vEMNk-lbGTE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vEMNk-lbGTE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vEN9szBPBkw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vEN9szBPBkw_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vEt13GxzDKk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vEt13GxzDKk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VeXcCHo5iMI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VeXcCHo5iMI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vf3n40mDLHw_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vf3n40mDLHw_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VfARCp38XtA_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VfARCp38XtA_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vfcfj4OIJXE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vfcfj4OIJXE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VfEJHqtsuIo_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VfEJHqtsuIo_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vfMEPOl1Wqw_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vfMEPOl1Wqw_10-20.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vfscNjNneZg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vfscNjNneZg_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vG0FGgJlDGw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vG0FGgJlDGw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vG0QJ3bjfqk_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vG0QJ3bjfqk_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VG6-MlmCgzI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VG6-MlmCgzI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vgpV6F9tge8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vgpV6F9tge8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VgwsGjRk61M_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VgwsGjRk61M_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vhTWW5Bx15Q_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vhTWW5Bx15Q_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VHYxygh1STA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VHYxygh1STA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ViF7A7XODiw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ViF7A7XODiw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vispMqNJ1j8_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vispMqNJ1j8_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VJ-dpTx_3Cg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VJ-dpTx_3Cg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VJ1RqPqF9O4_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VJ1RqPqF9O4_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VjbRot21Hq0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VjbRot21Hq0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vjW8wmF5VWc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vjW8wmF5VWc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VjXt63pqUgw_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VjXt63pqUgw_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vK9x7UQ9Y7k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vK9x7UQ9Y7k_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vKjC5HTH22o_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vKjC5HTH22o_160-170.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vKNGqQ3GRB8_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vKNGqQ3GRB8_90-100.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VkVKGyWi2r4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VkVKGyWi2r4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VkXLtUx-RmI_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VkXLtUx-RmI_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VL6uF-XeE_A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VL6uF-XeE_A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VlgOLOoctm0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VlgOLOoctm0_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VLjcIlZvkY0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VLjcIlZvkY0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VlwbDjggUKk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VlwbDjggUKk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VlXi2TxMXbc_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VlXi2TxMXbc_130-140.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vmBkZflwViA_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vmBkZflwViA_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vMU7ZKY2Eso_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vMU7ZKY2Eso_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vmVOWilkmOA_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vmVOWilkmOA_210-220.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VMWW9OX1EJM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VMWW9OX1EJM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vmz9kAEiTSc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vmz9kAEiTSc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VMzn9GytUTk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VMzn9GytUTk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VnJeG9RGUVM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VnJeG9RGUVM_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VNjYW4OXqTs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VNjYW4OXqTs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vNPx6RS8PiM_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vNPx6RS8PiM_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vnwKpQeza3A_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vnwKpQeza3A_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VNzEAjztgxg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VNzEAjztgxg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vo-o3dG8Oq0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vo-o3dG8Oq0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vo6eT8eMMfQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vo6eT8eMMfQ_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vOiDwXo-SuM_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vOiDwXo-SuM_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vOU-qA25xNM_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vOU-qA25xNM_260-270.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VOWGbyg4KZY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VOWGbyg4KZY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VP1cB_AVu6c_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VP1cB_AVu6c_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vp6p45b-038_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vp6p45b-038_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vpcEBryyej4_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vpcEBryyej4_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VpIhbDN58mA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VpIhbDN58mA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VpikuLP_9qQ_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VpikuLP_9qQ_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vpU4XIISXtM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vpU4XIISXtM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vQ09gQBt1IU_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vQ09gQBt1IU_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vQcB6NI7cMo_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vQcB6NI7cMo_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vqRFzhWik2c_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vqRFzhWik2c_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vr7wbGcvFts_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vr7wbGcvFts_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VRfi64fecj4_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VRfi64fecj4_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vrNQbCbBlLY_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vrNQbCbBlLY_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VrqBeY3kfKI_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VrqBeY3kfKI_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vrxT5jhqu0Q_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vrxT5jhqu0Q_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VsMy72BoIbU_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VsMy72BoIbU_40-50.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vStedb9LiDk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vStedb9LiDk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VswY2mI7Wbo_360-370.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VswY2mI7Wbo_360-370.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vsXs3GUrw64_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vsXs3GUrw64_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vt3HzkNtOP4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vt3HzkNtOP4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VTagIq90b7s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VTagIq90b7s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VtHkxrta5xQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VtHkxrta5xQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vtnuHbHbveg_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vtnuHbHbveg_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VTOf24hbq0A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VTOf24hbq0A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vTXb8P7sAFY_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vTXb8P7sAFY_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vukJyd8xt0I_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vukJyd8xt0I_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VuWr1HXHoZg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VuWr1HXHoZg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VV-DgnPPhSo_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VV-DgnPPhSo_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VV85n-ebuUU_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VV85n-ebuUU_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vvfs2TUj-D4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vvfs2TUj-D4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vwekk3EOa-U_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vwekk3EOa-U_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vWiq7n4yTAw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vWiq7n4yTAw_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VwkRHbqpHqk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VwkRHbqpHqk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vWM2qG-nU-Y_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vWM2qG-nU-Y_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vx4aO4-nr0c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vx4aO4-nr0c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vx5iuWuE2Ng_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vx5iuWuE2Ng_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vxIF3B4YqW8_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vxIF3B4YqW8_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vXtk2JEP0zM_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vXtk2JEP0zM_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vx_vqfpRdUU_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vx_vqfpRdUU_100-110.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Vy00ycBpqpc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Vy00ycBpqpc_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vy2gUzgmBzQ_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vy2gUzgmBzQ_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vykrv5BaW-s_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vykrv5BaW-s_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vyNstX5b1V8_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vyNstX5b1V8_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vYP60jdTupc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vYP60jdTupc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vZ9IanI59gE_550-560.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vZ9IanI59gE_550-560.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VzFpg271sm8_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VzFpg271sm8_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VZfrDZhI7BU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VZfrDZhI7BU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VzGHr0aV220_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VzGHr0aV220_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VZjE27e9X7o_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VZjE27e9X7o_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VZJfkEet6EQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VZJfkEet6EQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\vZUup6rK728_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\vZUup6rK728_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\VzYc-c-uHjI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\VzYc-c-uHjI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W-nkxlYTdV4_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W-nkxlYTdV4_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w-qG-P9E1U4_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w-qG-P9E1U4_500-510.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w-YAUcPl-HU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w-YAUcPl-HU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W00eTCOgUNs_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W00eTCOgUNs_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w09XinexaIY_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w09XinexaIY_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w0A-4EbkVz8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w0A-4EbkVz8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w0QJT6ywza0_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w0QJT6ywza0_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w0yHqPxybQE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w0yHqPxybQE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W2EJai-3k2w_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W2EJai-3k2w_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W2KaBnoGxek_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W2KaBnoGxek_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w2MeQg3W7Po_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w2MeQg3W7Po_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W2nlA65AwtU_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W2nlA65AwtU_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w2vMywh5Nto_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w2vMywh5Nto_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w35p3oCU0g4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w35p3oCU0g4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W3DwueAy65k_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W3DwueAy65k_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W3lKc2hj4XU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W3lKc2hj4XU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w3QIsHxQfPE_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w3QIsHxQfPE_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w41gqTFYh08_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w41gqTFYh08_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w4ayJNZ5w5o_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w4ayJNZ5w5o_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W4eLgBYEEqA_440-450.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W4eLgBYEEqA_440-450.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w4Z1QuBOMWU_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w4Z1QuBOMWU_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W58kioYp1Ms_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W58kioYp1Ms_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W5BB6pubJZI_540-550.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W5BB6pubJZI_540-550.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w5EbmsPfGSo_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w5EbmsPfGSo_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w5qf9O6c20o_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w5qf9O6c20o_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w62KGC7um_Y_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w62KGC7um_Y_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w6MtzUCl4vM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w6MtzUCl4vM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w6zHc6nRJ0o_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w6zHc6nRJ0o_220-230.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W7i4LkdSfjw_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W7i4LkdSfjw_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W7KbboEOmeM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W7KbboEOmeM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W7U-glgu4GM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W7U-glgu4GM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w8c7JFU6by4_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w8c7JFU6by4_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W8Xv3Q2kGRA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W8Xv3Q2kGRA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w9CxACZ5Oi0_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w9CxACZ5Oi0_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w9EGDo9Yybc_530-540.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w9EGDo9Yybc_530-540.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WaddbqEQ1NE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WaddbqEQ1NE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WAxDN-FyPn8_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WAxDN-FyPn8_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wBozBh7BR6k_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wBozBh7BR6k_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wC0mY7NzihY_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wC0mY7NzihY_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wc4UEh8wvCA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wc4UEh8wvCA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WcC9sKxJ1gI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WcC9sKxJ1gI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WCifI6rwOoM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WCifI6rwOoM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WCiS9IDILQg_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WCiS9IDILQg_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WCl93HBuj60_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WCl93HBuj60_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wcLPCMoy5hk_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wcLPCMoy5hk_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wd4T3iTsgrI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wd4T3iTsgrI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WditOomsdRU_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WditOomsdRU_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wDpz90boBzU_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wDpz90boBzU_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wdtku1dqJo0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wdtku1dqJo0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WdxNikVdK-U_410-420.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WdxNikVdK-U_410-420.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\We-bFXFjWaM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\We-bFXFjWaM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WE0JqjuhaQI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WE0JqjuhaQI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\We9P_UcHNk8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\We9P_UcHNk8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WeDA1mDFSCo_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WeDA1mDFSCo_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wEHRmd84Dwc_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wEHRmd84Dwc_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\weJKl-6TiDQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\weJKl-6TiDQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Weu8nsJRMqE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Weu8nsJRMqE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WEVBqGarEIY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WEVBqGarEIY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WEXJSNm_T0o_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WEXJSNm_T0o_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WFPGA_BYkKU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WFPGA_BYkKU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wgf7UYPVoAo_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wgf7UYPVoAo_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wGievbsKUnk_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wGievbsKUnk_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wgIf0FX6WzI_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wgIf0FX6WzI_290-300.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WgZ8KAnnTb8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WgZ8KAnnTb8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wg_kYW4xvz4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wg_kYW4xvz4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wh5JSj89tW8_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wh5JSj89tW8_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WhEd8h7J0Lk_360-370.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WhEd8h7J0Lk_360-370.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\whIj6mrUGzQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\whIj6mrUGzQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WhNun_U3cRU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WhNun_U3cRU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\whZygh228yw_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\whZygh228yw_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wh_g-Eiw9Kc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wh_g-Eiw9Kc_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WI2d5vDJeLo_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WI2d5vDJeLo_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WiAFUo2nxIk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WiAFUo2nxIk_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wil8e6kBxe8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wil8e6kBxe8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wIP7AqIOU1s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wIP7AqIOU1s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WIuLaxWIAAI_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WIuLaxWIAAI_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wj4ukZFNEgs_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wj4ukZFNEgs_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WJIrkvEq4EI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WJIrkvEq4EI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WJORWlj6BW8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WJORWlj6BW8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WjPHxUtF9go_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WjPHxUtF9go_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WK-gdfCurCg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WK-gdfCurCg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wKE9STHwX-Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wKE9STHwX-Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WkkhcwXpYy4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WkkhcwXpYy4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wKoFJHb2BoI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wKoFJHb2BoI_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wLITXWAuZy0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wLITXWAuZy0_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wMelBK3yArA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wMelBK3yArA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wMHBhCVv--g_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wMHBhCVv--g_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wMN-Xp9IMUw_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wMN-Xp9IMUw_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WmTDKYYH5OU_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WmTDKYYH5OU_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WMtztIW1f6k_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WMtztIW1f6k_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WmyHFkyiiF8_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WmyHFkyiiF8_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WmyhSRhWh3k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WmyhSRhWh3k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wnl0qbVynL4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wnl0qbVynL4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WNmAlKrAPjQ_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WNmAlKrAPjQ_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WNv-YNn1cZ8_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WNv-YNn1cZ8_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\woVby8SBWDI_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\woVby8SBWDI_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WoWF7gGzGVY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WoWF7gGzGVY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WoXgPQQjcJU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WoXgPQQjcJU_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WO_Y7djT2k4_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WO_Y7djT2k4_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wp5AiCmbQjA_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wp5AiCmbQjA_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WPguqXCBQCI_328-338.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WPguqXCBQCI_328-338.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wPmTJWybq_E_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wPmTJWybq_E_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WqC-fx3uNVE_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WqC-fx3uNVE_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wQhycJsKSPE_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wQhycJsKSPE_340-350.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wQN7fRaPl2A_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wQN7fRaPl2A_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WQsuFvw43RA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WQsuFvw43RA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wr5sFgqxLzQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wr5sFgqxLzQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wR7n4Gg-_ac_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wR7n4Gg-_ac_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wraN7rWUsfI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wraN7rWUsfI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WrpWb-Zumnc_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WrpWb-Zumnc_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wRWxsKN394Q_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wRWxsKN394Q_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WRZGYDh7qRo_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WRZGYDh7qRo_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WSaCGNkM6_k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WSaCGNkM6_k_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WsaOJT2SsPg_47-57.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WsaOJT2SsPg_47-57.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WsDb16qzA5Q_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WsDb16qzA5Q_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wsdH6cv4YkA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wsdH6cv4YkA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wsJ5ZLKiPzs_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wsJ5ZLKiPzs_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wt-f7K_suBc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wt-f7K_suBc_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WT2iyJmKkc8_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WT2iyJmKkc8_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wT2Y0DCq5LI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wT2Y0DCq5LI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WtN6uiDikRM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WtN6uiDikRM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wTPI3MHqxSQ_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wTPI3MHqxSQ_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WT_wvvEvkw4_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WT_wvvEvkw4_230-240.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wu-Oh9OJIlI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wu-Oh9OJIlI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wu3LKQG1fwU_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wu3LKQG1fwU_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wv6YaiCGPi0_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wv6YaiCGPi0_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WvaIypMvAHY_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WvaIypMvAHY_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wvg5rlMbjJc_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wvg5rlMbjJc_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Wvh59Y4OzUM_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Wvh59Y4OzUM_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WW4_c2J79QA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WW4_c2J79QA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wwbATvWFaLY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wwbATvWFaLY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wwHi10qX8u8_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wwHi10qX8u8_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WWIT13tTW7c_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WWIT13tTW7c_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WxgolzWTmO4_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WxgolzWTmO4_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wxKtBDKasgM_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wxKtBDKasgM_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wXmIm6Bq3Tc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wXmIm6Bq3Tc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wXWpkfGfZD8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wXWpkfGfZD8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WY73T0xaY0A_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WY73T0xaY0A_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WYbD9YUrf_4_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WYbD9YUrf_4_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WyGJdstaxK4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WyGJdstaxK4_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WySgNm8qH-I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WySgNm8qH-I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wYtd_Sq2-Tw_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wYtd_Sq2-Tw_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WYxXUBP_XaM_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WYxXUBP_XaM_210-220.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wz-7sy_Rin4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wz-7sy_Rin4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\WZd2nT2Afds_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\WZd2nT2Afds_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\wZopmfXTtxw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\wZopmfXTtxw_30-40.mid\n","21/32 [==================>...........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W_979HkE4EI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W_979HkE4EI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W_MZo88gzrA_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W_MZo88gzrA_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w_XFNKSRgKI_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w_XFNKSRgKI_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\w_z9oSn-eIM_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\w_z9oSn-eIM_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\W_zgEkvp4xU_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\W_zgEkvp4xU_140-150.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x-ob6_6f4jQ_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x-ob6_6f4jQ_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X-uVubaJ3II_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X-uVubaJ3II_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X0MN34Us6eE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X0MN34Us6eE_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x14jW4c8YnQ_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x14jW4c8YnQ_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X1KJfb5xhr4_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X1KJfb5xhr4_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x1KyLxsnJY0_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x1KyLxsnJY0_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x1S2oreZBWU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x1S2oreZBWU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x1x54MgStxQ_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x1x54MgStxQ_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X1_RmTiDC4I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X1_RmTiDC4I_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x22NHqwKSNE_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x22NHqwKSNE_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X28GWrn9LlI_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X28GWrn9LlI_110-120.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X2gHQb5ubco_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X2gHQb5ubco_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x6FbyqrK0g0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x6FbyqrK0g0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X6Q53uXgaHc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X6Q53uXgaHc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X7LrhZX4rdU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X7LrhZX4rdU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x85BtdoxRek_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x85BtdoxRek_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X96v9LlsjJM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X96v9LlsjJM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x9bcsYF_by8_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x9bcsYF_by8_230-240.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X9H8FzpVL8s_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X9H8FzpVL8s_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\x9xXU30ktcY_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\x9xXU30ktcY_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XalMIYYgHt0_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XalMIYYgHt0_130-140.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xaq-segSEsQ_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xaq-segSEsQ_160-170.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XaqVAF-ADWU_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XaqVAF-ADWU_10-20.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XaUXJG0BZuk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XaUXJG0BZuk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xb07gLlmkL8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xb07gLlmkL8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xBDcJKb-9vk_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xBDcJKb-9vk_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xCLzxuZE3yg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xCLzxuZE3yg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XcvY-NdM8WA_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XcvY-NdM8WA_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XDBxMQrRaFY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XDBxMQrRaFY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XdxTZ4-sJvY_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XdxTZ4-sJvY_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XE4NRSDLYG8_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XE4NRSDLYG8_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xe59DpKa-O4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xe59DpKa-O4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xe9vDoF8TQM_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xe9vDoF8TQM_60-70.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xeHt-R5ScmI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xeHt-R5ScmI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XEIP1OUXU8E_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XEIP1OUXU8E_140-150.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xf0aZ3a3Toc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xf0aZ3a3Toc_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XfdySM4X9Xo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XfdySM4X9Xo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XfLI8gHCuFE_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XfLI8gHCuFE_90-100.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XfLIbeSJSHE_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XfLIbeSJSHE_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XFuw-m2gYOQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XFuw-m2gYOQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xGHN0kphhWM_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xGHN0kphhWM_50-60.mid\n","1/1 [==============================] - 0s 12ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XgLUXNAC7b8_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XgLUXNAC7b8_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XgOA5oRkL2A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XgOA5oRkL2A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xgwzTQ8vnso_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xgwzTQ8vnso_30-40.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xgXd06kKFIQ_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xgXd06kKFIQ_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XgXOW3lX25Y_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XgXOW3lX25Y_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XHczpbtBhk4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XHczpbtBhk4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xhOsZuB_Zqc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xhOsZuB_Zqc_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XhV4zf-Xlmk_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XhV4zf-Xlmk_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XI-tRuDZ6HA_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XI-tRuDZ6HA_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xIbSUwO43Ig_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xIbSUwO43Ig_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xIdWJyhWueE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xIdWJyhWueE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XILyHZyyCik_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XILyHZyyCik_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ximk6BHj9nE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ximk6BHj9nE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xJ63DJzzvnA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xJ63DJzzvnA_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xJMTA3Ay5FI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xJMTA3Ay5FI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XjoRxeEyjz4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XjoRxeEyjz4_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XjrVSk0_4vc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XjrVSk0_4vc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XjUmXwVlDDo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XjUmXwVlDDo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XJXn88r9ys8_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XJXn88r9ys8_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xJYBA7VTkHA_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xJYBA7VTkHA_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xk4U8BembHM_470-480.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xk4U8BembHM_470-480.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XkBXsaSXDJ0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XkBXsaSXDJ0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xKc_9B3RiOc_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xKc_9B3RiOc_60-70.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xKEJ6fVhb8w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xKEJ6fVhb8w_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XKp670Yh0E0_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XKp670Yh0E0_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xKrdOZAp2w0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xKrdOZAp2w0_30-40.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xl4FJzeU0YA_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xl4FJzeU0YA_170-180.mid\n","32/32 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xl4RSHQsnl8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xl4RSHQsnl8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xLQF7S41XLE_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xLQF7S41XLE_20-30.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xlxxWFENWr8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xlxxWFENWr8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xLZp-3_71Vs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xLZp-3_71Vs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xm2ciX0_UP8_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xm2ciX0_UP8_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XM4hxyK-Ddo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XM4hxyK-Ddo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xM4p5pmRAxM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xM4p5pmRAxM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xMCLKME4hAY_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xMCLKME4hAY_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XmMN-6g1L8w_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XmMN-6g1L8w_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xMsgBL9Sunw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xMsgBL9Sunw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xmSMAmnoRug_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xmSMAmnoRug_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xn0wIqnt_44_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xn0wIqnt_44_220-230.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xN9tKWgXLI4_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xN9tKWgXLI4_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XnHAH2aPHk0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XnHAH2aPHk0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XNlFs7Yjauk_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XNlFs7Yjauk_40-50.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XnMokzAE5kk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XnMokzAE5kk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xNn2UdI-kvA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xNn2UdI-kvA_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XOLVI1bgxqk_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XOLVI1bgxqk_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XOsHEjo-RSg_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XOsHEjo-RSg_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XoTJkok3FlY_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XoTJkok3FlY_150-160.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XPGtOugQ69U_290-300.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XPGtOugQ69U_290-300.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XpueyrkcMyQ_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XpueyrkcMyQ_280-290.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XQB27QPic3k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XQB27QPic3k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xqjpWi83CWM_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xqjpWi83CWM_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xR2p3UED4VU_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xR2p3UED4VU_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xrbIZTswt3c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xrbIZTswt3c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xRfbWrI03gc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xRfbWrI03gc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XrjkzI6TVwc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XrjkzI6TVwc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xrqDoBor2dk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xrqDoBor2dk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XRQyoAk-Qz0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XRQyoAk-Qz0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XS-3djsJWTA_360-370.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XS-3djsJWTA_360-370.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XscK8V4Veac_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XscK8V4Veac_60-70.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XscNEv9tX5U_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XscNEv9tX5U_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xSDkn9PtQm0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xSDkn9PtQm0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xseL3oZc7pY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xseL3oZc7pY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xsLJe043ar4_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xsLJe043ar4_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xsvi5Mgl3qo_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xsvi5Mgl3qo_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xt6V3Ic72nE_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xt6V3Ic72nE_300-310.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xtGmrLOsjHk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xtGmrLOsjHk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xtllXrdFAFQ_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xtllXrdFAFQ_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XtpfZx12hDM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XtpfZx12hDM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XUD-9HkQuTE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XUD-9HkQuTE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xuepy6SFOf8_480-490.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xuepy6SFOf8_480-490.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xUmMfewERLg_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xUmMfewERLg_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xUMzNtC2ITA_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xUMzNtC2ITA_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xus0LI3QV2A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xus0LI3QV2A_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xUVvBF9BWdg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xUVvBF9BWdg_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xuxKtxzq2Cs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xuxKtxzq2Cs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XUzaEsoOlWQ_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XUzaEsoOlWQ_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xVab_CbwecE_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xVab_CbwecE_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xVi1wNljxjk_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xVi1wNljxjk_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xvryKn-V-JM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xvryKn-V-JM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XvtL_TTLXHY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XvtL_TTLXHY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XvyaEbEpAMc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XvyaEbEpAMc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XW6tS4zAZ5E_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XW6tS4zAZ5E_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XwhAoMLNYWQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XwhAoMLNYWQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XWj7nP7kfdQ_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XWj7nP7kfdQ_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xWmcax3aX5U_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xWmcax3aX5U_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XWVGQbfpA0k_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XWVGQbfpA0k_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xx1RccwlF5g_380-390.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xx1RccwlF5g_380-390.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xx3nnVzGXa0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xx3nnVzGXa0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XXBVsNt2Qr8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XXBVsNt2Qr8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XXdPZMsrBd4_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XXdPZMsrBd4_370-380.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Xxe6vTEwFvs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Xxe6vTEwFvs_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XxKlsW4H0qo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XxKlsW4H0qo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xxNroISqkt4_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xxNroISqkt4_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xXRGgPVnkqk_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xXRGgPVnkqk_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xxRnOYSjF64_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xxRnOYSjF64_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xyAbP5XfGz8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xyAbP5XfGz8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xyco-5DC_K8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xyco-5DC_K8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xydcedfPePM_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xydcedfPePM_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XYOnq7ju7o0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XYOnq7ju7o0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XYQnMxWnetY_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XYQnMxWnetY_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xyXQ7Z1vX7E_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xyXQ7Z1vX7E_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xzgnLpKkvdg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xzgnLpKkvdg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XzlDa1dzUh4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XzlDa1dzUh4_0-10.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XzRxO8n3WRE_420-430.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XzRxO8n3WRE_420-430.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XzTBNfQ7_GA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XzTBNfQ7_GA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xZTlnE6IcYQ_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xZTlnE6IcYQ_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xzU6sJot-Gk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xzU6sJot-Gk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\xZukWGb52BI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\xZukWGb52BI_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XZurp_Ex9No_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XZurp_Ex9No_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\XzwhTltRQcM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\XzwhTltRQcM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\X_nfMNpw9SA_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\X_nfMNpw9SA_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y-qOOR0izlE_102-112.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y-qOOR0izlE_102-112.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y02VBGoTi9w_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y02VBGoTi9w_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y0w7FyJcZ8w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y0w7FyJcZ8w_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y0_Ixl1d7oQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y0_Ixl1d7oQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y1gheqplpIg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y1gheqplpIg_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y1ItBiA8nKU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y1ItBiA8nKU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y3Pqe5DLvok_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y3Pqe5DLvok_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y4vtzCAPv84_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y4vtzCAPv84_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y516mYOT_9c_260-270.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y516mYOT_9c_260-270.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y5HkvusmkqM_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y5HkvusmkqM_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y5I5pq0bXmg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y5I5pq0bXmg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y5RVYmf3uWc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y5RVYmf3uWc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y6iMm7Pltq0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y6iMm7Pltq0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y6NS77HLjEE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y6NS77HLjEE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y7mTjfgcybQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y7mTjfgcybQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y7PtSsbkGdM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y7PtSsbkGdM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y7SoAXBFUew_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y7SoAXBFUew_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y8gB3-yw3tE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y8gB3-yw3tE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y8oi64M0IyE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y8oi64M0IyE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y8ULUSXWTcY_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y8ULUSXWTcY_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y8wHDcVCGa0_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y8wHDcVCGa0_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y9hdu9iMBG8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y9hdu9iMBG8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yAoMoKe7gj8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yAoMoKe7gj8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yAqznhOhoIk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yAqznhOhoIk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yaUK4XvVGTg_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yaUK4XvVGTg_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yAvqiPL-ssU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yAvqiPL-ssU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YAVVMxqtxGE_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YAVVMxqtxGE_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YAYp2E5vMNw_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YAYp2E5vMNw_310-320.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YB28WMv7wUE_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YB28WMv7wUE_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YBbvQ0RPrG8_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YBbvQ0RPrG8_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yBYd03Hr2kQ_320-330.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yBYd03Hr2kQ_320-330.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YB_PzRgHOeo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YB_PzRgHOeo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yCDloqQe65k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yCDloqQe65k_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YcfGSJB1YvQ_430-440.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YcfGSJB1YvQ_430-440.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yCGM8aJV6fM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yCGM8aJV6fM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ycid0vBwqUg_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ycid0vBwqUg_160-170.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YcWJUHWt-64_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YcWJUHWt-64_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Yd8JBTdUvrw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Yd8JBTdUvrw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YDBxdZchOuM_230-240.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YDBxdZchOuM_230-240.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YddV91xnUz4_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YddV91xnUz4_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YDh36ZdneAU_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YDh36ZdneAU_180-190.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YE2rN3xknlk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YE2rN3xknlk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YeIXmKPyTVY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YeIXmKPyTVY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YErpnsceZw8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YErpnsceZw8_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yesyhQkYrQM_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yesyhQkYrQM_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yeu6OEIKwws_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yeu6OEIKwws_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YEwikeeqF38_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YEwikeeqF38_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yfaxqwNHe7w_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yfaxqwNHe7w_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YFhbrSUb0JQ_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YFhbrSUb0JQ_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YFXSbPFaxcA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YFXSbPFaxcA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yfXvz2FyZ_U_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yfXvz2FyZ_U_140-150.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yfZ0z1C3blk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yfZ0z1C3blk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yG1bzzXDIak_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yG1bzzXDIak_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YGWweVRzFrw_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YGWweVRzFrw_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YgX85tZf1ts_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YgX85tZf1ts_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yGXohnxCLCA_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yGXohnxCLCA_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yhbpAGdv_d8_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yhbpAGdv_d8_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yhS-6Y8ToR8_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yhS-6Y8ToR8_60-70.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yi4-kGV30qs_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yi4-kGV30qs_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Yiau7DypQi0_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Yiau7DypQi0_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yIFP8fkq8GU_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yIFP8fkq8GU_90-100.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YIhfk4Zaevk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YIhfk4Zaevk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yIOUPSGFqoY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yIOUPSGFqoY_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Yj7YyxKyXPU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Yj7YyxKyXPU_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YJKZVSvz1Bk_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YJKZVSvz1Bk_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YjTz5y8DnWo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YjTz5y8DnWo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YK1AEw1kf28_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YK1AEw1kf28_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Yk2ZrS0ZS6g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Yk2ZrS0ZS6g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ykkVTInYctY_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ykkVTInYctY_120-130.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YKQMolFL2Rs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YKQMolFL2Rs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yKx_RFUTPfI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yKx_RFUTPfI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YlgCFc3OvmI_500-510.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YlgCFc3OvmI_500-510.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ylKvglDzBU4_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ylKvglDzBU4_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YLlbLSNxdQ4_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YLlbLSNxdQ4_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YlV45uBUVBc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YlV45uBUVBc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yMEMzSFbZ2s_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yMEMzSFbZ2s_110-120.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ymGg5TA2YfM_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ymGg5TA2YfM_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ymOjaaxRDLU_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ymOjaaxRDLU_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YMq4wE6KxmQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YMq4wE6KxmQ_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ymuRKv9iJm4_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ymuRKv9iJm4_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yn4-OtUmyWo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yn4-OtUmyWo_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YNdexakUGOo_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YNdexakUGOo_180-190.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YnE5ONaXtLY_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YnE5ONaXtLY_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yNIZaqTHUnc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yNIZaqTHUnc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YNoR-SR5t1s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YNoR-SR5t1s_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YNv7mzbUUHc_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YNv7mzbUUHc_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yO7MWuJ7zLA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yO7MWuJ7zLA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YOA1JOyd7cw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YOA1JOyd7cw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YODoF8e7Jlk_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YODoF8e7Jlk_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YOG_PPvTvW0_140-150.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YOG_PPvTvW0_140-150.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yOVaak2hemM_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yOVaak2hemM_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ypg2ItQIc2c_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ypg2ItQIc2c_190-200.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YpOHemscGCk_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YpOHemscGCk_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yPou7kokTgA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yPou7kokTgA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ypuv3htJlpg_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ypuv3htJlpg_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yPzhMx3NPW4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yPzhMx3NPW4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yqb4GenP8gs_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yqb4GenP8gs_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yQN9gj7Vk0w_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yQN9gj7Vk0w_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YqZNMFyPJOQ_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YqZNMFyPJOQ_240-250.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yreWOyWr6Uk_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yreWOyWr6Uk_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YrGQKTbiG1g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YrGQKTbiG1g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yrme-KRBvzk_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yrme-KRBvzk_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yRU7DifuAXY_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yRU7DifuAXY_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yRWndZvIAHc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yRWndZvIAHc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yScg02DM-jY_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yScg02DM-jY_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ysrlv2UlG8A_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ysrlv2UlG8A_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YSrTtw6ku2E_200-210.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YSrTtw6ku2E_200-210.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YSXrSxC68VM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YSXrSxC68VM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ySY5J3TDgag_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ySY5J3TDgag_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Yt1czlnCUCg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Yt1czlnCUCg_30-40.mid\n","19/32 [================>.............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yTc-ENutOD4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yTc-ENutOD4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YTYj8Bk0qM8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YTYj8Bk0qM8_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YtYjdkTK5oY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YtYjdkTK5oY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YTZK9FNgK74_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YTZK9FNgK74_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YuiQRYaF9SA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YuiQRYaF9SA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yuWjB3XA8tc_480-490.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yuWjB3XA8tc_480-490.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YVEqyQjyy1Q_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YVEqyQjyy1Q_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YvFY7xU2kGk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YvFY7xU2kGk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YvT7qFbUOO0_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YvT7qFbUOO0_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yVWk3yq3Abc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yVWk3yq3Abc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Yw28B_xflHk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Yw28B_xflHk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YW4AKwkpYxs_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YW4AKwkpYxs_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yw6uqQQF5Ig_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yw6uqQQF5Ig_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YWf3I4jKusI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YWf3I4jKusI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YwUa3OS92ZQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YwUa3OS92ZQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ywuR9AfpA_E_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ywuR9AfpA_E_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yx7BZ_djE-U_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yx7BZ_djE-U_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YXDHyD4HU0E_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YXDHyD4HU0E_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YxkYVsE0UdQ_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YxkYVsE0UdQ_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YxQzJweGS2c_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YxQzJweGS2c_160-170.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YyHmz1vcob8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YyHmz1vcob8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yYpfb_xV--4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yYpfb_xV--4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YyYEzAY2e2I_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YyYEzAY2e2I_30-40.mid\n","22/32 [===================>..........] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YyZ5bXcMDv4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YyZ5bXcMDv4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Yz1DrC54UGk_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Yz1DrC54UGk_190-200.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YZH-PZBir3E_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YZH-PZBir3E_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yzjbAxCnt7U_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yzjbAxCnt7U_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yZNgqVInQGw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yZNgqVInQGw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YzpzKyzyL0Y_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YzpzKyzyL0Y_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\yZRTQX8pcMY_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\yZRTQX8pcMY_490-500.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\YZx0_GRtvJk_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\YZx0_GRtvJk_250-260.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Y_eh6C0EBP8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Y_eh6C0EBP8_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y_lfY0uzmr0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y_lfY0uzmr0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y_TnstfXeBQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y_TnstfXeBQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\y_toDfeACWE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\y_toDfeACWE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z-G7nL9tiws_240-250.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z-G7nL9tiws_240-250.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z-Vb1Ay-zNA_400-410.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z-Vb1Ay-zNA_400-410.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z0htOHTOtHY_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z0htOHTOtHY_210-220.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z0O2r0Dl2T4_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z0O2r0Dl2T4_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z0OTDXtjK9M_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z0OTDXtjK9M_210-220.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z0w3Y8BGLQE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z0w3Y8BGLQE_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z2c1npe5AYY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z2c1npe5AYY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z2kTJ6pQ4Uo_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z2kTJ6pQ4Uo_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z31gI08SMzI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z31gI08SMzI_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z31iCbkqYyw_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z31iCbkqYyw_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z3UCnloQGPY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z3UCnloQGPY_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z5x5BLzQKZI_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z5x5BLzQKZI_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z6q5doznOcI_340-350.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z6q5doznOcI_340-350.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z6SNngkMAug_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z6SNngkMAug_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z7V7Curou7s_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z7V7Curou7s_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z7vNtEcM9Bk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z7vNtEcM9Bk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z8L3jychP14_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z8L3jychP14_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z8Wjdss5uMg_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z8Wjdss5uMg_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z9hnLYpypCU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z9hnLYpypCU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z9hRQiJMnIw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z9hRQiJMnIw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zaEdWwSamS0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zaEdWwSamS0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZahBai58_Ec_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZahBai58_Ec_330-340.mid\n","1/1 [==============================] - 0s 10ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZAT2_-x59pY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZAT2_-x59pY_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZaUaqnLdg6k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZaUaqnLdg6k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zayC5mUo7sY_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zayC5mUo7sY_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zbCqre50eLM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zbCqre50eLM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZbdmiykoJm8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZbdmiykoJm8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zbmm_hXcrA0_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zbmm_hXcrA0_160-170.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zc4rX7nbRW4_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zc4rX7nbRW4_190-200.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zcc7dJIY7uc_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zcc7dJIY7uc_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zCGGb7Eh_f4_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zCGGb7Eh_f4_160-170.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZCKzgf3QD4M_390-400.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZCKzgf3QD4M_390-400.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZCR7qJ2IgGI_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZCR7qJ2IgGI_60-70.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zd3lShuZNmU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zd3lShuZNmU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zD4PXuUkwsc_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zD4PXuUkwsc_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZdqPnWEANuI_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZdqPnWEANuI_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZE0f_S44O7M_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZE0f_S44O7M_180-190.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZEN8_GtW_UQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZEN8_GtW_UQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zeUEOxTd8IE_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zeUEOxTd8IE_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZEuY5HnECuo_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZEuY5HnECuo_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZF8uHVu4Res_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZF8uHVu4Res_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZFg6KpT5ehU_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZFg6KpT5ehU_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZFG9jHrLtBE_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZFG9jHrLtBE_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZFimyfPWltk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZFimyfPWltk_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zfkPKRn8ah8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zfkPKRn8ah8_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZfR3_QJF8f4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZfR3_QJF8f4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zGBKakEGSyc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zGBKakEGSyc_30-40.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZGfGiVauGL4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZGfGiVauGL4_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zgI-Lr6Pbcs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zgI-Lr6Pbcs_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zGONTDY_rNM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zGONTDY_rNM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZgooDijn2as_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZgooDijn2as_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZH8VGGvZBok_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZH8VGGvZBok_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZhafwFYgltI_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZhafwFYgltI_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zhurw43-Y1g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zhurw43-Y1g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZHzhdhKEjMc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZHzhdhKEjMc_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZiHlhUvmgzQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZiHlhUvmgzQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zir3uL14ijM_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zir3uL14ijM_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zixIuxzCCvs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zixIuxzCCvs_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zj2G-KVw4N4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zj2G-KVw4N4_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZJHlHb-VyDc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZJHlHb-VyDc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zjsWFvUkh7M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zjsWFvUkh7M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zjZV0tvur2I_180-190.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zjZV0tvur2I_180-190.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZJZxWLYzNh8_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZJZxWLYzNh8_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZK3bYlekfm0_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZK3bYlekfm0_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZK5M3DZejzk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZK5M3DZejzk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZkfKOLp5SxU_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZkfKOLp5SxU_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZkGQhIbEDrs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZkGQhIbEDrs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZKkfCOqLrT0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZKkfCOqLrT0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZkmtfBzpQlI_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZkmtfBzpQlI_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zkYXE0-JsY4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zkYXE0-JsY4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zlbo8ygfPSM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zlbo8ygfPSM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZleHXDirD58_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZleHXDirD58_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZLxhZcS3Ppw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZLxhZcS3Ppw_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZLXW4ewrVpQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZLXW4ewrVpQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZM0imDMXuw8_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZM0imDMXuw8_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zmbwvsdXlBU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zmbwvsdXlBU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZmgkpmzvL6c_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZmgkpmzvL6c_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zmtw8tP-KFo_330-340.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zmtw8tP-KFo_330-340.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zNAHQYshxZk_310-320.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zNAHQYshxZk_310-320.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zNbF006Y5x4_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zNbF006Y5x4_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZnBvXFDWpWo_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZnBvXFDWpWo_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZNGJN30LCwM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZNGJN30LCwM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZNGvyFsCx4g_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZNGvyFsCx4g_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zNSV9GkpRfM_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zNSV9GkpRfM_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zo9xROGuV3k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zo9xROGuV3k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZoAfkpmztww_510-520.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZoAfkpmztww_510-520.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZocCGcJcGJE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZocCGcJcGJE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZOGMpGQQ3FI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZOGMpGQQ3FI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZOKQFjrfbpw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZOKQFjrfbpw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zon9WGTwAME_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zon9WGTwAME_210-220.mid\n","16/32 [==============>...............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zopos1B6Elc_270-280.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zopos1B6Elc_270-280.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zOvFaef41iw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zOvFaef41iw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZOzavOPeuJQ_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZOzavOPeuJQ_100-110.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zPhuyMYy9EI_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zPhuyMYy9EI_130-140.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZPK1hSPI540_220-230.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZPK1hSPI540_220-230.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zPMiMXCazAI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zPMiMXCazAI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zq92ED3IvLQ_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zq92ED3IvLQ_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zqbHYVH6Wqo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zqbHYVH6Wqo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZqnbgQeeRbM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZqnbgQeeRbM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZQwpXl8qnnk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZQwpXl8qnnk_30-40.mid\n","31/31 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zrb76mJOZQQ_3-13.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zrb76mJOZQQ_3-13.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zRpPf62Zvto_280-290.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zRpPf62Zvto_280-290.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zrrM6Qg2Dwg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zrrM6Qg2Dwg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZSGRzalgx4s_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZSGRzalgx4s_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zSGWoXDFM64_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zSGWoXDFM64_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZSHm7FdyxpQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZSHm7FdyxpQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZSItez9gTyY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZSItez9gTyY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZsmfIMEzrQs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZsmfIMEzrQs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZsmxO0wnqdQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZsmxO0wnqdQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zt8x7tvP9Qs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zt8x7tvP9Qs_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZtcHktwEfAU_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZtcHktwEfAU_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZTf9i8y5muo_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZTf9i8y5muo_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ztfegVzqeCI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ztfegVzqeCI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Ztlcnd14Kn4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Ztlcnd14Kn4_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zTtZH-Q61Ik_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zTtZH-Q61Ik_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zTuxNA1y6Os_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zTuxNA1y6Os_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZTVMsW1h3bI_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZTVMsW1h3bI_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZU6sI1Plq50_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZU6sI1Plq50_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zUaZGKZIKic_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zUaZGKZIKic_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZUcHBeueBww_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZUcHBeueBww_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZUg7rRpFGvA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZUg7rRpFGvA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZUkh168Nyus_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZUkh168Nyus_40-50.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zu_1zpF--Zg_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zu_1zpF--Zg_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zVA66aZOBH4_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zVA66aZOBH4_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZVMIk3xYaYo_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZVMIk3xYaYo_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZVvX2-ldhvY_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZVvX2-ldhvY_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZV_ZbmjPpkw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZV_ZbmjPpkw_30-40.mid\n","30/30 [==============================] - 1s 19ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zw5dkiklbhE_15-25.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zw5dkiklbhE_15-25.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zWEznZ40k2Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zWEznZ40k2Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zwfo7wnXdjs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zwfo7wnXdjs_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZwfzBagtpV0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZwfzBagtpV0_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zWJC_qr2610_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zWJC_qr2610_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZwLfj7tvpdc_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZwLfj7tvpdc_110-120.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZX2fVPmUidA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZX2fVPmUidA_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZX7EzqMBjfo_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZX7EzqMBjfo_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zXxJymYt8Z4_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zXxJymYt8Z4_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zx_vcwOsDO4_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zx_vcwOsDO4_50-60.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zy4uiiy0qgA_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zy4uiiy0qgA_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zYa3ksSrCqw_350-360.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zYa3ksSrCqw_350-360.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zYM0gtd_PRo_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zYM0gtd_PRo_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zYRI-R2gxUI_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zYRI-R2gxUI_90-100.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zYsFbF9emtI_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zYsFbF9emtI_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZYUAY6EN05Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZYUAY6EN05Q_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zYUZEXCE7gw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zYUZEXCE7gw_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zyXa2tdBTGc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zyXa2tdBTGc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zy_YSROQmlE_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zy_YSROQmlE_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Zz1Bz1a7yPE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Zz1Bz1a7yPE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\zzNdwF40ID8_70-80.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\zzNdwF40ID8_70-80.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\ZzyWbehtt0M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\ZzyWbehtt0M_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z_0Ta-m_-hU_110-120.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z_0Ta-m_-hU_110-120.mid\n","14/32 [============>.................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\z_fEIZOv0JY_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\z_fEIZOv0JY_0-10.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\Z_HT-d8W1_M_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\Z_HT-d8W1_M_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_-kssA-FOzU_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_-kssA-FOzU_300-310.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_0-2meOf9qY_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_0-2meOf9qY_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_1woPC5HWSg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_1woPC5HWSg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_2P_EJsnBls_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_2P_EJsnBls_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_2wFjBoreaY_90-100.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_2wFjBoreaY_90-100.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_3GnNMrDuCs_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_3GnNMrDuCs_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_3OlK_1yQOk_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_3OlK_1yQOk_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_43OOP6UEw0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_43OOP6UEw0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_5fwnVeZbvI_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_5fwnVeZbvI_80-90.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_5w5TVK5B90_370-380.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_5w5TVK5B90_370-380.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_6C2ffY_-mc_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_6C2ffY_-mc_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_8OIugVSFeE_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_8OIugVSFeE_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_94ra2KoZGo_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_94ra2KoZGo_520-530.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_9OUh0uwDec_210-220.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_9OUh0uwDec_210-220.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_ALGXHquYkM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_ALGXHquYkM_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_AVegKwklcg_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_AVegKwklcg_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_b-7P-XsnUI_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_b-7P-XsnUI_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_b5n-mny1lM_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_b5n-mny1lM_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_cf0WYQcNvk_570-580.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_cf0WYQcNvk_570-580.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_cg_IfaD1C0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_cg_IfaD1C0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_fKntnlIYTQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_fKntnlIYTQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_G3lYKAITu8_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_G3lYKAITu8_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_GjHL0FkYoY_120-130.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_GjHL0FkYoY_120-130.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_GQnXfIGNKY_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_GQnXfIGNKY_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_gWEpDgPAho_100-110.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_gWEpDgPAho_100-110.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_h2rFVPCSPE_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_h2rFVPCSPE_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_HfaIP9e0ww_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_HfaIP9e0ww_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_HXMIdSiOMA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_HXMIdSiOMA_30-40.mid\n","15/32 [=============>................] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_IkLUOsNHAA_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_IkLUOsNHAA_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_IP6zlayY7k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_IP6zlayY7k_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_JTHtcRHxnw_300-310.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_JTHtcRHxnw_300-310.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_KaRkSyELy4_490-500.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_KaRkSyELy4_490-500.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_KGUrOb1qgU_60-70.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_KGUrOb1qgU_60-70.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_kPmYc1nXuQ_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_kPmYc1nXuQ_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_KYo_89lgf0_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_KYo_89lgf0_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_lq8nEXh064_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_lq8nEXh064_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_m-N4i-ge28_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_m-N4i-ge28_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_miAGxDX5FM_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_miAGxDX5FM_160-170.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_MjbdUaJcik_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_MjbdUaJcik_190-200.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_mQ6KuA2p6k_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_mQ6KuA2p6k_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_n3r2inlqBc_520-530.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_n3r2inlqBc_520-530.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_n9boKzVRhs_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_n9boKzVRhs_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_nrz_BawPMY_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_nrz_BawPMY_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_oNLyxk08oA_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_oNLyxk08oA_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_pU2KbHMN4Q_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_pU2KbHMN4Q_30-40.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_qf0UiKtB3k_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_qf0UiKtB3k_30-40.mid\n","20/32 [=================>............] - ETA: 0s"]},{"name":"stderr","output_type":"stream","text":["E:\\conda_pkg\\.conda\\envs\\newEnv\\lib\\site-packages\\crepe\\core.py:209: RuntimeWarning: invalid value encountered in true_divide\n","  frames /= np.std(frames, axis=1)[:, np.newaxis]\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_Ra1Y6K7nSs_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_Ra1Y6K7nSs_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_RLsXrr0fQo_80-90.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_RLsXrr0fQo_80-90.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_Rpn2FUAUgY_20-30.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_Rpn2FUAUgY_20-30.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_RrA-0lfIiU_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_RrA-0lfIiU_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_Slo8QXYOp8_0-10.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_Slo8QXYOp8_0-10.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_u2cNlW5DxQ_160-170.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_u2cNlW5DxQ_160-170.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_VmCPixy9GQ_50-60.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_VmCPixy9GQ_50-60.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_vwBe9ZXWXE_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_vwBe9ZXWXE_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_wyELLqwF3w_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_wyELLqwF3w_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_WYwB1qRgLM_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_WYwB1qRgLM_10-20.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_x4a974Pl-A_150-160.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_x4a974Pl-A_150-160.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_xC7IXGWlk4_170-180.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_xC7IXGWlk4_170-180.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_XrolyeJXDw_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_XrolyeJXDw_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_xURU_-ffC4_250-260.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_xURU_-ffC4_250-260.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_y07ENAx2_E_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_y07ENAx2_E_130-140.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_yRFCl-z-EE_190-200.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_yRFCl-z-EE_190-200.mid\n","1/1 [==============================] - 0s 15ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_yWsqs9FOnU_10-20.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_yWsqs9FOnU_10-20.mid\n","32/32 [==============================] - 0s 8ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_yXtw_z2xf4_40-50.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_yXtw_z2xf4_40-50.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_yzcCFe-uo0_30-40.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_yzcCFe-uo0_30-40.mid\n","32/32 [==============================] - 0s 9ms/step\n","Converted E:\\Project and Dissertation in Data Science\\dataset\\archive\\musiccaps\\_zQTlTCqMzs_130-140.wav to E:\\Project and Dissertation in Data Science\\dataset\\archive\\music_midi\\_zQTlTCqMzs_130-140.mid\n"]}],"source":["import os\n","import librosa\n","import crepe\n","import pretty_midi\n","\n","def convert_wav_to_midi(wav_path, midi_path):\n","    try:\n","        # 加载音频文件\n","        audio, sr = librosa.load(wav_path)\n","\n","        # 使用 CREPE 进行音高预测\n","        time, frequency, confidence, _ = crepe.predict(audio, sr, viterbi=True)\n","\n","        # 创建 PrettyMIDI 对象\n","        midi = pretty_midi.PrettyMIDI()\n","        instrument = pretty_midi.Instrument(program=0)\n","\n","        # 遍历预测的时间、频率和置信度\n","        for t, f, c in zip(time, frequency, confidence):\n","            if c > 0.8:  # 置信度阈值\n","                note_number = librosa.hz_to_midi(f)  # 将频率转换为 MIDI 音符编号\n","                start = t\n","                end = t + 0.05  # 短时持续时间\n","                note = pretty_midi.Note(velocity=100, pitch=int(note_number), start=start, end=end)\n","                instrument.notes.append(note)\n","\n","        # 将音符添加到 MIDI 对象中并保存\n","        midi.instruments.append(instrument)\n","        midi.write(midi_path)\n","        print(f\"Converted {wav_path} to {midi_path}\")\n","    except Exception as e:\n","        print(f\"Failed to convert {wav_path}: {e}\")\n","\n","def batch_convert(wav_folder, midi_folder):\n","    if not os.path.exists(midi_folder):\n","        os.makedirs(midi_folder)\n","\n","    for wav_file in os.listdir(wav_folder):\n","        if wav_file.endswith('.wav'):\n","            wav_path = os.path.join(wav_folder, wav_file)\n","            midi_path = os.path.join(midi_folder, wav_file.replace('.wav', '.mid'))\n","            convert_wav_to_midi(wav_path, midi_path)\n","\n","\n","batch_convert(wav_folder, midi_folder)\n"]},{"cell_type":"markdown","metadata":{"id":"85df47f4-0ae5-409e-9d1d-6ce0dfe334c4"},"source":["### Load Melodies from MIDI Files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22d51d9a-7343-4304-afa1-258c1cb585d8"},"outputs":[],"source":["# 从数据框中的文件名找到对应的MIDI文件并进行转换\n","def load_melodies_from_midi_files(df, midi_folder_path):\n","    melodies = []\n","    for filename in df['Music_Name']:\n","        midi_file_path = os.path.join(midi_folder_path, f\"{filename}.mid\")\n","        if os.path.exists(midi_file_path):\n","            melody = note_seq.midi_file_to_melody(midi_file_path)\n","            melodies.append(melody)\n","        else:\n","            print(f\"File {midi_file_path} does not exist.\")\n","    return melodies\n","\n","# 加载MIDI文件并转换为Melody\n","melodies = load_melodies_from_midi_files(test_data, midi_folder)"]},{"cell_type":"markdown","metadata":{"id":"4263f80d-2f37-4b9a-9f87-40d9d6ae1e37"},"source":["### All Data for Melodies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31771e92-05d0-4adb-b841-1a72c798fc22"},"outputs":[],"source":["# 从数据框中的文件名找到对应的MIDI文件并进行转换\n","def load_melodies_from_midi_files(df, midi_folder_path):\n","    melodies = []\n","    for filename in df['Music_Name']:\n","        midi_file_path = os.path.join(midi_folder_path, f\"{filename}.mid\")\n","        if os.path.exists(midi_file_path):\n","            melody = note_seq.midi_file_to_melody(midi_file_path)\n","            melodies.append(melody)\n","        else:\n","            print(f\"File {midi_file_path} does not exist.\")\n","    return melodies\n","\n","# 加载MIDI文件并转换为Melody\n","melodies = load_melodies_from_midi_files(base_data, midi_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85ad2a71-ee48-4873-aa8a-f276fffd1fd8"},"outputs":[],"source":["base_data2 = base_data\n","base_data2['melody'] = melodies\n","\n","# 序列化 Melody 对象为 JSON 字符串\n","base_data2['melody_json'] = base_data2['melody'].apply(lambda x: json.dumps(x._events))\n","# 创建 HDF5 文件（'w' 代表写模式）\n","with h5py.File('data_with_melody.h5', 'w') as hf:\n","    hf.create_dataset('image_features', data=np.array(base_data2['image_features'].tolist()))\n","    hf.create_dataset('text_features', data=np.array(base_data2['text_features'].tolist()))\n","    hf.create_dataset('features_mean', data=np.array(base_data2['features_mean'].tolist()))\n","    hf.create_dataset('features_weighted', data=np.array(base_data2['features_weighted'].tolist()))\n","    hf.create_dataset('melody', data=np.array(base_data2['melody_json'].tolist()).astype('S'))"]},{"cell_type":"markdown","metadata":{"id":"50c67fbe-63ba-45d3-9d11-88a4c203a0cc"},"source":["### Load Whole Dataset Melodies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f07f36b1-9ae7-4505-9890-1285d8fdcfa6"},"outputs":[],"source":["# 读取 HDF5 文件\n","with h5py.File('data_with_melody.h5', 'r') as hf:\n","    melody_data = hf['melody'][:]\n","    # 反序列化 JSON 字符串为 Melody 对象\n","    melodies = [note_seq.Melody(json.loads(m.decode())) for m in melody_data]\n","\n","    image_features = hf['image_features'][:]\n","    text_features = hf['text_features'][:]\n","    features_mean = hf['features_mean'][:]\n","    features_weighted = hf['features_weighted'][:]\n","\n","# 将数组转换为列表（如果需要）并添加到 other_data DataFrame\n","base_data['image_features'] = list(image_features)\n","base_data['text_features'] = list(text_features)\n","base_data['features_mean'] = list(features_mean)\n","base_data['features_weighted'] = list(features_weighted)\n","base_data['melody'] = list(melodies)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ca0b0ac2-a0f1-45a0-8082-0228dc2a4576","outputId":"46229af5-07c4-4544-f9ae-fd680b8243c5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","      <th>image_features</th>\n","      <th>text_features</th>\n","      <th>features_mean</th>\n","      <th>features_weighted</th>\n","      <th>melody</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...</td>\n","      <td>[[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...</td>\n","      <td>[[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...</td>\n","      <td>(50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...</td>\n","      <td>[[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...</td>\n","      <td>[[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...</td>\n","      <td>(-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...</td>\n","      <td>[[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...</td>\n","      <td>[[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...</td>\n","      <td>(-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....</td>\n","      <td>[[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...</td>\n","      <td>[[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....</td>\n","      <td>(67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...</td>\n","      <td>[[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....</td>\n","      <td>[[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...</td>\n","      <td>(-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>443657</th>\n","      <td>willi-baumeister_machine-man-with-spiral-turn-...</td>\n","      <td>The interlocking mechanical shapes fitting tog...</td>\n","      <td>R_HAtyDbw1M_30-40</td>\n","      <td>Someone is skillfully playing maracas playing ...</td>\n","      <td>0.806879</td>\n","      <td>[[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...</td>\n","      <td>[[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...</td>\n","      <td>[[0.2112, 0.1582, 0.1954, -0.1548, 0.02435, 0....</td>\n","      <td>[[0.2625, 0.1536, 0.1647, -0.1792, 0.04053, 0....</td>\n","      <td>()</td>\n","    </tr>\n","    <tr>\n","      <th>443658</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","      <td>[[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...</td>\n","      <td>[[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...</td>\n","      <td>[[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....</td>\n","      <td>[[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....</td>\n","      <td>(-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...</td>\n","    </tr>\n","    <tr>\n","      <th>443659</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....</td>\n","      <td>[[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...</td>\n","      <td>[[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...</td>\n","      <td>(63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...</td>\n","    </tr>\n","    <tr>\n","      <th>443660</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...</td>\n","      <td>[[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...</td>\n","      <td>[[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...</td>\n","      <td>(50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>443661</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...</td>\n","      <td>[[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...</td>\n","      <td>[[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....</td>\n","      <td>(-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>443662 rows × 10 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","443657  willi-baumeister_machine-man-with-spiral-turn-...   \n","443658                           gino-severini_a-dancer-1   \n","443659                  ivan-aivazovsky_sea-at-night-1861   \n","443660                  ivan-aivazovsky_sea-at-night-1861   \n","443661                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","443657  The interlocking mechanical shapes fitting tog...   \n","443658  the collection and collage of different colors...   \n","443659  The peaceful reflections of the moonlight on t...   \n","443660  I can imagine the sailors resting this peacefu...   \n","443661  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","443657    R_HAtyDbw1M_30-40   \n","443658     oMZcsGUi8ZE_0-10   \n","443659    s1QeDT7jqHQ_30-40   \n","443660    ABVYSaLu_VM_10-20   \n","443661    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \\\n","0       Here we have a slow piano piece played in a ma...          0.791458   \n","1       This is a recording of two didgeridoos. They a...          0.772168   \n","2       This audio contains a female voice speaking in...          0.798202   \n","3       The low quality recording features a resonatin...          0.792188   \n","4       In this clip, a large bell is rung and left to...          0.740201   \n","...                                                   ...               ...   \n","443657  Someone is skillfully playing maracas playing ...          0.806879   \n","443658  This clip features a synchronised playing of s...          0.799300   \n","443659  The low quality recording features multiple la...          0.781008   \n","443660  Here we have a slow piano piece played in a ma...          0.733153   \n","443661  The low quality recording features a theremin ...          0.761976   \n","\n","                                           image_features  \\\n","0       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","1       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","2       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","3       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","4       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","...                                                   ...   \n","443657  [[0.4673, 0.1345, 0.04214, -0.2769, 0.1053, -0...   \n","443658  [[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...   \n","443659  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443660  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","443661  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","\n","                                            text_features  \\\n","0       [[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...   \n","1       [[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...   \n","2       [[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...   \n","3       [[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....   \n","4       [[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...   \n","...                                                   ...   \n","443657  [[-0.04492, 0.182, 0.3486, -0.03268, -0.05658,...   \n","443658  [[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...   \n","443659  [[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....   \n","443660  [[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...   \n","443661  [[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...   \n","\n","                                            features_mean  \\\n","0       [[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...   \n","1       [[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...   \n","2       [[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...   \n","3       [[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...   \n","4       [[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....   \n","...                                                   ...   \n","443657  [[0.2112, 0.1582, 0.1954, -0.1548, 0.02435, 0....   \n","443658  [[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....   \n","443659  [[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...   \n","443660  [[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...   \n","443661  [[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...   \n","\n","                                        features_weighted  \\\n","0       [[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...   \n","1       [[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...   \n","2       [[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...   \n","3       [[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....   \n","4       [[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...   \n","...                                                   ...   \n","443657  [[0.2625, 0.1536, 0.1647, -0.1792, 0.04053, 0....   \n","443658  [[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....   \n","443659  [[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...   \n","443660  [[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...   \n","443661  [[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....   \n","\n","                                                   melody  \n","0       (50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...  \n","1       (-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...  \n","2       (-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...  \n","3       (67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...  \n","4       (-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...  \n","...                                                   ...  \n","443657                                                 ()  \n","443658  (-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...  \n","443659  (63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...  \n","443660  (50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...  \n","443661  (-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...  \n","\n","[443662 rows x 10 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["base_data"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"1e0b0bde-9f59-4e0f-b9b5-6d1edffa644b","outputId":"c3e46a97-09de-4eb8-d1c0-2ec12b777d64"},"outputs":[{"name":"stdout","output_type":"stream","text":["空的 Melody 对象数量:  20901\n"]}],"source":["count = 0\n","for melody in melodies:\n","    # 检查每个 Melody 对象的 _events 属性是否为空列表\n","    if not melody._events:  # 如果列表为空，这个表达式为真\n","        count += 1\n","\n","print('空的 Melody 对象数量: ', count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8384911b-6b57-41bb-856e-044ddcd17df1","outputId":"8949910c-bad6-4ed1-c771-3b5aa26c9c10"},"outputs":[{"data":{"text/plain":["RangeIndex(start=0, stop=443662, step=1)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["base_data.index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"987c73f9-8eef-4415-94d4-dd897597a709","outputId":"5676ad83-3e84-411b-bdb3-57c28a6c50b2"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\hjy\\AppData\\Local\\Temp\\ipykernel_6904\\2148986185.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  base_data.drop(columns=['is_melody_empty'], inplace=True)\n"]}],"source":["base_data['is_melody_empty'] = base_data['melody'].apply(lambda x: len(x._events) == 0)\n","base_data = base_data[base_data['is_melody_empty'] == False]\n","base_data.drop(columns=['is_melody_empty'], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ce6263fd-c5cb-4c6e-93e8-0ae9dd3cbacb","outputId":"fc27e880-936e-43e4-937f-96e3bbc472aa"},"outputs":[{"data":{"text/plain":["RangeIndex(start=0, stop=422761, step=1)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["base_data = base_data.reset_index(drop=True)\n","base_data.index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"be9685d8-e492-447c-be73-b1d8171121ab"},"outputs":[],"source":["processed_base_data = base_data.iloc[:,:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3e61c809-a19f-43f1-97e4-fb30dd88f1e6"},"outputs":[],"source":["processed_base_data.to_csv(\"processed_music_matched_data.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"90983fc9-759d-46e7-b259-6706925a9fe5","outputId":"186ffaf6-4af7-4311-8c10-cad90e97e480"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>422756</th>\n","      <td>david-burliuk_landscape-1</td>\n","      <td>The greenery landscape and flowery background ...</td>\n","      <td>M0ygCD6WyXw_0-10</td>\n","      <td>This clip consists of a blowing horn being pla...</td>\n","      <td>0.758374</td>\n","    </tr>\n","    <tr>\n","      <th>422757</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","    </tr>\n","    <tr>\n","      <th>422758</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","    </tr>\n","    <tr>\n","      <th>422759</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","    </tr>\n","    <tr>\n","      <th>422760</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>422761 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","422756                          david-burliuk_landscape-1   \n","422757                           gino-severini_a-dancer-1   \n","422758                  ivan-aivazovsky_sea-at-night-1861   \n","422759                  ivan-aivazovsky_sea-at-night-1861   \n","422760                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","422756  The greenery landscape and flowery background ...   \n","422757  the collection and collage of different colors...   \n","422758  The peaceful reflections of the moonlight on t...   \n","422759  I can imagine the sailors resting this peacefu...   \n","422760  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","422756     M0ygCD6WyXw_0-10   \n","422757     oMZcsGUi8ZE_0-10   \n","422758    s1QeDT7jqHQ_30-40   \n","422759    ABVYSaLu_VM_10-20   \n","422760    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \n","0       Here we have a slow piano piece played in a ma...          0.791458  \n","1       This is a recording of two didgeridoos. They a...          0.772168  \n","2       This audio contains a female voice speaking in...          0.798202  \n","3       The low quality recording features a resonatin...          0.792188  \n","4       In this clip, a large bell is rung and left to...          0.740201  \n","...                                                   ...               ...  \n","422756  This clip consists of a blowing horn being pla...          0.758374  \n","422757  This clip features a synchronised playing of s...          0.799300  \n","422758  The low quality recording features multiple la...          0.781008  \n","422759  Here we have a slow piano piece played in a ma...          0.733153  \n","422760  The low quality recording features a theremin ...          0.761976  \n","\n","[422761 rows x 5 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Load processed matched musical data, which has deleted the no-sound audio row of data\n","base_data2 = pd.read_csv(\"processed_music_matched_data.csv\")\n","base_data2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"203db33f-553e-4afe-b55e-a81f53da6db7"},"outputs":[],"source":["# 序列化 Melody 对象为 JSON 字符串\n","base_data['melody_json'] = base_data['melody'].apply(lambda x: json.dumps(x._events))\n","# 创建 HDF5 文件（'w' 代表写模式）\n","with h5py.File('processed_data_with_melody.h5', 'w') as hf:\n","    hf.create_dataset('image_features', data=np.array(base_data['image_features'].tolist()))\n","    hf.create_dataset('text_features', data=np.array(base_data['text_features'].tolist()))\n","    hf.create_dataset('features_mean', data=np.array(base_data['features_mean'].tolist()))\n","    hf.create_dataset('features_weighted', data=np.array(base_data['features_weighted'].tolist()))\n","    hf.create_dataset('melody', data=np.array(base_data['melody_json'].tolist()).astype('S'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dd8dacfd-add8-4515-b9ce-c03786a560dd","outputId":"471dbb61-34ed-435b-a084-767c35343003"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","      <th>image_features</th>\n","      <th>text_features</th>\n","      <th>features_mean</th>\n","      <th>features_weighted</th>\n","      <th>melody</th>\n","      <th>melody_json</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...</td>\n","      <td>[[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...</td>\n","      <td>[[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...</td>\n","      <td>(50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","      <td>[50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...</td>\n","      <td>[[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...</td>\n","      <td>[[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...</td>\n","      <td>(-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...</td>\n","      <td>[-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...</td>\n","      <td>[[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...</td>\n","      <td>[[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...</td>\n","      <td>(-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...</td>\n","      <td>[-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....</td>\n","      <td>[[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...</td>\n","      <td>[[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....</td>\n","      <td>(67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...</td>\n","      <td>[67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...</td>\n","      <td>[[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....</td>\n","      <td>[[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...</td>\n","      <td>(-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...</td>\n","      <td>[-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>422756</th>\n","      <td>david-burliuk_landscape-1</td>\n","      <td>The greenery landscape and flowery background ...</td>\n","      <td>M0ygCD6WyXw_0-10</td>\n","      <td>This clip consists of a blowing horn being pla...</td>\n","      <td>0.758374</td>\n","      <td>[[0.2013, -0.2996, 0.1554, -0.04733, 0.1796, -...</td>\n","      <td>[[0.06445, 0.1355, 0.3389, -0.1179, -0.04034, ...</td>\n","      <td>[[0.1328, -0.08203, 0.2471, -0.08264, 0.0696, ...</td>\n","      <td>[[0.1466, -0.1256, 0.2288, -0.07556, 0.0916, -...</td>\n","      <td>(-2, 66, 66, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n","      <td>[-2, 66, 66, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>422757</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","      <td>[[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...</td>\n","      <td>[[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...</td>\n","      <td>[[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....</td>\n","      <td>[[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....</td>\n","      <td>(-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...</td>\n","      <td>[-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...</td>\n","    </tr>\n","    <tr>\n","      <th>422758</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....</td>\n","      <td>[[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...</td>\n","      <td>[[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...</td>\n","      <td>(63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...</td>\n","      <td>[63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...</td>\n","    </tr>\n","    <tr>\n","      <th>422759</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...</td>\n","      <td>[[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...</td>\n","      <td>[[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...</td>\n","      <td>(50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","      <td>[50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>422760</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...</td>\n","      <td>[[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...</td>\n","      <td>[[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....</td>\n","      <td>(-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...</td>\n","      <td>[-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>422761 rows × 11 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","422756                          david-burliuk_landscape-1   \n","422757                           gino-severini_a-dancer-1   \n","422758                  ivan-aivazovsky_sea-at-night-1861   \n","422759                  ivan-aivazovsky_sea-at-night-1861   \n","422760                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","422756  The greenery landscape and flowery background ...   \n","422757  the collection and collage of different colors...   \n","422758  The peaceful reflections of the moonlight on t...   \n","422759  I can imagine the sailors resting this peacefu...   \n","422760  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","422756     M0ygCD6WyXw_0-10   \n","422757     oMZcsGUi8ZE_0-10   \n","422758    s1QeDT7jqHQ_30-40   \n","422759    ABVYSaLu_VM_10-20   \n","422760    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \\\n","0       Here we have a slow piano piece played in a ma...          0.791458   \n","1       This is a recording of two didgeridoos. They a...          0.772168   \n","2       This audio contains a female voice speaking in...          0.798202   \n","3       The low quality recording features a resonatin...          0.792188   \n","4       In this clip, a large bell is rung and left to...          0.740201   \n","...                                                   ...               ...   \n","422756  This clip consists of a blowing horn being pla...          0.758374   \n","422757  This clip features a synchronised playing of s...          0.799300   \n","422758  The low quality recording features multiple la...          0.781008   \n","422759  Here we have a slow piano piece played in a ma...          0.733153   \n","422760  The low quality recording features a theremin ...          0.761976   \n","\n","                                           image_features  \\\n","0       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","1       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","2       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","3       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","4       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","...                                                   ...   \n","422756  [[0.2013, -0.2996, 0.1554, -0.04733, 0.1796, -...   \n","422757  [[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...   \n","422758  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","422759  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","422760  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","\n","                                            text_features  \\\n","0       [[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...   \n","1       [[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...   \n","2       [[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...   \n","3       [[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....   \n","4       [[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...   \n","...                                                   ...   \n","422756  [[0.06445, 0.1355, 0.3389, -0.1179, -0.04034, ...   \n","422757  [[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...   \n","422758  [[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....   \n","422759  [[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...   \n","422760  [[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...   \n","\n","                                            features_mean  \\\n","0       [[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...   \n","1       [[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...   \n","2       [[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...   \n","3       [[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...   \n","4       [[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....   \n","...                                                   ...   \n","422756  [[0.1328, -0.08203, 0.2471, -0.08264, 0.0696, ...   \n","422757  [[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....   \n","422758  [[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...   \n","422759  [[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...   \n","422760  [[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...   \n","\n","                                        features_weighted  \\\n","0       [[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...   \n","1       [[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...   \n","2       [[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...   \n","3       [[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....   \n","4       [[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...   \n","...                                                   ...   \n","422756  [[0.1466, -0.1256, 0.2288, -0.07556, 0.0916, -...   \n","422757  [[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....   \n","422758  [[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...   \n","422759  [[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...   \n","422760  [[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....   \n","\n","                                                   melody  \\\n","0       (50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...   \n","1       (-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...   \n","2       (-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...   \n","3       (67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...   \n","4       (-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...   \n","...                                                   ...   \n","422756  (-2, 66, 66, 59, 59, 59, 59, 59, 59, 59, 59, 5...   \n","422757  (-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...   \n","422758  (63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...   \n","422759  (50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...   \n","422760  (-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...   \n","\n","                                              melody_json  \n","0       [50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...  \n","1       [-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...  \n","2       [-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...  \n","3       [67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...  \n","4       [-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...  \n","...                                                   ...  \n","422756  [-2, 66, 66, 59, 59, 59, 59, 59, 59, 59, 59, 5...  \n","422757  [-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...  \n","422758  [63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...  \n","422759  [50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...  \n","422760  [-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...  \n","\n","[422761 rows x 11 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["base_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adadf154-3461-4c05-9f41-e17e30eb9dbf"},"outputs":[],"source":["# 读取 HDF5 文件\n","with h5py.File('processed_data_with_melody.h5', 'r') as hf:\n","    melody_data = hf['melody'][:]\n","    # 反序列化 JSON 字符串为 Melody 对象\n","    melodies = [note_seq.Melody(json.loads(m.decode())) for m in melody_data]\n","\n","    image_features = hf['image_features'][:]\n","    text_features = hf['text_features'][:]\n","    features_mean = hf['features_mean'][:]\n","    features_weighted = hf['features_weighted'][:]\n","\n","# 将数组转换为列表（如果需要）并添加到 other_data DataFrame\n","base_data2['image_features'] = list(image_features)\n","base_data2['text_features'] = list(text_features)\n","base_data2['features_mean'] = list(features_mean)\n","base_data2['features_weighted'] = list(features_weighted)\n","base_data2['melody'] = list(melodies)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1116f204-da12-4a17-92ab-596b8044109f","outputId":"eb6df10b-2b74-4b14-d1b5-481cd9be5b54"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","      <th>image_features</th>\n","      <th>text_features</th>\n","      <th>features_mean</th>\n","      <th>features_weighted</th>\n","      <th>melody</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...</td>\n","      <td>[[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...</td>\n","      <td>[[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...</td>\n","      <td>(50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...</td>\n","      <td>[[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...</td>\n","      <td>[[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...</td>\n","      <td>(-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...</td>\n","      <td>[[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...</td>\n","      <td>[[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...</td>\n","      <td>(-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....</td>\n","      <td>[[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...</td>\n","      <td>[[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....</td>\n","      <td>(67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","      <td>[[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...</td>\n","      <td>[[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...</td>\n","      <td>[[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....</td>\n","      <td>[[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...</td>\n","      <td>(-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>422756</th>\n","      <td>david-burliuk_landscape-1</td>\n","      <td>The greenery landscape and flowery background ...</td>\n","      <td>M0ygCD6WyXw_0-10</td>\n","      <td>This clip consists of a blowing horn being pla...</td>\n","      <td>0.758374</td>\n","      <td>[[0.2013, -0.2996, 0.1554, -0.04733, 0.1796, -...</td>\n","      <td>[[0.06445, 0.1355, 0.3389, -0.1179, -0.04034, ...</td>\n","      <td>[[0.1328, -0.08203, 0.2471, -0.08264, 0.0696, ...</td>\n","      <td>[[0.1466, -0.1256, 0.2288, -0.07556, 0.0916, -...</td>\n","      <td>(-2, 66, 66, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>422757</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","      <td>[[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...</td>\n","      <td>[[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...</td>\n","      <td>[[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....</td>\n","      <td>[[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....</td>\n","      <td>(-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...</td>\n","    </tr>\n","    <tr>\n","      <th>422758</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....</td>\n","      <td>[[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...</td>\n","      <td>[[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...</td>\n","      <td>(63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...</td>\n","    </tr>\n","    <tr>\n","      <th>422759</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...</td>\n","      <td>[[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...</td>\n","      <td>[[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...</td>\n","      <td>(50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>422760</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","      <td>[[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....</td>\n","      <td>[[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...</td>\n","      <td>[[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...</td>\n","      <td>[[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....</td>\n","      <td>(-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>422761 rows × 10 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","422756                          david-burliuk_landscape-1   \n","422757                           gino-severini_a-dancer-1   \n","422758                  ivan-aivazovsky_sea-at-night-1861   \n","422759                  ivan-aivazovsky_sea-at-night-1861   \n","422760                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","422756  The greenery landscape and flowery background ...   \n","422757  the collection and collage of different colors...   \n","422758  The peaceful reflections of the moonlight on t...   \n","422759  I can imagine the sailors resting this peacefu...   \n","422760  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","422756     M0ygCD6WyXw_0-10   \n","422757     oMZcsGUi8ZE_0-10   \n","422758    s1QeDT7jqHQ_30-40   \n","422759    ABVYSaLu_VM_10-20   \n","422760    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \\\n","0       Here we have a slow piano piece played in a ma...          0.791458   \n","1       This is a recording of two didgeridoos. They a...          0.772168   \n","2       This audio contains a female voice speaking in...          0.798202   \n","3       The low quality recording features a resonatin...          0.792188   \n","4       In this clip, a large bell is rung and left to...          0.740201   \n","...                                                   ...               ...   \n","422756  This clip consists of a blowing horn being pla...          0.758374   \n","422757  This clip features a synchronised playing of s...          0.799300   \n","422758  The low quality recording features multiple la...          0.781008   \n","422759  Here we have a slow piano piece played in a ma...          0.733153   \n","422760  The low quality recording features a theremin ...          0.761976   \n","\n","                                           image_features  \\\n","0       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","1       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","2       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","3       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","4       [[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0...   \n","...                                                   ...   \n","422756  [[0.2013, -0.2996, 0.1554, -0.04733, 0.1796, -...   \n","422757  [[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.089...   \n","422758  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","422759  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","422760  [[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0....   \n","\n","                                            text_features  \\\n","0       [[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, ...   \n","1       [[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0...   \n","2       [[0.05783, -0.0409, -0.4458, -0.0473, -0.08594...   \n","3       [[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0....   \n","4       [[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753,...   \n","...                                                   ...   \n","422756  [[0.06445, 0.1355, 0.3389, -0.1179, -0.04034, ...   \n","422757  [[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782...   \n","422758  [[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0....   \n","422759  [[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, ...   \n","422760  [[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.014...   \n","\n","                                            features_mean  \\\n","0       [[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, ...   \n","1       [[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0...   \n","2       [[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, ...   \n","3       [[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.3...   \n","4       [[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0....   \n","...                                                   ...   \n","422756  [[0.1328, -0.08203, 0.2471, -0.08264, 0.0696, ...   \n","422757  [[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0....   \n","422758  [[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.103...   \n","422759  [[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.0...   \n","422760  [[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -...   \n","\n","                                        features_weighted  \\\n","0       [[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542...   \n","1       [[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.0...   \n","2       [[0.1821, -0.11926, -0.0989, -0.010765, 0.2378...   \n","3       [[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0....   \n","4       [[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, ...   \n","...                                                   ...   \n","422756  [[0.1466, -0.1256, 0.2288, -0.07556, 0.0916, -...   \n","422757  [[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0....   \n","422758  [[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0...   \n","422759  [[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.012...   \n","422760  [[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0....   \n","\n","                                                   melody  \n","0       (50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...  \n","1       (-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...  \n","2       (-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...  \n","3       (67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...  \n","4       (-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...  \n","...                                                   ...  \n","422756  (-2, 66, 66, 59, 59, 59, 59, 59, 59, 59, 59, 5...  \n","422757  (-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...  \n","422758  (63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...  \n","422759  (50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...  \n","422760  (-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...  \n","\n","[422761 rows x 10 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["base_data2"]}]}