{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4lw9210sr5I+Ia6qNuo5U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b0d1be61-1c5d-4954-85f3-645e9244fb93"},"source":["# Evaluate the Audio (Outputs)"]},{"cell_type":"markdown","source":["Mainly for Model Lyra and Pegasus."],"metadata":{"id":"vL5lGR0kOA07"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0518a88e-0b79-42af-85b5-49d166a08e16"},"outputs":[],"source":["import numpy as np\n","import librosa\n","import librosa.display\n","import scipy.signal\n","from sklearn.metrics import pairwise_distances\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"81923e42-e286-42bd-af98-8e52bc150549"},"source":["## Evaluation Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8d2e6d0f-15f8-490d-8d99-fac9f1dff3a2"},"outputs":[],"source":["# load audio file\n","def load_audio(filename):\n","    y, sr = librosa.load(filename, sr=None)\n","    return y, sr\n","\n","# calculate SNR\n","def calculate_snr(signal, noise):\n","    signal_power = np.mean(signal**2)\n","    noise_power = np.mean(noise**2)\n","    snr = 10 * np.log10(signal_power / noise_power)\n","    return snr\n","\n","# calculate resolution\n","def calculate_thd(signal, sr):\n","    harmonics = librosa.effects.harmonic(signal)\n","    residual = signal - harmonics\n","    thd = np.sqrt(np.sum(residual**2)) / np.sqrt(np.sum(signal**2))\n","    return thd\n","\n","# calculate MFCC\n","def calculate_mfcc(signal, sr, n_mfcc=13):\n","    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n","    return mfccs\n","\n","# Calculate the resolution of the audio signal (using simple energy distribution calculations)\n","def calculate_resolution(signal):\n","    resolution = np.sum(np.abs(np.diff(signal)))\n","    return resolution\n","\n","# Calculate the diversity of generated audio (distance metrics based on MFCC)\n","def calculate_diversity(audio_signals, sr):\n","    mfccs_list = [calculate_mfcc(signal, sr) for signal in audio_signals]\n","    mfccs_flattened = [mfcc.flatten() for mfcc in mfccs_list]\n","    diversity = np.mean(pairwise_distances(mfccs_flattened))\n","    return diversity"]},{"cell_type":"markdown","metadata":{"id":"c81419f8-297a-4b49-a3a2-b1e936a83c4a"},"source":["## Load the Audios"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eb7ef1ae-cb6f-4045-b516-89ee0650d7a0"},"outputs":[],"source":["model1_output1 = \"models outputs/model1_1.wav\"\n","model2_output1 = \"models outputs/model2_1.wav\"\n","\n","model1_output2 = \"models outputs/model1_2.wav\"\n","model2_output2 = \"models outputs/model2_2.wav\"\n","\n","model1_output3 = \"models outputs/model1_3.wav\"\n","model2_output3 = \"models outputs/model2_3.wav\"\n","\n","model1_signal1, model1_sr1 = load_audio(model1_output1)\n","model2_signal1, model2_sr1 = load_audio(model2_output1)\n","\n","model1_signal2, model1_sr2 = load_audio(model1_output2)\n","model2_signal2, model2_sr2 = load_audio(model2_output2)\n","\n","model1_signal3, model1_sr3 = load_audio(model1_output3)\n","model2_signal3, model2_sr3 = load_audio(model2_output3)"]},{"cell_type":"markdown","metadata":{"id":"6f9ef1e7-13d6-44eb-aba7-02fc48bcdb72"},"source":["### Evaluation for Audio1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bb1c70e-b925-4104-9191-31239489f251","outputId":"66dedb5d-18ad-4668-e92d-fc83aefaec9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["THD (model 1): 0.11003703624010086\n","THD (model 2): 0.11261150985956192\n","Resolution (model 1): 17528.90234375\n","Resolution (model 2): 17222.611328125\n"]}],"source":["# calculate THD\n","thd1 = calculate_thd(model1_signal1, model1_sr1)\n","print(f'THD (model 1): {thd1}')\n","\n","# calculate THD\n","thd2 = calculate_thd(model2_signal1, model2_sr1)\n","print(f'THD (model 2): {thd2}')\n","\n","# calculate resolution\n","resolution1 = calculate_resolution(model1_signal1)\n","resolution2 = calculate_resolution(model2_signal1)\n","print(f'Resolution (model 1): {resolution1}')\n","print(f'Resolution (model 2): {resolution2}')"]},{"cell_type":"markdown","metadata":{"id":"5fa31207-11a2-4998-a99b-270d91a22d40"},"source":["### Evaluation for Audio2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06a63d92-02a7-4a86-9041-430b83c2053c","outputId":"4a213968-126a-4391-d04c-c9b9042f81d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["THD (model 1): 0.11390731483697891\n","THD (model 2): 0.1219075471162796\n","Resolution (model 1): 18634.3828125\n","Resolution (model 2): 19353.29296875\n"]}],"source":["# calculate THD\n","thd1 = calculate_thd(model1_signal2, model1_sr2)\n","print(f'THD (model 1): {thd1}')\n","\n","# calculate THD\n","thd2 = calculate_thd(model2_signal2, model2_sr2)\n","print(f'THD (model 2): {thd2}')\n","\n","# calculate resolution\n","resolution1 = calculate_resolution(model1_signal2)\n","resolution2 = calculate_resolution(model2_signal2)\n","print(f'Resolution (model 1): {resolution1}')\n","print(f'Resolution (model 2): {resolution2}')"]},{"cell_type":"markdown","metadata":{"id":"bb13b8a0-a0c0-4d3b-84d5-d353fd348771"},"source":["### Evaluation for Audio3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44e2435a-792f-43b3-8f9f-9f959cfc536b","outputId":"c8d8bb55-3cd1-44fb-c2dd-3c31162ed884"},"outputs":[{"name":"stdout","output_type":"stream","text":["THD (model 1): 0.10915417969226837\n","THD (model 2): 0.11625958234071732\n","Resolution (model 1): 18693.884765625\n","Resolution (model 2): 19340.333984375\n"]}],"source":["# calculate THD\n","thd1 = calculate_thd(model1_signal3, model1_sr3)\n","print(f'THD (model 1): {thd1}')\n","\n","# calculate THD\n","thd2 = calculate_thd(model2_signal3, model2_sr3)\n","print(f'THD (model 2): {thd2}')\n","\n","# calculate resolution\n","resolution1 = calculate_resolution(model1_signal3)\n","resolution2 = calculate_resolution(model2_signal3)\n","print(f'Resolution (model 1): {resolution1}')\n","print(f'Resolution (model 2): {resolution2}')"]},{"cell_type":"markdown","metadata":{"id":"bdc87732-5456-4c6c-9130-b01ee635e4ef"},"source":["## Diversity Evaluation"]},{"cell_type":"markdown","metadata":{"id":"07b5e888-e489-4505-a65d-307a6e1784e6"},"source":["### Model Lyra"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0d27c456-30d5-411f-b165-79c56e8d1569","outputId":"91eff7df-f24d-4a51-9c5c-01cb87fbf6c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Diversity: 363.7644348144531\n"]}],"source":["# calculate diversity\n","model1_audio_files = [model1_output1, model1_output2, model1_output3]\n","\n","audio_signals = [load_audio(file)[0] for file in model1_audio_files]\n","sr = load_audio(model1_audio_files[0])[1]\n","\n","diversity = calculate_diversity(audio_signals, sr)\n","print(f'Diversity: {diversity}')"]},{"cell_type":"markdown","metadata":{"id":"149436b3-5ee9-4b16-9d50-2173f44af4e4"},"source":["### Model Pegasus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8d2d263b-4b16-42db-8257-a5f58d0dc70d","outputId":"84ae85c7-6e9f-4c0f-fbbf-4e6c05b4a7fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Diversity: 621.8104858398438\n"]}],"source":["model1_audio_files = [model2_output1, model2_output2, model2_output3]\n","\n","audio_signals = [load_audio(file)[0] for file in model1_audio_files]\n","sr = load_audio(model1_audio_files[0])[1]\n","\n","diversity = calculate_diversity(audio_signals, sr)\n","print(f'Diversity: {diversity}')"]}]}