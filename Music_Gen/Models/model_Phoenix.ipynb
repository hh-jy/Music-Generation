{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPD8izSa0xlXXholXi5EAIj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Model Phoenix"],"metadata":{"id":"kZblIId0-Q1E"}},{"cell_type":"markdown","source":["* Based on a self-attention mechanism, the Transformer model can process the entire sequence in parallel and model the relationships of each element in the sequence, which helps to capture more complex dependencies while increasing diversity in the build process.\n","* The Transformer architecture is excellent for processing serial data, especially for NLP and music generation tasks."],"metadata":{"id":"m0gmZqM9-kzy"}},{"cell_type":"markdown","metadata":{"id":"e3c32499-8696-4ad4-bd7a-0b9f096475de"},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ff187762-f931-44ce-b6af-0b54ddcaca95"},"outputs":[],"source":["import numpy as np\n","import librosa\n","from note_seq.protobuf import music_pb2\n","from note_seq.midi_synth import fluidsynth\n","from note_seq import sequences_lib\n","from note_seq import audio_io\n","from note_seq import midi_io\n","from pydub import AudioSegment\n","import tensorflow as tf\n","from note_seq import note_sequence_to_midi_file, NoteSequence, midi_to_note_sequence\n","from magenta.models.music_vae import TrainedModel, configs\n","\n","import pandas as pd\n","import torch\n","import clip\n","from PIL import Image\n","import os\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","import torch\n","import torch.nn as nn\n","import note_seq\n","\n","from tensorflow.keras.layers import Input, Dense, Lambda, LSTM, RNN, LSTMCell, RepeatVector, TimeDistributed, Layer, Dropout, BatchNormalization, LeakyReLU, LayerNormalization, MultiHeadAttention\n","from tensorflow.keras import Model\n","from tensorflow.keras import backend as K\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tqdm import tqdm\n","\n","import h5py\n","import json\n","\n","from tensorflow.keras.models import load_model\n","from scipy.io.wavfile import write\n","import fluidsynth\n","\n","from nltk.corpus import opinion_lexicon\n","from nltk.tokenize import word_tokenize\n","import random"]},{"cell_type":"markdown","metadata":{"id":"ae5aa86d-54e2-4e43-9f84-31cbec2a931d"},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"de27d8fb-adcd-41ec-9a5f-1b4345d94603","outputId":"f7680869-c876-469e-c6d3-cd2d92f765f7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>422756</th>\n","      <td>david-burliuk_landscape-1</td>\n","      <td>The greenery landscape and flowery background ...</td>\n","      <td>M0ygCD6WyXw_0-10</td>\n","      <td>This clip consists of a blowing horn being pla...</td>\n","      <td>0.758374</td>\n","    </tr>\n","    <tr>\n","      <th>422757</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","    </tr>\n","    <tr>\n","      <th>422758</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","    </tr>\n","    <tr>\n","      <th>422759</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","    </tr>\n","    <tr>\n","      <th>422760</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>422761 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","422756                          david-burliuk_landscape-1   \n","422757                           gino-severini_a-dancer-1   \n","422758                  ivan-aivazovsky_sea-at-night-1861   \n","422759                  ivan-aivazovsky_sea-at-night-1861   \n","422760                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","422756  The greenery landscape and flowery background ...   \n","422757  the collection and collage of different colors...   \n","422758  The peaceful reflections of the moonlight on t...   \n","422759  I can imagine the sailors resting this peacefu...   \n","422760  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","422756     M0ygCD6WyXw_0-10   \n","422757     oMZcsGUi8ZE_0-10   \n","422758    s1QeDT7jqHQ_30-40   \n","422759    ABVYSaLu_VM_10-20   \n","422760    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \n","0       Here we have a slow piano piece played in a ma...          0.791458  \n","1       This is a recording of two didgeridoos. They a...          0.772168  \n","2       This audio contains a female voice speaking in...          0.798202  \n","3       The low quality recording features a resonatin...          0.792188  \n","4       In this clip, a large bell is rung and left to...          0.740201  \n","...                                                   ...               ...  \n","422756  This clip consists of a blowing horn being pla...          0.758374  \n","422757  This clip features a synchronised playing of s...          0.799300  \n","422758  The low quality recording features multiple la...          0.781008  \n","422759  Here we have a slow piano piece played in a ma...          0.733153  \n","422760  The low quality recording features a theremin ...          0.761976  \n","\n","[422761 rows x 5 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Load processed matched musical data, which has deleted the no-sound audio row of data\n","base_data = pd.read_csv(\"processed_music_matched_data.csv\")\n","base_data"]},{"cell_type":"markdown","metadata":{"id":"93473adf-4e83-4523-8ecb-bd877981b568"},"source":["### Load Dataset with Extracted Features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"899d0278-7721-45fa-99a0-514bd12969bb"},"outputs":[],"source":["# load HDF5 file\n","with h5py.File('processed_data_with_melody2.h5', 'r') as hf:\n","    melody_data = hf['melody'][:]\n","    # Deserialize the JSON string to the Melody object\n","    melodies = [note_seq.Melody(json.loads(m.decode())) for m in melody_data]\n","\n","    image_features = hf['image_features'][:]\n","    text_features = hf['text_features'][:]\n","    features_mean = hf['features_mean'][:]\n","    features_weighted = hf['features_weighted'][:]\n","    combined_features = hf['combined_features'][:]\n","\n","# Convert the array to a list and add it to other_data DataFrame\n","base_data['image_features'] = list(image_features)\n","base_data['text_features'] = list(text_features)\n","base_data['features_mean'] = list(features_mean)\n","base_data['features_weighted'] = list(features_weighted)\n","base_data['melody'] = list(melodies)\n","base_data['combined_features'] = list(combined_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5c30bf61-c684-4058-8fb7-34fe3822b891","outputId":"ffbfcc02-13c8-47fe-bedc-179ea6cc84e8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Artwork</th>\n","      <th>Art_Utterance</th>\n","      <th>Music_Name</th>\n","      <th>Music_Comment</th>\n","      <th>Similarity_Score</th>\n","      <th>image_features</th>\n","      <th>text_features</th>\n","      <th>features_mean</th>\n","      <th>features_weighted</th>\n","      <th>melody</th>\n","      <th>combined_features</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She seems very happy in the picture, and you w...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.791458</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","      <td>[-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, -...</td>\n","      <td>[0.1167, 0.002075, -0.0323, 0.03006, 0.2042, -...</td>\n","      <td>[0.1464, -0.03265, 0.0006714, 0.02676, 0.2542,...</td>\n","      <td>(50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>This woman has really knotty hands which makes...</td>\n","      <td>vnwKpQeza3A_320-330</td>\n","      <td>This is a recording of two didgeridoos. They a...</td>\n","      <td>0.772168</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","      <td>[-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0....</td>\n","      <td>[0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0....</td>\n","      <td>[0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.04...</td>\n","      <td>(-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>When looking at this woman, I am filled with c...</td>\n","      <td>0VwX92X3iPc_30-40</td>\n","      <td>This audio contains a female voice speaking in...</td>\n","      <td>0.798202</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","      <td>[0.05783, -0.0409, -0.4458, -0.0473, -0.08594,...</td>\n","      <td>[0.1614, -0.1062, -0.1567, -0.01685, 0.1838, -...</td>\n","      <td>[0.1821, -0.11926, -0.0989, -0.010765, 0.2378,...</td>\n","      <td>(-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>A woman looking at ease, peaceful, and satisfi...</td>\n","      <td>kh6rmFg3U4k_480-490</td>\n","      <td>The low quality recording features a resonatin...</td>\n","      <td>0.792188</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","      <td>[0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0.5...</td>\n","      <td>[0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.36...</td>\n","      <td>[0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0.3...</td>\n","      <td>(67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vincent-van-gogh_portrait-of-madame-ginoux-l-a...</td>\n","      <td>She looks like a lady from that past that migh...</td>\n","      <td>-VI2IRq17rs_360-370</td>\n","      <td>In this clip, a large bell is rung and left to...</td>\n","      <td>0.740201</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","      <td>[-0.1611, -0.002035, -0.2603, 0.1305, 0.1753, ...</td>\n","      <td>[0.05188, -0.0868, -0.064, 0.072, 0.3145, -0.2...</td>\n","      <td>[0.0945, -0.1037, -0.02472, 0.06033, 0.3423, -...</td>\n","      <td>(-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...</td>\n","      <td>[0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>422756</th>\n","      <td>david-burliuk_landscape-1</td>\n","      <td>The greenery landscape and flowery background ...</td>\n","      <td>M0ygCD6WyXw_0-10</td>\n","      <td>This clip consists of a blowing horn being pla...</td>\n","      <td>0.758374</td>\n","      <td>[0.2013, -0.2996, 0.1554, -0.04733, 0.1796, -0...</td>\n","      <td>[0.06445, 0.1355, 0.3389, -0.1179, -0.04034, 0...</td>\n","      <td>[0.1328, -0.08203, 0.2471, -0.08264, 0.0696, 0...</td>\n","      <td>[0.1466, -0.1256, 0.2288, -0.07556, 0.0916, -0...</td>\n","      <td>(-2, 66, 66, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n","      <td>[0.2013, -0.2996, 0.1554, -0.04733, 0.1796, -0...</td>\n","    </tr>\n","    <tr>\n","      <th>422757</th>\n","      <td>gino-severini_a-dancer-1</td>\n","      <td>the collection and collage of different colors...</td>\n","      <td>oMZcsGUi8ZE_0-10</td>\n","      <td>This clip features a synchronised playing of s...</td>\n","      <td>0.799300</td>\n","      <td>[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.0896...</td>\n","      <td>[-0.05054, 0.3774, 0.2979, -0.06555, -0.04782,...</td>\n","      <td>[0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0.0...</td>\n","      <td>[0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0.0...</td>\n","      <td>(-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...</td>\n","      <td>[0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.0896...</td>\n","    </tr>\n","    <tr>\n","      <th>422758</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The peaceful reflections of the moonlight on t...</td>\n","      <td>s1QeDT7jqHQ_30-40</td>\n","      <td>The low quality recording features multiple la...</td>\n","      <td>0.781008</td>\n","      <td>[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...</td>\n","      <td>[0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0.1...</td>\n","      <td>[0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.1034...</td>\n","      <td>[0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0....</td>\n","      <td>(63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...</td>\n","      <td>[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>422759</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>I can imagine the sailors resting this peacefu...</td>\n","      <td>ABVYSaLu_VM_10-20</td>\n","      <td>Here we have a slow piano piece played in a ma...</td>\n","      <td>0.733153</td>\n","      <td>[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...</td>\n","      <td>[-0.01753, -0.018, 0.11707, -0.0385, 0.2886, 0...</td>\n","      <td>[0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.02...</td>\n","      <td>[0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.0121...</td>\n","      <td>(50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...</td>\n","      <td>[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>422760</th>\n","      <td>ivan-aivazovsky_sea-at-night-1861</td>\n","      <td>The steep mountains and the moonlight provide ...</td>\n","      <td>8q0An6WY7_c_10-20</td>\n","      <td>The low quality recording features a theremin ...</td>\n","      <td>0.761976</td>\n","      <td>[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...</td>\n","      <td>[-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.0142...</td>\n","      <td>[-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -0...</td>\n","      <td>[0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0.0...</td>\n","      <td>(-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...</td>\n","      <td>[0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>422761 rows × 11 columns</p>\n","</div>"],"text/plain":["                                                  Artwork  \\\n","0       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","1       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","2       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","3       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","4       vincent-van-gogh_portrait-of-madame-ginoux-l-a...   \n","...                                                   ...   \n","422756                          david-burliuk_landscape-1   \n","422757                           gino-severini_a-dancer-1   \n","422758                  ivan-aivazovsky_sea-at-night-1861   \n","422759                  ivan-aivazovsky_sea-at-night-1861   \n","422760                  ivan-aivazovsky_sea-at-night-1861   \n","\n","                                            Art_Utterance  \\\n","0       She seems very happy in the picture, and you w...   \n","1       This woman has really knotty hands which makes...   \n","2       When looking at this woman, I am filled with c...   \n","3       A woman looking at ease, peaceful, and satisfi...   \n","4       She looks like a lady from that past that migh...   \n","...                                                   ...   \n","422756  The greenery landscape and flowery background ...   \n","422757  the collection and collage of different colors...   \n","422758  The peaceful reflections of the moonlight on t...   \n","422759  I can imagine the sailors resting this peacefu...   \n","422760  The steep mountains and the moonlight provide ...   \n","\n","                 Music_Name  \\\n","0         ABVYSaLu_VM_10-20   \n","1       vnwKpQeza3A_320-330   \n","2         0VwX92X3iPc_30-40   \n","3       kh6rmFg3U4k_480-490   \n","4       -VI2IRq17rs_360-370   \n","...                     ...   \n","422756     M0ygCD6WyXw_0-10   \n","422757     oMZcsGUi8ZE_0-10   \n","422758    s1QeDT7jqHQ_30-40   \n","422759    ABVYSaLu_VM_10-20   \n","422760    8q0An6WY7_c_10-20   \n","\n","                                            Music_Comment  Similarity_Score  \\\n","0       Here we have a slow piano piece played in a ma...          0.791458   \n","1       This is a recording of two didgeridoos. They a...          0.772168   \n","2       This audio contains a female voice speaking in...          0.798202   \n","3       The low quality recording features a resonatin...          0.792188   \n","4       In this clip, a large bell is rung and left to...          0.740201   \n","...                                                   ...               ...   \n","422756  This clip consists of a blowing horn being pla...          0.758374   \n","422757  This clip features a synchronised playing of s...          0.799300   \n","422758  The low quality recording features multiple la...          0.781008   \n","422759  Here we have a slow piano piece played in a ma...          0.733153   \n","422760  The low quality recording features a theremin ...          0.761976   \n","\n","                                           image_features  \\\n","0       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....   \n","1       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....   \n","2       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....   \n","3       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....   \n","4       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....   \n","...                                                   ...   \n","422756  [0.2013, -0.2996, 0.1554, -0.04733, 0.1796, -0...   \n","422757  [0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.0896...   \n","422758  [0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...   \n","422759  [0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...   \n","422760  [0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...   \n","\n","                                            text_features  \\\n","0       [-0.0315, 0.1757, -0.1968, 0.0465, -0.04526, -...   \n","1       [-0.0724, 0.3037, -0.4678, -0.1588, 0.1721, 0....   \n","2       [0.05783, -0.0409, -0.4458, -0.0473, -0.08594,...   \n","3       [0.1517, -0.2998, 0.1375, 0.3303, 0.3237, -0.5...   \n","4       [-0.1611, -0.002035, -0.2603, 0.1305, 0.1753, ...   \n","...                                                   ...   \n","422756  [0.06445, 0.1355, 0.3389, -0.1179, -0.04034, 0...   \n","422757  [-0.05054, 0.3774, 0.2979, -0.06555, -0.04782,...   \n","422758  [0.0625, -0.1382, 0.1168, 0.2683, 0.3545, -0.1...   \n","422759  [-0.01753, -0.018, 0.11707, -0.0385, 0.2886, 0...   \n","422760  [-0.2, -0.1665, 0.2362, 0.0648, 0.2886, 0.0142...   \n","\n","                                            features_mean  \\\n","0       [0.1167, 0.002075, -0.0323, 0.03006, 0.2042, -...   \n","1       [0.09625, 0.0661, -0.1677, -0.07263, 0.313, 0....   \n","2       [0.1614, -0.1062, -0.1567, -0.01685, 0.1838, -...   \n","3       [0.2083, -0.2356, 0.1348, 0.172, 0.3887, -0.36...   \n","4       [0.05188, -0.0868, -0.064, 0.072, 0.3145, -0.2...   \n","...                                                   ...   \n","422756  [0.1328, -0.08203, 0.2471, -0.08264, 0.0696, 0...   \n","422757  [0.1157, 0.2744, 0.2466, -0.1272, 0.1846, -0.0...   \n","422758  [0.1274, -0.2164, 0.0941, 0.33, 0.317, -0.1034...   \n","422759  [0.0874, -0.1564, 0.09424, 0.1768, 0.284, 0.02...   \n","422760  [-0.003784, -0.2306, 0.1538, 0.2285, 0.284, -0...   \n","\n","                                        features_weighted  \\\n","0       [0.1464, -0.03265, 0.0006714, 0.02676, 0.2542,...   \n","1       [0.13, 0.01855, -0.10767, -0.0554, 0.341, 0.04...   \n","2       [0.1821, -0.11926, -0.0989, -0.010765, 0.2378,...   \n","3       [0.2196, -0.2228, 0.1343, 0.1403, 0.4019, -0.3...   \n","4       [0.0945, -0.1037, -0.02472, 0.06033, 0.3423, -...   \n","...                                                   ...   \n","422756  [0.1466, -0.1256, 0.2288, -0.07556, 0.0916, -0...   \n","422757  [0.1489, 0.2537, 0.2363, -0.1395, 0.2311, -0.0...   \n","422758  [0.1405, -0.2322, 0.08954, 0.3428, 0.3093, -0....   \n","422759  [0.10846, -0.1841, 0.0896, 0.22, 0.283, 0.0121...   \n","422760  [0.03552, -0.2434, 0.1373, 0.2612, 0.283, -0.0...   \n","\n","                                                   melody  \\\n","0       (50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...   \n","1       (-2, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 3...   \n","2       (-2, -2, -2, -2, -2, -2, 57, 56, 56, 55, 55, -...   \n","3       (67, 67, 67, 67, 67, 67, 67, 67, 67, 66, 66, -...   \n","4       (-2, -2, 60, 60, -1, -2, -2, -2, 60, 60, 60, -...   \n","...                                                   ...   \n","422756  (-2, 66, 66, 59, 59, 59, 59, 59, 59, 59, 59, 5...   \n","422757  (-2, -2, 69, 69, -1, 64, -1, -2, -2, 71, 71, 7...   \n","422758  (63, 63, 60, 60, 63, 63, 63, 65, 65, 63, 62, 6...   \n","422759  (50, -1, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5...   \n","422760  (-2, -2, -2, -2, -2, -2, 81, 81, 81, 81, 81, 8...   \n","\n","                                        combined_features  \n","0       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....  \n","1       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....  \n","2       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....  \n","3       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....  \n","4       [0.265, -0.1715, 0.1322, 0.013596, 0.4536, -0....  \n","...                                                   ...  \n","422756  [0.2013, -0.2996, 0.1554, -0.04733, 0.1796, -0...  \n","422757  [0.282, 0.1711, 0.1952, -0.1887, 0.417, 0.0896...  \n","422758  [0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...  \n","422759  [0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...  \n","422760  [0.1924, -0.2947, 0.07135, 0.392, 0.2793, -0.0...  \n","\n","[422761 rows x 11 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["base_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0f04d407-7a0f-41c8-bb9e-993794338369","outputId":"b65ab5a7-6f18-4f9a-fe99-eb885946d62b"},"outputs":[{"name":"stdout","output_type":"stream","text":["shape of combined features:  (422761, 1024)\n","shape of features mean:  (422761, 512)\n","shape of features weighted:  (422761, 512)\n","Exist different length of _events，there are 80 kinds of lenegth\n"]}],"source":["print('shape of combined features: ', combined_features.shape)\n","print('shape of features mean: ', features_mean.shape)\n","print('shape of features weighted: ', features_weighted.shape)\n","\n","# Calculates the length of each Melody object _events\n","event_lengths = base_data['melody'].apply(lambda x: len(x._events))\n","# Check that all _events have the same length\n","unique_length_count = event_lengths.nunique()\n","# print the result\n","if unique_length_count == 1:\n","    print(\"All Melody obejcts have the same length of _events\")\n","else:\n","    print(f\"Exist different length of _events，there are {unique_length_count} kinds of lenegth\")"]},{"cell_type":"markdown","metadata":{"id":"b4d03a13-fdfe-4b41-a568-8566d4087b45"},"source":["## Create Data Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdfe5658-20e9-4704-b33b-dee5abf20a77","outputId":"6a336f93-4c05-4cdb-b958-ce2e2d2fa3d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["The max length of events: 81\n"]}],"source":["# Calculates the length of each Melody object _events\n","max_length = base_data['melody'].apply(lambda x: len(x._events)).max()\n","# max_length is now the longest _events length in the entire dataset\n","print(\"The max length of events:\", max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"060bc5c8-0fd7-4515-9ffc-497decbff7b8","outputId":"245e9608-9767-42ea-851f-e4a6388aa1a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["min:  -6.195\n","max:  5.023\n"]}],"source":["global_min_feature = base_data['features_mean'].apply(lambda x: np.min(x)).min()\n","global_max_feature = base_data['features_mean'].apply(lambda x: np.max(x)).max()\n","\n","print('min: ', global_min_feature)\n","print('max: ', global_max_feature)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8c280777-787b-4e7c-802b-277908de2a6e"},"outputs":[],"source":["def normalize(data, min_val, max_val):\n","    normalized_data = 2 * (data - min_val) / (max_val - min_val) - 1\n","    return normalized_data\n","\n","def denormalize(data, min_val, max_val):\n","    data = (data + 1) / 2 * (max_val - min_val) + min_val\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb8599d2-adce-449c-8f14-a9381b576362"},"outputs":[],"source":["def augment_data(features):\n","    augmented_features = []\n","    for feature in features:\n","        noise = np.random.normal(0, 0.1, feature.shape)\n","        augmented_features.append(feature + noise)\n","    return np.array(augmented_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ff983a60-8dd8-44b3-82a0-e512145c96de"},"outputs":[],"source":["def data_generator(df, feature_col, batch_size, max_length):\n","    num_batches = (len(df) + batch_size - 1) // batch_size\n","\n","    for i in range(num_batches):\n","        batch_slice = slice(i * batch_size, min((i + 1) * batch_size, len(df)))\n","        batch = df.iloc[batch_slice]\n","\n","        # Deal with melody\n","        melody_tensors = []\n","        for melody in batch['melody']:\n","            melody_events = melody._events\n","            melody_tensor = tf.convert_to_tensor(melody_events, dtype=tf.float32)\n","            melody_tensor = normalize(melody_tensor,-2, 127)\n","            # Calculate the number of fillers you need\n","            padding_needed = max_length - tf.shape(melody_tensor)[0]\n","\n","            # Fill if padding_needed is greater than 0\n","            if padding_needed > 0:\n","                padded_melody_tensor = tf.pad(melody_tensor, [[0, padding_needed]], \"CONSTANT\")\n","            else:\n","                padded_melody_tensor = melody_tensor\n","\n","            padded_melody_tensor = tf.expand_dims(padded_melody_tensor, -1)\n","            melody_tensors.append(padded_melody_tensor)\n","\n","        features = np.array(batch[feature_col].tolist())\n","        augmented_features = augment_data(features)\n","        normalized_features = normalize(augmented_features, global_min_feature, global_max_feature)\n","\n","        yield  (normalized_features, np.stack(melody_tensors)), np.stack(melody_tensors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f550e2d6-9949-4f70-ab80-95019e23dc9c"},"outputs":[],"source":["def created_dataset(df, features_col, batch_size, max_length):\n","    dataset = tf.data.Dataset.from_generator(\n","    lambda: data_generator(df, features_col, batch_size, max_length),\n","    output_signature=(\n","        (tf.TensorSpec(shape=(None, np.stack(df[features_col].values).shape[1]), dtype=tf.float32),         # Adjust this as well\n","        tf.TensorSpec(shape=(None, max_length, 1), dtype=tf.float32)),  # Adjust the shape based on your actual data\n","        tf.TensorSpec(shape=(None, max_length, 1), dtype=tf.float32)\n","    )\n",")\n","    return dataset"]},{"cell_type":"markdown","metadata":{"id":"2e5cf614-4f14-4c78-9ae7-7b5777370b74"},"source":["## Seperate the Dataset (Train data, Test data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4f45eca2-9b49-4d13-85aa-a65abf0802d2","outputId":"27af1435-edba-461a-fd61-ac7abdc71250"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Melodies shape: (16, 81, 1)\n","Train Features shape: (16, 512)\n","Test Melodies shape: (16, 81, 1)\n","Test Features shape: (16, 512)\n"]}],"source":["batch_size = 16\n","max_length = 81\n","\n","dataset = created_dataset(base_data, 'features_mean', batch_size, max_length)\n","\n","# Shuffle and seperate the dataset\n","dataset = dataset.shuffle(buffer_size=1000)\n","train_size = int(0.8 * sum(1 for _ in dataset))\n","train_dataset = dataset.take(train_size)\n","test_dataset = dataset.skip(train_size)\n","\n","# Print out for verification\n","for (features, melodies), true_melodies in train_dataset.take(1):\n","    print(\"Train Melodies shape:\", melodies.shape)\n","    print(\"Train Features shape:\", features.shape)\n","\n","for (features, melodies), true_melodies in test_dataset.take(1):\n","    print(\"Test Melodies shape:\", melodies.shape)\n","    print(\"Test Features shape:\", features.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"7efc6ae2-3e6f-4688-8b01-2e765f367104","outputId":"bd4caeae-22df-47ce-8b3f-22a7c644cb55"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Melodies shape: [[[-1.        ]\n","  [-0.4263566 ]\n","  [-0.4263566 ]\n","  ...\n","  [-0.41085273]\n","  [-0.4263566 ]\n","  [-0.4263566 ]]\n","\n"," [[-0.10077518]\n","  [-0.10077518]\n","  [-0.10077518]\n","  ...\n","  [ 0.        ]\n","  [ 0.        ]\n","  [ 0.        ]]\n","\n"," [[ 0.2093023 ]\n","  [ 0.2093023 ]\n","  [ 0.17829454]\n","  ...\n","  [ 0.2093023 ]\n","  [ 0.2093023 ]\n","  [ 0.2093023 ]]\n","\n"," ...\n","\n"," [[-1.        ]\n","  [-1.        ]\n","  [-1.        ]\n","  ...\n","  [-1.        ]\n","  [-1.        ]\n","  [-0.22480619]]\n","\n"," [[-0.25581396]\n","  [-0.25581396]\n","  [-0.25581396]\n","  ...\n","  [-0.28682172]\n","  [-0.27131784]\n","  [-0.31782943]]\n","\n"," [[-1.        ]\n","  [-1.        ]\n","  [-1.        ]\n","  ...\n","  [ 0.        ]\n","  [ 0.        ]\n","  [ 0.        ]]]\n","Train Features shape: [[0.13999909 0.07518089 0.11259886 ... 0.18333589 0.10209716 0.07586011]\n"," [0.08232404 0.09179335 0.07168759 ... 0.07675587 0.06982681 0.13599318]\n"," [0.15500376 0.04933098 0.10326672 ... 0.01411227 0.08852018 0.16527387]\n"," ...\n"," [0.09959353 0.03951982 0.11845498 ... 0.11777332 0.0954692  0.12650113]\n"," [0.0761585  0.02206802 0.09464581 ... 0.07939823 0.10014649 0.15365586]\n"," [0.11471324 0.10682762 0.08614465 ... 0.09066269 0.11836759 0.12485005]]\n"]}],"source":["# Print out for verification\n","for (features, melodies), true_melodies in train_dataset.take(1):\n","    print(\"Train Melodies shape:\", melodies.numpy())\n","    print(\"Train Features shape:\", features.numpy())"]},{"cell_type":"markdown","metadata":{"id":"5465e8e9-b9b5-491a-8dcb-bf125f50060e"},"source":["## Generative Model (VAE)"]},{"cell_type":"markdown","metadata":{"id":"bc71dd8e-703b-4aed-ae38-54c6538c10c1"},"source":["For feature vectors extracted by CLIP model, we may not need too complex encoder network, because these features are already at a high level of abstraction. As a result, the encoder can be simpler to keep this encoded high-level information, while the decoder may need more tweaking to produce a more detailed output (such as a music sequence)."]},{"cell_type":"markdown","metadata":{"id":"cdb05cda-b240-4198-8c8b-53b3f193cd1d"},"source":["### Sampling"]},{"cell_type":"markdown","metadata":{"id":"56b305be-3d93-4755-a4ec-545dc718317b"},"source":["The sampling function samples a potential vector from the normal distribution 𝑧 using the reparameterization trick. This function avoids the gradient propagation problem caused by random nodes and allows the model to be trained using backpropagation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf79c7a1-2f87-4fbd-b4e5-f64416898175"},"outputs":[],"source":["# Define the sampling function\n","def sampling(args):\n","    z_mean, z_log_sigma = args\n","    batch = K.shape(z_mean)[0]\n","    dim = K.int_shape(z_mean)[1]\n","    epsilon = K.random_normal(shape=(batch, dim))\n","    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon"]},{"cell_type":"markdown","metadata":{"id":"3c046e98-244b-4c2f-95af-2455bce8baef"},"source":["### Encoder"]},{"cell_type":"markdown","metadata":{"id":"3cce90a4-8945-4e40-a4ff-4f3d2bd593af"},"source":["Since the input features are already highly abstract, encoders can be simplified or designed to be more focused on accommodating such high-dimensional features.\n","The encoder maps the input data to the latent space, outputs the potential mean z_mean and the potential log-variance z_log_sigma, and uses the sampling function to generate the potential vector 𝑧."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d345339-66c8-4e90-ac59-d0bffef1d69c"},"outputs":[],"source":["def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Attention and standardization\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs  # Residual connection\n","\n","    # Part of the feedforward network\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res  # Residual connection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ed431607-5bca-4ade-b9da-cc17e26d78fc"},"outputs":[],"source":["def build_encoder(input_dim, latent_dim):\n","    inputs = Input(shape=(input_dim,))\n","    x = Dense(512)(inputs)\n","    x = LeakyReLU(alpha=0.01)(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","    x = Dense(256)(x)\n","    x = LeakyReLU(alpha=0.01)(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","    x = Dense(128)(x)\n","    z_mean = Dense(latent_dim)(x)\n","    z_log_sigma = Dense(latent_dim)(x)\n","\n","    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n","    encoder = Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n","    encoder.summary()\n","    return encoder"]},{"cell_type":"markdown","metadata":{"id":"596dd94f-e67f-4680-87e7-c6769b73f405"},"source":["### Decoder"]},{"cell_type":"markdown","metadata":{"id":"17c8ec52-5732-4064-a80c-58f53f9b6ce4"},"source":["Learn how to generate concrete musical sequences from abstract features extracted from the latent space. Predict every note or event in Melody."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1551898-6d32-4997-a1cb-bae78072e384"},"outputs":[],"source":["def build_decoder(latent_dim, sequence_length):\n","    latent_inputs = Input(shape=(latent_dim,))\n","    x = Dense(128, activation='relu')(latent_inputs)\n","    x = tf.keras.layers.RepeatVector(sequence_length)(x)\n","\n","    # Transformer block\n","    x = transformer_encoder(x, head_size=64, num_heads=2, ff_dim=128, dropout=0.05)  # Reduce complexity and dropout\n","\n","    outputs = TimeDistributed(Dense(1, activation='linear'))(x)\n","    decoder = Model(latent_inputs, outputs, name='decoder')\n","    decoder.summary()\n","    return decoder"]},{"cell_type":"markdown","metadata":{"id":"da4d5408-1900-406a-a39e-a21421c6af04"},"source":["### VAE Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65a8e2f7-b193-4034-9b5a-cc9b027aaf74"},"outputs":[],"source":["# Custom refactoring losses\n","def reconstruction_loss(y_true, y_pred):\n","    mse_loss = K.mean(K.square(y_true - y_pred), axis=[1, 2])\n","\n","    y_true_norm = K.l2_normalize(y_true, axis=1)\n","    y_pred_norm = K.l2_normalize(y_pred, axis=1)\n","    cosine_similarity = K.sum(y_true_norm * y_pred_norm, axis=2)\n","\n","    cosine_loss = 1 - cosine_similarity\n","\n","    combined_loss = mse_loss + 0.5 * K.mean(cosine_loss, axis=1)\n","    return combined_loss\n","\n","def kl_loss(z_mean, z_log_sigma):\n","    kl_loss = -0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n","    return kl_loss\n","\n","def vae_loss(true_melody, reconstructed_melody, z_mean, z_log_sigma, beta = 0.05):\n","    recon_loss = reconstruction_loss(true_melody, reconstructed_melody)\n","    kl = kl_loss(z_mean, z_log_sigma)\n","    return recon_loss + kl * beta\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ca4ef832-f7d6-4d97-93f0-5c2c4f2965c1"},"outputs":[],"source":["class VAE(Model):\n","    def __init__(self, encoder, decoder, beta=0.1, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.beta = beta\n","\n","    def call(self, inputs):\n","        inputs, true_melody = inputs\n","        z_mean, z_log_sigma, z = self.encoder(inputs)\n","        reconstructed_melody = self.decoder(z)\n","        recon_loss = reconstruction_loss(true_melody, reconstructed_melody)\n","        kl = kl_loss(z_mean, z_log_sigma)\n","        total_loss = recon_loss + self.beta * kl\n","        self.add_loss(total_loss)\n","        self.add_metric(recon_loss, name='reconstruction_loss', aggregation='mean')\n","        self.add_metric(kl, name='kl_loss', aggregation='mean')\n","        return reconstructed_melody"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8312c3cf-4fb1-4149-9894-ef1cc54f2842"},"outputs":[],"source":["# Build up the VAE model\n","def build_vae_models(input_dim, sequence_length, latent_dim, beta=0.1):\n","    inputs = Input(shape=(input_dim,), name=\"input_features\")\n","    true_melody = Input(shape=(sequence_length, 1), name=\"true_melody\")\n","\n","    encoder = build_encoder(input_dim, latent_dim)\n","    decoder = build_decoder(latent_dim, sequence_length)\n","\n","    z_mean, z_log_sigma, z = encoder(inputs)\n","    reconstructed_melody = decoder(z)\n","\n","    # train model\n","    vae_train = VAE(encoder, decoder, beta)\n","    vae_train.compile(optimizer='adam')\n","\n","    # predict model, do not need to input the Melody\n","    vae_predict = Model(inputs=inputs, outputs=reconstructed_melody, name='vae_predict')\n","\n","    return vae_train, vae_predict"]},{"cell_type":"markdown","metadata":{"id":"e5fa3492-1712-4607-a691-d4b0b5fcac13"},"source":["## Train the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"7c22383b-9a00-4688-890f-e2d6f13c66b2","outputId":"c4ecddb1-d729-4ba3-e32b-cdfaa2d0f19d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," dense (Dense)                  (None, 512)          262656      ['input_1[0][0]']                \n","                                                                                                  \n"," leaky_re_lu (LeakyReLU)        (None, 512)          0           ['dense[0][0]']                  \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 512)         2048        ['leaky_re_lu[0][0]']            \n"," alization)                                                                                       \n","                                                                                                  \n"," dropout (Dropout)              (None, 512)          0           ['batch_normalization[0][0]']    \n","                                                                                                  \n"," dense_1 (Dense)                (None, 256)          131328      ['dropout[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_1 (LeakyReLU)      (None, 256)          0           ['dense_1[0][0]']                \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 256)         1024        ['leaky_re_lu_1[0][0]']          \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 256)          0           ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," dense_2 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']              \n","                                                                                                  \n"," dense_3 (Dense)                (None, 64)           8256        ['dense_2[0][0]']                \n","                                                                                                  \n"," dense_4 (Dense)                (None, 64)           8256        ['dense_2[0][0]']                \n","                                                                                                  \n"," lambda (Lambda)                (None, 64)           0           ['dense_3[0][0]',                \n","                                                                  'dense_4[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 446,464\n","Trainable params: 444,928\n","Non-trainable params: 1,536\n","__________________________________________________________________________________________________\n","Model: \"decoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 64)]         0           []                               \n","                                                                                                  \n"," dense_5 (Dense)                (None, 128)          8320        ['input_2[0][0]']                \n","                                                                                                  \n"," repeat_vector (RepeatVector)   (None, 81, 128)      0           ['dense_5[0][0]']                \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 81, 128)     256         ['repeat_vector[0][0]']          \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 81, 128)     66048       ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 81, 128)      0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 81, 128)     0           ['dropout_2[0][0]',              \n"," da)                                                              'repeat_vector[0][0]']          \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 81, 128)     256         ['tf.__operators__.add[0][0]']   \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_6 (Dense)                (None, 81, 128)      16512       ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 81, 128)      0           ['dense_6[0][0]']                \n","                                                                                                  \n"," dense_7 (Dense)                (None, 81, 128)      16512       ['dropout_3[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 81, 128)     0           ['dense_7[0][0]',                \n"," mbda)                                                            'tf.__operators__.add[0][0]']   \n","                                                                                                  \n"," time_distributed (TimeDistribu  (None, 81, 1)       129         ['tf.__operators__.add_1[0][0]'] \n"," ted)                                                                                             \n","                                                                                                  \n","==================================================================================================\n","Total params: 108,033\n","Trainable params: 108,033\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/5\n","21138/21138 [==============================] - 698s 32ms/step - loss: 0.7415 - reconstruction_loss: 0.6783 - kl_loss: 0.6317 - val_loss: 0.6726 - val_reconstruction_loss: 0.6726 - val_kl_loss: 9.7731e-05\n","Epoch 2/5\n","21138/21138 [==============================] - 701s 33ms/step - loss: 0.6712 - reconstruction_loss: 0.6711 - kl_loss: 1.6412e-04 - val_loss: 0.6726 - val_reconstruction_loss: 0.6726 - val_kl_loss: 1.3613e-04\n","Epoch 3/5\n","21138/21138 [==============================] - 705s 33ms/step - loss: 0.6710 - reconstruction_loss: 0.6709 - kl_loss: 1.3371e-04 - val_loss: 0.6723 - val_reconstruction_loss: 0.6723 - val_kl_loss: 9.1568e-05\n","Epoch 4/5\n","21138/21138 [==============================] - 713s 33ms/step - loss: 0.6709 - reconstruction_loss: 0.6709 - kl_loss: 1.2782e-04 - val_loss: 0.6726 - val_reconstruction_loss: 0.6726 - val_kl_loss: 6.1450e-04\n","Epoch 5/5\n","21138/21138 [==============================] - 728s 34ms/step - loss: 0.6708 - reconstruction_loss: 0.6708 - kl_loss: 1.4312e-04 - val_loss: 0.6725 - val_reconstruction_loss: 0.6725 - val_kl_loss: 8.1850e-05\n","5285/5285 [==============================] - 284s 15ms/step - loss: 0.6725 - reconstruction_loss: 0.6725 - kl_loss: 8.1849e-05\n","Test Loss: [0.6725451946258545, 0.6725373268127441, 8.184945909306407e-05]\n"]}],"source":["input_dim = 512  # input the dimension of features vector\n","sequence_length = 81  # output the length of music sequence\n","latent_dim = 64  # The dimensions of the latent space can be adjusted as needed\n","\n","# create the model\n","vae_train,_ = build_vae_models(input_dim, sequence_length, latent_dim)\n","# Use the model's fit method for training\n","vae_train.fit(train_dataset, epochs=5, validation_data=test_dataset)\n","# Evaluate the model performancee\n","total_loss = vae_train.evaluate(test_dataset)\n","print(\"Test Loss:\", total_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb7faf76-be65-420e-9414-af4781f79337"},"outputs":[],"source":["# save the model\n","vae_train.save_weights('my models/my_vae_weights24.h5')"]},{"cell_type":"markdown","metadata":{"id":"e4f4a5b7-980d-4384-a355-8dd59298cb8f"},"source":["## Load the Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"c35e4123-9adf-4bd2-909d-8fcb2da2e2e8","outputId":"b128fecc-8796-4023-d1d4-82d6d727820c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," dense_9 (Dense)                (None, 512)          262656      ['input_3[0][0]']                \n","                                                                                                  \n"," leaky_re_lu_2 (LeakyReLU)      (None, 512)          0           ['dense_9[0][0]']                \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 512)         2048        ['leaky_re_lu_2[0][0]']          \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 512)          0           ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," dense_10 (Dense)               (None, 256)          131328      ['dropout_4[0][0]']              \n","                                                                                                  \n"," leaky_re_lu_3 (LeakyReLU)      (None, 256)          0           ['dense_10[0][0]']               \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 256)         1024        ['leaky_re_lu_3[0][0]']          \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 256)          0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," dense_11 (Dense)               (None, 128)          32896       ['dropout_5[0][0]']              \n","                                                                                                  \n"," dense_12 (Dense)               (None, 64)           8256        ['dense_11[0][0]']               \n","                                                                                                  \n"," dense_13 (Dense)               (None, 64)           8256        ['dense_11[0][0]']               \n","                                                                                                  \n"," lambda_1 (Lambda)              (None, 64)           0           ['dense_12[0][0]',               \n","                                                                  'dense_13[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 446,464\n","Trainable params: 444,928\n","Non-trainable params: 1,536\n","__________________________________________________________________________________________________\n","Model: \"decoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_4 (InputLayer)           [(None, 64)]         0           []                               \n","                                                                                                  \n"," dense_14 (Dense)               (None, 128)          8320        ['input_4[0][0]']                \n","                                                                                                  \n"," repeat_vector_1 (RepeatVector)  (None, 81, 128)     0           ['dense_14[0][0]']               \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 81, 128)     256         ['repeat_vector_1[0][0]']        \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 81, 128)     66048       ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 81, 128)      0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 81, 128)     0           ['dropout_6[0][0]',              \n"," mbda)                                                            'repeat_vector_1[0][0]']        \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 81, 128)     256         ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_15 (Dense)               (None, 81, 128)      16512       ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 81, 128)      0           ['dense_15[0][0]']               \n","                                                                                                  \n"," dense_16 (Dense)               (None, 81, 128)      16512       ['dropout_7[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 81, 128)     0           ['dense_16[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_2[0][0]'] \n","                                                                                                  \n"," time_distributed_1 (TimeDistri  (None, 81, 1)       129         ['tf.__operators__.add_3[0][0]'] \n"," buted)                                                                                           \n","                                                                                                  \n","==================================================================================================\n","Total params: 108,033\n","Trainable params: 108,033\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["# load the model\n","input_dim = 512  # input the dimension of features vector\n","sequence_length = 81  # output the length of music sequence\n","latent_dim = 64  # The dimensions of the latent space can be adjusted as needed\n","\n","_,model = build_vae_models(input_dim, sequence_length, latent_dim)\n","# load weights\n","model.load_weights('my models/my_vae_weights24.h5')"]},{"cell_type":"markdown","metadata":{"id":"e6480c59-92d3-46d8-8811-d9cab56a56b3"},"source":["## Test the Model"]},{"cell_type":"markdown","metadata":{"id":"2f362e34-e6d5-4748-b9b5-42dc4045f353"},"source":["### Load the Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18191dd6-a820-40f9-b076-3346fa59cd71"},"outputs":[],"source":["# image_add = \"E:\\\\Project and Dissertation in Data Science\\\\dataset\\\\dataset\\\\test\\\\ivan-aivazovsky_sea-at-night-1861.jpg\"\n","image_add = \"E:\\\\Project and Dissertation in Data Science\\\\dataset\\\\artemis_official_data\\\\art_images\\\\vincent-van-gogh_portrait-of-madame-ginoux-l-arlesienne-1890.jpg\"\n","# text = \"The steep mountains and the moonlight provide safety to the inhabitants of the isolated towns. \"\n","# text = \"I can imagine the sailors resting this peaceful night, dreaming of new adventures \"\n","text = \"She seems very happy in the picture, and you want to know what what is behind the smile. \""]},{"cell_type":"markdown","metadata":{"id":"ee64a1ae-9a0f-400d-8eea-dc5b8b1bdd91"},"source":["### Extract Text-Image Features (CLIP Model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d45681a2-7551-4f0b-85b8-a1d802e67ef2"},"outputs":[],"source":["# load pre-trained CLIP model\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","extracted_features_model, preprocess = clip.load(\"ViT-B/32\", device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72ec9754-7663-420b-86b2-82404f488dc3","outputId":"35877bc2-0fc4-4bfb-ce6f-8d03d7e9a76f"},"outputs":[{"name":"stdout","output_type":"stream","text":["image features:  (1, 512)\n","text features:  (1, 512)\n"]}],"source":["# extract the images and text features\n","with torch.no_grad():\n","    image = Image.open(image_add).convert(\"RGB\")\n","    image = preprocess(image).unsqueeze(0)\n","    # image feature\n","    image_feature = torch.cat([extracted_features_model.encode_image(image.to(device))]).cpu().numpy()\n","\n","    # text feature\n","    text_tokens = clip.tokenize(text).to(device)\n","    text_feature = extracted_features_model.encode_text(text_tokens).cpu().numpy()\n","\n","print('image features: ', image_feature.shape)\n","print('text features: ', text_feature.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"682573d4-fa5f-4f3f-8155-888ee7bde794","outputId":"cb19d42d-a74a-49fd-8b5d-b663d87c1bd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 512)\n","[[ 1.1670e-01  2.0752e-03 -3.2288e-02  3.0060e-02  2.0422e-01 -1.3196e-01\n","   1.0681e-02 -5.5029e-01 -3.5370e-02  3.3203e-01 -1.0632e-01  4.0131e-03\n","   2.7002e-01  1.8604e-01  3.2397e-01 -9.5215e-03  8.7830e-02 -2.3462e-01\n","   3.7445e-02 -9.9182e-02  6.4160e-01  1.7737e-01 -2.1960e-01  1.7773e-01\n","  -1.1566e-02 -6.7932e-02  1.9531e-01 -6.2378e-02 -8.5938e-02 -3.8965e-01\n","   1.7249e-01  2.4951e-01 -1.2817e-01  3.3875e-02  1.8884e-01  1.5076e-01\n","   1.5381e-01 -9.2407e-02  1.0217e-01  1.0339e-01  5.9875e-02  3.9429e-02\n","  -5.1941e-02  1.3184e-01  1.0071e-01  1.6919e-01 -2.0691e-01  4.3726e-01\n","   2.4609e-01 -8.9600e-02  1.8506e-01  6.9397e-02  1.6870e-01 -1.9824e-01\n","  -5.8075e-02 -2.5195e-01  1.6016e-01  2.1777e-01 -1.6504e-01  6.5369e-02\n","   4.9805e-01  1.0767e-01  1.8799e-01 -3.5767e-02  1.9214e-01  4.5532e-02\n","   2.4438e-01  2.5098e-01  1.7004e-01 -7.0557e-02  1.9080e-01  2.2644e-02\n","   1.8079e-01 -1.3354e-01 -8.8257e-02  8.4351e-02  4.1162e-01 -2.8648e-03\n","   1.1035e-01  3.1494e-01  1.1902e-02  3.3374e-01 -1.2427e-01 -1.0651e-01\n","   3.3264e-02  2.7002e-01  5.1660e-01 -2.8442e-01 -2.5854e-01 -8.7097e-02\n","  -1.3831e-01 -1.0101e-01 -2.9492e+00 -5.9174e-02  8.1635e-03 -1.3525e-01\n","   9.4604e-03  3.3813e-02 -7.9285e-02  6.9458e-02  2.1826e-01 -1.0657e-01\n","  -4.0344e-02 -1.2720e-01  1.8286e-01  7.5073e-02  1.0254e-01  3.5327e-01\n","  -6.7444e-02 -1.0376e-02 -6.9946e-02 -3.0542e-01 -1.7639e-02  1.6614e-01\n","  -1.5320e-02 -1.1853e-01 -8.7952e-02  5.7983e-03 -1.0938e-01  1.7737e-01\n","  -1.4282e-02 -2.6782e-01 -1.7456e-02 -6.1035e-05  2.1411e-01 -2.3804e-01\n","   1.9946e-01 -1.1194e-01  2.3218e-01  5.5176e-01  2.5000e-01  5.1392e-02\n","  -1.5967e-01  3.4414e+00 -1.3782e-01  1.5083e-02 -2.3499e-01 -1.7456e-02\n","   3.6084e-01  1.0962e-01 -1.2524e-01  2.4390e-01  1.8042e-01  2.5146e-01\n","   9.8022e-02 -8.1787e-02 -1.3237e-02  2.4438e-01 -2.7344e-01  5.7678e-03\n","  -1.1475e-01  9.1736e-02  1.0156e-01 -4.1626e-02  8.1909e-02 -1.5259e-01\n","  -1.3596e-02 -4.4971e-01 -2.5562e-01  2.8491e-01 -2.6294e-01  3.8818e-02\n","  -6.6345e-02  3.6011e-02 -1.0022e-01  7.8003e-02  1.4941e-01  1.3721e-01\n","  -4.1943e-01 -1.2891e-01 -4.8828e-04 -2.3462e-01  4.8608e-01  1.4526e-02\n","  -1.2329e-02 -1.0022e-01 -4.1718e-02  2.0117e-01  7.1094e-01 -2.3877e-01\n","   8.1055e-02 -1.0101e-01  2.4323e-02 -5.9375e-01 -2.6489e-01 -1.2817e-01\n","   1.0883e-01 -8.3862e-02 -1.7407e-01  7.4829e-02  1.3306e-01  1.4941e-01\n","   1.4795e-01  1.0022e-01  1.1609e-01  5.0354e-03 -4.6997e-02  4.0894e-01\n","  -4.0649e-01 -1.3647e-01  1.7883e-02 -2.9443e-01 -1.6345e-01  3.1250e-01\n","  -7.9651e-03 -2.4841e-01 -1.1877e-01  1.3733e-01  2.0972e-01  1.7346e-01\n","   4.5020e-01  4.0210e-01 -1.9257e-02  1.6235e-02 -1.6260e-01  3.2715e-01\n","   2.3608e-01 -2.7930e-01  3.4863e-01  2.2156e-01  3.1372e-02 -1.1407e-01\n","   9.6313e-02  6.5247e-02 -2.2766e-01  9.5581e-02 -2.1454e-02  4.2358e-02\n","  -2.4719e-01 -2.0996e-01 -4.3457e-01  1.0535e-01 -1.1096e-01  1.9238e-01\n","   1.3892e-01 -2.5342e-01 -9.3628e-02  1.3232e-01 -1.6064e-01  2.4890e-01\n","   2.9053e-01  1.5186e-01 -1.8457e-01 -2.3889e-01 -1.1609e-01 -1.4526e-02\n","   2.8320e-01 -1.8738e-01  1.5625e-02 -5.8105e-02  3.1494e-01 -2.9614e-01\n","   8.0200e-02 -2.2803e-01  3.2745e-02 -1.7432e-01  1.6711e-01 -1.2390e-01\n","  -1.2573e-01 -4.4556e-03  2.7051e-01 -8.1665e-02 -3.1030e-01 -8.5449e-02\n","   9.0332e-02  2.2632e-01 -1.0083e-01 -7.5012e-02 -5.3040e-02 -2.6221e-01\n","  -1.9177e-01  4.3457e-01  5.2246e-01 -1.2671e-01  4.6783e-02  2.2766e-01\n","   1.6406e-01  1.1633e-01  2.0093e-01 -1.1285e-01  9.9304e-02 -7.0679e-02\n","   1.9189e-01  2.3376e-02 -2.6123e-01 -4.3945e-03 -6.6357e-01  3.6987e-02\n","   1.3379e-01  8.7128e-03  1.2244e-01  8.1299e-02  2.0581e-01  2.4063e-02\n","   1.0895e-01  2.9480e-02 -1.0223e-02 -2.0203e-02 -3.6652e-02  1.6113e-02\n","   3.0579e-02 -2.6538e-01 -1.5356e-01 -2.9633e-02 -3.3508e-02  2.9810e-01\n","   3.5522e-02  3.7134e-01  8.6792e-02 -7.4646e-02  7.4707e-02  6.7078e-02\n","   3.4355e+00  5.5298e-02  1.2939e-01  2.6978e-01 -2.0248e-02 -1.0138e-01\n","   1.1914e-01  1.0742e-02  1.5100e-01  8.5498e-01  8.4106e-02  1.7346e-01\n","  -3.3887e-01 -1.7624e-02 -5.1331e-02  2.2522e-02  3.0298e-01 -1.1562e+00\n","  -5.8075e-02  8.4045e-02  2.4414e-01 -6.3843e-02 -3.1677e-02  3.5950e-02\n","   3.9886e-02 -6.8054e-02 -3.6426e-01  1.1603e-01 -8.9294e-02 -2.4341e-01\n","  -1.6309e-01  2.2675e-02 -1.0815e-01  1.6113e-01  2.3633e-01 -3.5156e-02\n","  -7.8491e-02 -1.5198e-01 -1.9836e-01  4.3121e-02 -3.4027e-02  6.2866e-02\n","   1.6211e-01  5.4639e-01 -1.0388e-01 -2.9028e-01 -1.5149e-01  1.7212e-02\n","   3.8574e-01 -1.7334e-01  2.7441e-01  1.6187e-01 -6.2354e-01 -9.4788e-02\n","  -1.5503e-01 -9.6741e-02  1.7908e-01 -1.8311e-04  1.6602e-01 -3.7354e-01\n","   6.4087e-02  6.7993e-02 -2.3218e-01 -1.6394e-01  7.4414e-01  1.1334e-01\n","  -3.0566e-01 -6.6528e-03  3.8672e-01 -3.3691e-02 -2.1378e-02 -2.4170e-01\n","   6.2073e-02  1.4453e-01 -1.1768e-01 -1.8860e-02 -2.8491e-01  1.1055e+00\n","  -3.6182e-01 -1.5137e-01 -1.1212e-01  2.0715e-01 -1.3794e-01  6.3599e-02\n","  -1.2122e-01 -6.7322e-02  1.0327e-01 -2.2705e-01  1.2772e-02  4.8706e-02\n","   2.2034e-01 -1.1230e-02  6.1035e-04  2.9102e-01  1.4697e-01 -6.3843e-02\n","   1.8835e-01  3.8483e-02 -4.8438e-01 -4.4922e-02 -1.4282e-02 -1.2561e-01\n","   2.1924e-01 -3.8483e-02 -9.9915e-02 -1.0651e-01 -2.5122e-01  1.8262e-01\n","   8.0322e-02 -9.1736e-02  6.3477e-03  1.5942e-01  3.3356e-02 -6.6406e-02\n","   2.6758e-01 -2.5635e-01  2.2559e-01 -3.1433e-03  2.2266e-01  2.6611e-01\n","   8.0225e-01 -2.6978e-01 -2.3206e-01  3.5010e-01 -3.0859e-01 -2.6001e-01\n","  -2.0361e-01 -2.9980e-01 -8.9172e-02  5.6702e-02 -3.2666e-01 -3.0518e-03\n","  -6.1157e-02  2.0654e-01 -4.7302e-02 -2.9572e-02  1.8262e-01  8.2031e-02\n","   4.4287e-01 -5.4492e-01  8.5693e-02  1.1206e-01  7.1838e-02  1.2805e-01\n","  -6.0638e-02  1.3245e-01 -3.4277e-01  1.7041e-01 -1.5869e-02 -5.8258e-02\n","   1.3757e-01 -2.0898e-01  1.6748e-01 -1.4001e-01  2.4182e-01 -9.7290e-02\n","  -1.0602e-01 -1.7261e-01  3.0762e-02 -1.9556e-01 -1.6260e-01 -6.9275e-03\n","   2.0996e-01  2.8076e-01  1.4001e-01  1.3806e-01  3.0029e-01  1.0229e-01\n","  -4.8645e-02 -3.1567e-01  1.1462e-01 -1.8018e-01 -4.4403e-02 -6.8237e-02\n","   1.3245e-01  1.5442e-02 -4.3091e-02  2.6489e-01  1.7334e-01  1.9617e-01\n","   9.8083e-02  2.8564e-01  3.1738e-02 -2.6099e-01  6.7993e-02 -9.4604e-02\n","   1.0901e-01 -1.6174e-02  1.7163e-01 -4.8584e-02  9.4238e-02  2.8046e-02\n","   4.1357e-01  1.4111e-01 -2.3315e-02 -1.0242e-01 -1.5527e-01 -1.0785e-01\n","  -1.5454e-01  1.0590e-01]]\n","(1, 512)\n","[[ 2.11227629e-01  6.44658465e-03 -6.83159721e-02 -6.01570369e-02\n","   3.87216038e-01 -2.05424813e-01 -1.62938177e-02 -5.88486038e-01\n","  -3.42408185e-04  1.90337130e-01 -1.10568506e-01 -3.81723239e-02\n","   1.73249970e-01  1.55980227e-01  2.08492900e-01 -1.31160792e-01\n","  -3.09866346e-02 -3.80268061e-01  1.32332190e-02 -2.60269120e-01\n","   6.43517005e-01  1.27282703e-01 -1.58946249e-01  1.51038320e-01\n","  -4.76145723e-02 -1.68824299e-01  3.05094450e-01 -1.04886433e-01\n","  -1.80831393e-02 -3.04023646e-01  2.71021729e-01  1.89636661e-01\n","  -4.52800407e-03  5.44451733e-02  3.00326955e-01  2.44406179e-01\n","   1.30551791e-01 -1.92358965e-02  1.86562513e-01 -1.51016662e-01\n","   1.45398511e-01  1.13656325e-01 -2.36516532e-02  2.54076074e-01\n","   1.37979131e-01  1.82921412e-01 -1.42257562e-01  4.06405877e-01\n","   2.99896638e-01 -1.05190618e-01  1.29419947e-01 -2.61396918e-02\n","   1.52083850e-01 -3.65215851e-01 -3.68487877e-02 -3.15234915e-01\n","   2.46220051e-01  3.23801196e-01 -1.73131854e-01  8.80489474e-02\n","   5.56929266e-01  2.18699151e-01  1.47666243e-01  2.61959989e-02\n","   8.16966598e-02  2.71416610e-02  4.39311252e-01  5.76170383e-02\n","   1.95087872e-01 -7.07659021e-02  1.77740562e-01  9.37528313e-02\n","   2.75422898e-01 -3.07646915e-01 -8.61996712e-02  1.59433198e-02\n","   5.26122715e-01  1.99259823e-02  1.04200137e-01  2.78096186e-01\n","   3.25197572e-02  3.27375495e-01 -4.98883339e-02 -2.69922943e-01\n","   6.20345852e-03  3.70323943e-01  4.52076385e-01 -4.56606838e-01\n","  -3.43593017e-01 -6.01497786e-02 -1.97948822e-01 -7.95898548e-02\n","  -2.82314391e+00 -9.06977308e-04 -1.36042114e-02 -1.44640038e-01\n","   1.25983221e-02  6.32988510e-02 -8.30003246e-02 -3.01971314e-02\n","   1.38118675e-01 -1.69627115e-01 -1.72061729e-01 -2.08564552e-01\n","   2.77225363e-01  2.37403666e-01  7.72521227e-02  2.52306856e-01\n","   5.82642780e-02  7.07936244e-02 -6.20625472e-02 -4.18765297e-01\n","  -5.81933413e-02  2.84461614e-01  2.04413295e-02  9.80751709e-02\n","  -4.09886162e-03 -8.90742810e-02 -2.69254269e-01  1.76379728e-01\n","  -1.58725410e-01 -2.18119158e-01 -5.92485120e-02 -1.49489356e-01\n","   3.09922642e-01 -7.23610586e-02  4.58417540e-02 -2.23170688e-01\n","   2.76004376e-01  6.09378078e-01  4.94818675e-01 -6.58209945e-02\n","  -1.15825931e-02  3.30268264e+00 -1.93730846e-01  9.74442659e-02\n","  -3.25772568e-01 -4.95292155e-02  2.86999368e-01  9.17420914e-02\n","   2.05199959e-02  3.55003084e-01  1.74531933e-01  3.92607130e-01\n","   1.31385058e-01  5.43829836e-03 -1.05625049e-02  2.93112378e-01\n","  -3.63050549e-01  4.37221882e-02 -1.02414958e-01  7.31054680e-02\n","   1.22298532e-01 -8.03503147e-02  1.55106555e-01 -8.79664972e-02\n","  -3.22152772e-02 -4.36040706e-01 -4.30178388e-01  1.44521031e-01\n","  -1.66725947e-01 -1.63083621e-02 -4.64547276e-02  9.22676544e-02\n","   5.39865906e-02  2.23785423e-01  1.20904533e-01  1.90500306e-01\n","  -3.96245882e-01 -2.81574081e-02 -1.22920321e-01 -1.71676967e-01\n","   5.73684711e-01 -8.05640288e-02 -5.18392077e-02 -1.60243317e-01\n","   1.04562419e-01  2.58079877e-01  6.10317650e-01 -2.01143238e-01\n","   1.59914754e-01 -8.71196857e-02  1.40045799e-01 -6.62464883e-01\n","  -2.19312958e-01 -1.93777672e-01  5.37847452e-02  1.05990725e-01\n","  -1.43818080e-01  1.05428687e-01  2.64528048e-01  1.45748531e-01\n","   1.70669163e-01  1.28518269e-01  2.75422405e-01  8.70826520e-03\n","  -7.47992750e-02  3.18432711e-01 -5.01419821e-01 -1.95914760e-01\n","   7.43075954e-02 -5.69722271e-02 -9.45265350e-02  1.79260202e-01\n","   7.83198075e-02 -3.16518639e-01 -2.59760288e-03  3.83136202e-01\n","   2.00781472e-01  1.62458053e-01  6.41923326e-01  4.34449130e-01\n","  -1.58941568e-01 -7.40572352e-02 -3.83973701e-01  4.91458770e-01\n","   2.53840703e-01 -4.28847666e-01  5.25984357e-01  2.87551616e-01\n","  -5.87763317e-02 -3.15098541e-01  1.66622586e-01  1.44530839e-01\n","  -3.52762413e-01  9.28680100e-02 -1.84643479e-01 -2.67822085e-02\n","  -3.94565164e-01 -3.22625073e-01 -3.19641394e-01  2.13599000e-01\n","  -4.79014352e-02  6.64844137e-02  2.86762208e-01 -1.32697092e-01\n","  -1.58355469e-01  1.03590167e-01 -8.52405082e-02  2.91711150e-01\n","   8.52640598e-02  9.85903839e-02 -2.91397834e-01 -1.46914121e-01\n","  -1.62185557e-01 -1.11274801e-01  2.91249266e-01 -1.85658079e-01\n","  -1.49219120e-01 -1.11177259e-02  4.02455073e-01 -3.96094081e-01\n","   5.69205399e-02 -1.45960876e-01  1.46189080e-01 -1.80805689e-01\n","   1.78677215e-01 -3.25063231e-02 -1.90703243e-02 -1.67441469e-01\n","   2.18645804e-01 -1.44603749e-01 -2.81244519e-01  9.58516032e-02\n","   1.68097286e-01  2.30423122e-01 -3.30887151e-02 -7.96228297e-03\n","  -1.31386925e-01 -1.98712950e-01 -9.51625329e-02  5.17583841e-01\n","   4.98882411e-01 -1.06834138e-01 -1.17709894e-01  1.46294396e-01\n","   2.04632042e-01  3.66078961e-02  2.19019460e-01 -7.70469547e-02\n","   1.07724409e-02  4.01966293e-02  1.47982421e-01 -7.03770349e-02\n","  -2.94931611e-01  1.12935462e-01 -5.35694351e-01  1.64366202e-01\n","   7.21778266e-02  6.36478468e-02  2.46030608e-01 -2.00438131e-02\n","   3.84318325e-01  6.60016383e-02  1.48015983e-01 -1.19775759e-02\n","   5.89470277e-02 -1.56287018e-01 -1.77728743e-01  2.47465918e-01\n","   2.06064910e-01 -3.96171027e-01 -4.50362812e-02 -5.44943419e-02\n","  -6.30344019e-03  2.71130588e-01  6.66325176e-02  4.72287066e-01\n","   4.91176989e-02 -3.52583334e-02 -1.12031891e-01  9.04936900e-02\n","   3.51732211e+00  1.41250267e-01 -7.59521996e-02  2.37061553e-01\n","  -6.81260471e-02 -6.49823726e-02  1.72549048e-01 -1.80110689e-01\n","  -2.29222843e-02  8.84433072e-01  9.47479535e-02  2.30017650e-01\n","  -5.67452474e-01 -1.01428179e-02 -6.71306861e-02  7.71589867e-02\n","   2.22457809e-01 -1.13564932e+00 -1.67237990e-02 -2.37091242e-02\n","   3.08095991e-01 -1.57478796e-01 -1.11468370e-01  3.15570727e-02\n","  -7.32022982e-02 -2.35568067e-01 -3.96456935e-01  6.69767887e-02\n","  -8.39083700e-02 -2.36979799e-02 -1.70548152e-01 -2.41327550e-02\n","  -1.61678183e-01  2.36486924e-01  2.47567989e-01 -5.96647151e-02\n","  -1.77084238e-01 -1.19859037e-01 -5.80024020e-02  9.22671664e-02\n","   8.48223866e-02 -7.27142895e-03  1.75312135e-01  5.44766569e-01\n","  -1.74766866e-01 -3.78328540e-01 -2.74213705e-01 -1.07044113e-01\n","   4.88400966e-01 -2.68978667e-01  3.67350681e-01  3.33385901e-01\n","  -5.37732431e-01  2.32634556e-02 -2.09877184e-01 -1.45600308e-01\n","   2.25162312e-01 -1.59799977e-02  2.48162872e-02 -4.61264513e-01\n","   2.08352398e-01  9.92044691e-02 -7.66526198e-02  5.15068518e-02\n","   7.81306536e-01  2.27191682e-01 -5.01378913e-01  3.57455405e-02\n","   5.00888374e-01  1.39480391e-01  3.62302390e-02 -1.91466531e-01\n","   9.06299759e-02  1.26249165e-01  6.45418931e-02 -8.20428540e-02\n","  -1.25403182e-01  1.18036591e+00 -3.63484447e-01 -2.99889873e-01\n","  -3.38544782e-02  1.86181724e-01  3.08358859e-02  1.37305097e-01\n","  -1.73109078e-01 -5.83797587e-02  6.70539237e-02 -1.30638424e-01\n","  -7.94036974e-02  3.70150576e-02  1.72793247e-01 -1.09304037e-01\n","   2.23713041e-01  1.75987933e-01  7.35194542e-02  4.63024623e-02\n","   3.15037296e-01 -3.82508334e-04 -5.27426552e-01 -3.17779772e-01\n","  -5.73814186e-02 -5.42504520e-02  2.18803424e-01 -1.49103755e-01\n","  -1.13464505e-01 -1.31805658e-01 -2.14390172e-01  2.57456806e-01\n","   1.44031088e-01 -1.06959823e-01  1.24445332e-01  1.17121215e-01\n","   1.63804898e-02  1.22018733e-02  2.08118771e-01 -3.83224645e-01\n","   2.05017973e-01 -1.10486103e-01  2.92175252e-01  2.62332942e-01\n","   7.06930852e-01 -1.42942761e-01 -1.54042332e-01  2.87572733e-01\n","  -2.19003822e-01 -3.20597945e-01 -1.23508398e-01 -3.55211176e-01\n","  -6.08485106e-02  1.59520088e-01 -1.19808976e-01 -2.08079951e-02\n","   6.07464604e-02  1.82458667e-01 -1.89134158e-02  6.78131051e-02\n","   1.35841150e-01  1.50089951e-01  4.80506616e-01 -4.46351699e-01\n","   1.41688596e-04 -1.33232217e-02  1.60243240e-01  3.44850593e-02\n","   6.71997839e-02  2.55939185e-01 -3.86482149e-01  2.35644528e-01\n","   1.44448881e-02 -4.56408408e-03  5.06158684e-02  2.71870655e-02\n","   1.43325770e-01  5.46149525e-03  3.23914894e-01  1.86984615e-02\n","  -2.02825496e-01 -2.50642112e-01  1.45918953e-01 -1.24014470e-01\n","  -3.62336820e-01  1.22276674e-01  2.61858968e-01  2.41637931e-01\n","   2.50856106e-01  2.63801625e-01  1.81901859e-01  2.71507074e-01\n","  -1.96741711e-01 -2.87205386e-01  2.04363048e-01 -2.42097119e-01\n","  -1.95971615e-01 -1.10906840e-01  1.60677597e-01 -1.21504067e-01\n","  -4.62490737e-02  3.59689538e-01  2.60548861e-01  1.41073102e-01\n","   4.28418185e-02  3.75015778e-01 -2.44230092e-02 -2.34594948e-01\n","   1.47946604e-01 -2.16278232e-01  7.50138543e-02 -5.81905363e-02\n","   1.91456654e-01 -4.86714330e-02  1.89152981e-01  4.18178611e-02\n","   5.11304485e-01  2.18611891e-01 -2.72378958e-02 -1.68477005e-01\n","  -7.38685114e-02 -3.21278638e-01 -1.29139479e-01  7.42117055e-02]]\n"]}],"source":["feature_mean = (image_feature + text_feature) / 2\n","print(feature_mean.shape)\n","print(feature_mean)\n","\n","feature_mean = augment_data(feature_mean)\n","augmented_features = normalize(feature_mean, global_min_feature, global_max_feature)\n","\n","print(augmented_features.shape)\n","print(augmented_features)"]},{"cell_type":"markdown","metadata":{"id":"f3242322-ea36-4f14-9885-cc89abd387d2"},"source":["### Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"23cfb34e-b90f-4027-855b-1bec9a2f44d3","outputId":"6b30c9b4-8cac-4a53-8d1d-cf059387535d"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 152ms/step\n","[[[-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]\n","  [-0.28752652]]]\n","(1, 81, 1)\n"]}],"source":["# generate the Melody by model\n","predicted_melody = model.predict(augmented_features)\n","\n","print(predicted_melody)\n","print(predicted_melody.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"1cf4d102-a17f-4a05-ac75-71c09f870482","outputId":"32e3f407-0c20-4454-d8bc-be4d3a9d34ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]\n","  [43.95454]]]\n","(1, 81, 1)\n"]}],"source":["predicted_melody = denormalize(predicted_melody, -2, 127)\n","\n","print(predicted_melody)\n","print(predicted_melody.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"a3878e1d-f75b-4c49-9ae0-b565b4d00b10"},"outputs":[],"source":["predicted_notes = np.round(predicted_melody).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29169283-ec1c-4bb6-9a01-f5d00a30a3a6","outputId":"e71ecc56-6d1e-469a-baf9-97d3f6515de6"},"outputs":[{"data":{"text/plain":["<note_seq.melodies_lib.Melody at 0x1d7a2be2ee0>"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["melody = note_seq.Melody(predicted_notes.flatten().tolist())\n","melody"]},{"cell_type":"markdown","metadata":{"id":"a6d7633c-1cb9-4ecd-bf74-5aa68fbeedac"},"source":["## Sentiment Analysis text content: Calculate the range of QPM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b70572d7-e770-4f38-a829-8d2274123674","outputId":"7285daf7-d1bc-4845-86ce-0df0b99afef7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentiment Score: 0.5357142857142857\n","Excitement Score: 0.39285714285714285\n","QPM Range: (20, 30)\n","Random QPM: 23\n"]}],"source":["positive_words = set(opinion_lexicon.positive())\n","negative_words = set(opinion_lexicon.negative())\n","\n","calm_words = {\n","    'peaceful', 'calm', 'relaxed', 'serene', 'tranquil', 'composed', 'quiet', 'soothing',\n","    'content', 'easygoing', 'gentle', 'harmonious', 'placid', 'mellow', 'restful',\n","    'untroubled', 'cool', 'collected'\n","}\n","excited_words = {\n","    'excited', 'energetic', 'lively', 'thrilled', 'exhilarated', 'animated', 'enthusiastic',\n","    'vivacious', 'vibrant', 'spirited', 'eager', 'dynamic', 'passionate', 'zealous',\n","    'high-spirited', 'raring', 'buoyant', 'stimulated'\n","}\n","\n","def sentiment_analysis(text):\n","\n","    words = word_tokenize(text.lower())\n","\n","    num_positive_words = sum(1 for word in words if word in positive_words)\n","    num_negative_words = sum(1 for word in words if word in negative_words)\n","    num_neutral_words = len(words) - num_positive_words - num_negative_words\n","    num_calm_words = sum(1 for word in words if word in calm_words)\n","    num_excited_words = sum(1 for word in words if word in excited_words)\n","\n","    total_words = num_positive_words + num_negative_words + num_neutral_words\n","    sentiment_score = ((num_positive_words - num_negative_words) + num_neutral_words * 0.5) / max(1, total_words)\n","\n","    total_emotion_words = num_calm_words + num_excited_words + num_neutral_words\n","    excitement_score = ((num_excited_words - num_calm_words) + num_neutral_words * 0.5) / max(1, total_emotion_words)\n","\n","    return sentiment_score, excitement_score\n","\n","def sentiment_to_qpm(sentiment, excitement):\n","    if excitement >= 0.5:\n","        if sentiment >= 0.5:\n","            return 60, 70\n","        elif sentiment > -0.5:\n","            return 40, 60\n","        else:\n","            return 30, 40\n","    else:\n","        if sentiment >= 0.5:\n","            return 20, 30\n","        elif sentiment > -0.5:\n","            return 10, 20\n","        else:\n","            return 5, 10\n","\n","sentiment_score, excitement_score = sentiment_analysis(text)\n","print('Sentiment Score:', sentiment_score)\n","print('Excitement Score:', excitement_score)\n","\n","qpm_range = sentiment_to_qpm(sentiment_score, excitement_score)\n","print('QPM Range:', qpm_range)\n","\n","random_qpm = random.randint(qpm_range[0], qpm_range[1])\n","print('Random QPM:', random_qpm)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"0517044c-e558-4e60-a0b1-241169661cc3","outputId":"e9693c4d-d826-4b9f-e14c-36b19cb32400"},"outputs":[{"name":"stdout","output_type":"stream","text":["ticks_per_quarter: 220\n","tempos {\n","  qpm: 23.0\n","}\n","notes {\n","  pitch: 19\n","  velocity: 100\n","  end_time: 0.6521739130434783\n","}\n","notes {\n","  pitch: 25\n","  velocity: 100\n","  start_time: 0.6521739130434783\n","  end_time: 1.3043478260869565\n","}\n","notes {\n","  pitch: 32\n","  velocity: 100\n","  start_time: 1.3043478260869565\n","  end_time: 1.9565217391304348\n","}\n","notes {\n","  pitch: 34\n","  velocity: 100\n","  start_time: 1.9565217391304348\n","  end_time: 2.608695652173913\n","}\n","notes {\n","  pitch: 30\n","  velocity: 100\n","  start_time: 2.608695652173913\n","  end_time: 3.2608695652173916\n","}\n","notes {\n","  pitch: 34\n","  velocity: 100\n","  start_time: 3.2608695652173916\n","  end_time: 3.9130434782608696\n","}\n","notes {\n","  pitch: 36\n","  velocity: 100\n","  start_time: 3.9130434782608696\n","  end_time: 4.565217391304348\n","}\n","notes {\n","  pitch: 39\n","  velocity: 100\n","  start_time: 4.565217391304348\n","  end_time: 5.217391304347826\n","}\n","notes {\n","  pitch: 39\n","  velocity: 100\n","  start_time: 5.217391304347826\n","  end_time: 5.869565217391305\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 5.869565217391305\n","  end_time: 6.521739130434783\n","}\n","notes {\n","  pitch: 42\n","  velocity: 100\n","  start_time: 6.521739130434783\n","  end_time: 7.173913043478261\n","}\n","notes {\n","  pitch: 36\n","  velocity: 100\n","  start_time: 7.173913043478261\n","  end_time: 7.826086956521739\n","}\n","notes {\n","  pitch: 41\n","  velocity: 100\n","  start_time: 7.826086956521739\n","  end_time: 8.478260869565217\n","}\n","notes {\n","  pitch: 38\n","  velocity: 100\n","  start_time: 8.478260869565217\n","  end_time: 9.130434782608695\n","}\n","notes {\n","  pitch: 39\n","  velocity: 100\n","  start_time: 9.130434782608695\n","  end_time: 9.782608695652174\n","}\n","notes {\n","  pitch: 41\n","  velocity: 100\n","  start_time: 9.782608695652174\n","  end_time: 10.434782608695652\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 10.434782608695652\n","  end_time: 11.08695652173913\n","}\n","notes {\n","  pitch: 45\n","  velocity: 100\n","  start_time: 11.08695652173913\n","  end_time: 11.73913043478261\n","}\n","notes {\n","  pitch: 39\n","  velocity: 100\n","  start_time: 11.73913043478261\n","  end_time: 12.391304347826088\n","}\n","notes {\n","  pitch: 41\n","  velocity: 100\n","  start_time: 12.391304347826088\n","  end_time: 13.043478260869566\n","}\n","notes {\n","  pitch: 39\n","  velocity: 100\n","  start_time: 13.043478260869566\n","  end_time: 13.695652173913043\n","}\n","notes {\n","  pitch: 40\n","  velocity: 100\n","  start_time: 13.695652173913043\n","  end_time: 14.347826086956522\n","}\n","notes {\n","  pitch: 41\n","  velocity: 100\n","  start_time: 14.347826086956522\n","  end_time: 15.0\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 15.0\n","  end_time: 15.652173913043478\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 15.652173913043478\n","  end_time: 16.304347826086957\n","}\n","notes {\n","  pitch: 37\n","  velocity: 100\n","  start_time: 16.304347826086957\n","  end_time: 16.956521739130434\n","}\n","notes {\n","  pitch: 40\n","  velocity: 100\n","  start_time: 16.956521739130434\n","  end_time: 17.608695652173914\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 17.608695652173914\n","  end_time: 18.26086956521739\n","}\n","notes {\n","  pitch: 38\n","  velocity: 100\n","  start_time: 18.26086956521739\n","  end_time: 18.91304347826087\n","}\n","notes {\n","  pitch: 36\n","  velocity: 100\n","  start_time: 18.91304347826087\n","  end_time: 19.565217391304348\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 19.565217391304348\n","  end_time: 20.217391304347828\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 20.217391304347828\n","  end_time: 20.869565217391305\n","}\n","notes {\n","  pitch: 42\n","  velocity: 100\n","  start_time: 20.869565217391305\n","  end_time: 21.52173913043478\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 21.52173913043478\n","  end_time: 22.17391304347826\n","}\n","notes {\n","  pitch: 45\n","  velocity: 100\n","  start_time: 22.17391304347826\n","  end_time: 22.82608695652174\n","}\n","notes {\n","  pitch: 46\n","  velocity: 100\n","  start_time: 22.82608695652174\n","  end_time: 23.47826086956522\n","}\n","notes {\n","  pitch: 47\n","  velocity: 100\n","  start_time: 23.47826086956522\n","  end_time: 24.130434782608695\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 24.130434782608695\n","  end_time: 24.782608695652176\n","}\n","notes {\n","  pitch: 47\n","  velocity: 100\n","  start_time: 24.782608695652176\n","  end_time: 25.434782608695652\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 25.434782608695652\n","  end_time: 26.086956521739133\n","}\n","notes {\n","  pitch: 45\n","  velocity: 100\n","  start_time: 26.086956521739133\n","  end_time: 26.73913043478261\n","}\n","notes {\n","  pitch: 48\n","  velocity: 100\n","  start_time: 26.73913043478261\n","  end_time: 27.391304347826086\n","}\n","notes {\n","  pitch: 45\n","  velocity: 100\n","  start_time: 27.391304347826086\n","  end_time: 28.043478260869566\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 28.043478260869566\n","  end_time: 28.695652173913043\n","}\n","notes {\n","  pitch: 45\n","  velocity: 100\n","  start_time: 28.695652173913043\n","  end_time: 29.347826086956523\n","}\n","notes {\n","  pitch: 48\n","  velocity: 100\n","  start_time: 29.347826086956523\n","  end_time: 30.0\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 30.0\n","  end_time: 30.65217391304348\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 30.65217391304348\n","  end_time: 31.304347826086957\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 31.304347826086957\n","  end_time: 31.956521739130434\n","}\n","notes {\n","  pitch: 42\n","  velocity: 100\n","  start_time: 31.956521739130434\n","  end_time: 32.608695652173914\n","}\n","notes {\n","  pitch: 41\n","  velocity: 100\n","  start_time: 32.608695652173914\n","  end_time: 33.26086956521739\n","}\n","notes {\n","  pitch: 45\n","  velocity: 100\n","  start_time: 33.26086956521739\n","  end_time: 33.91304347826087\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 33.91304347826087\n","  end_time: 34.56521739130435\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 34.56521739130435\n","  end_time: 35.21739130434783\n","}\n","notes {\n","  pitch: 41\n","  velocity: 100\n","  start_time: 35.21739130434783\n","  end_time: 35.869565217391305\n","}\n","notes {\n","  pitch: 42\n","  velocity: 100\n","  start_time: 35.869565217391305\n","  end_time: 36.52173913043478\n","}\n","notes {\n","  pitch: 46\n","  velocity: 100\n","  start_time: 36.52173913043478\n","  end_time: 37.17391304347826\n","}\n","notes {\n","  pitch: 39\n","  velocity: 100\n","  start_time: 37.17391304347826\n","  end_time: 37.82608695652174\n","}\n","notes {\n","  pitch: 40\n","  velocity: 100\n","  start_time: 37.82608695652174\n","  end_time: 38.47826086956522\n","}\n","notes {\n","  pitch: 42\n","  velocity: 100\n","  start_time: 38.47826086956522\n","  end_time: 39.130434782608695\n","}\n","notes {\n","  pitch: 45\n","  velocity: 100\n","  start_time: 39.130434782608695\n","  end_time: 39.78260869565217\n","}\n","notes {\n","  pitch: 41\n","  velocity: 100\n","  start_time: 39.78260869565217\n","  end_time: 40.434782608695656\n","}\n","notes {\n","  pitch: 42\n","  velocity: 100\n","  start_time: 40.434782608695656\n","  end_time: 41.08695652173913\n","}\n","notes {\n","  pitch: 41\n","  velocity: 100\n","  start_time: 41.08695652173913\n","  end_time: 41.73913043478261\n","}\n","notes {\n","  pitch: 46\n","  velocity: 100\n","  start_time: 41.73913043478261\n","  end_time: 42.391304347826086\n","}\n","notes {\n","  pitch: 48\n","  velocity: 100\n","  start_time: 42.391304347826086\n","  end_time: 43.04347826086956\n","}\n","notes {\n","  pitch: 43\n","  velocity: 100\n","  start_time: 43.04347826086956\n","  end_time: 43.69565217391305\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 43.69565217391305\n","  end_time: 44.34782608695652\n","}\n","notes {\n","  pitch: 42\n","  velocity: 100\n","  start_time: 44.34782608695652\n","  end_time: 45.0\n","}\n","notes {\n","  pitch: 42\n","  velocity: 100\n","  start_time: 45.0\n","  end_time: 45.65217391304348\n","}\n","notes {\n","  pitch: 44\n","  velocity: 100\n","  start_time: 45.65217391304348\n","  end_time: 46.30434782608696\n","}\n","notes {\n","  pitch: 47\n","  velocity: 100\n","  start_time: 46.30434782608696\n","  end_time: 46.95652173913044\n","}\n","notes {\n","  pitch: 48\n","  velocity: 100\n","  start_time: 46.95652173913044\n","  end_time: 47.608695652173914\n","}\n","notes {\n","  pitch: 47\n","  velocity: 100\n","  start_time: 47.608695652173914\n","  end_time: 48.26086956521739\n","}\n","notes {\n","  pitch: 47\n","  velocity: 100\n","  start_time: 48.26086956521739\n","  end_time: 48.91304347826087\n","}\n","notes {\n","  pitch: 49\n","  velocity: 100\n","  start_time: 48.91304347826087\n","  end_time: 49.56521739130435\n","}\n","notes {\n","  pitch: 48\n","  velocity: 100\n","  start_time: 49.56521739130435\n","  end_time: 50.21739130434783\n","}\n","notes {\n","  pitch: 47\n","  velocity: 100\n","  start_time: 50.21739130434783\n","  end_time: 50.869565217391305\n","}\n","notes {\n","  pitch: 50\n","  velocity: 100\n","  start_time: 50.869565217391305\n","  end_time: 51.52173913043478\n","}\n","notes {\n","  pitch: 56\n","  velocity: 100\n","  start_time: 51.52173913043478\n","  end_time: 52.173913043478265\n","}\n","notes {\n","  pitch: 56\n","  velocity: 100\n","  start_time: 52.173913043478265\n","  end_time: 52.82608695652174\n","}\n","total_time: 52.82608695652174\n","\n"]}],"source":["note_sequence = melody.to_sequence(velocity=100, instrument=0, program=0, sequence_start_time=0.0, qpm=random_qpm)\n","\n","print(note_sequence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8e48e557-4832-4384-8aa5-c26f40e6c637"},"outputs":[],"source":["# Use FluidSynth to generate audio data\n","# Need to specify the SoundFont file path\n","# audio_samples = note_seq.fluidsynth(ns, sample_rate=44100, sf2_path='GeneralUser GS v1.471.sf2')\n","# audio_samples = note_seq.fluidsynth(ns, sample_rate=44100, sf2_path=\"TimGM6mb.sf2\")\n","audio_samples = note_seq.fluidsynth(note_sequence, sample_rate=44100, sf2_path=\"FluidR3Mono_GM.sf3\")\n","\n","# Save audio data as WAV file\n","# 'audio_samples' is a floating-point audio array generated by fluidsynth\n","# Normalize audio and convert to 16-bit PCM format\n","write('generated_audios/output_audio_m12_2.wav', 44100, np.int16(audio_samples / np.max(np.abs(audio_samples)) * 32767))"]}]}